<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Fraser's IdM Blog</title>
    <link href="https://frasertweedale.github.io/blog-redhat/atom.xml" rel="self" />
    <link href="https://frasertweedale.github.io/blog-redhat" />
    <id>https://frasertweedale.github.io/blog-redhat/atom.xml</id>
    <author>
        <name>Fraser Tweedale</name>
        <email>frase@frase.id.au</email>
    </author>
    <updated>2018-03-26T00:00:00Z</updated>
    <entry>
    <title>Can we teach an old Dogtag new tricks?</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2018-03-26-old-dogtag-new-tricks.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2018-03-26-old-dogtag-new-tricks.html</id>
    <published>2018-03-26T00:00:00Z</published>
    <updated>2018-03-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="can-we-teach-an-old-dogtag-new-tricks">Can we teach an old Dogtag new tricks?</h1>
<p>Dogtag is a very old program. It started at <em>Netscape</em>. It is old enough to vote. Most of it was written in the early days of Java, long before generics or first-class functions. A lot of it has hardly been touched since it was first written.</p>
<p>Old code often follows old practices that are no longer reasonable. This is not an indictment on the original programmers! The capabilities of our tools usually improve over time (certainly true for Java). The way we solve problems often improves over time too, through better libraries and APIs. And back in the ’90s sites like Stack Overflow didn’t exist and there wasn’t as much free software to learn from. Also, observe that Dogtag is still here, 20 years on, used by customers and being actively developed. This is a <em>huge credit</em> to the original developers and everyone who worked on Dogtag in the meantime.</p>
<p>But we cannot deny that today we have a lot of very old Java code that follows outdated practices and is difficult to reason about and maintain. And maintain it we must. Bugs must be fixed, and new features will be developed. Can Dogtag’s code be modernised? <em>Should it</em> be modernised?</p>
<h2 id="costs-of-change-costs-of-avoiding-change">Costs of change, costs of avoiding change</h2>
<p>One option is to accept and embrace the status quo. Touch the old code as little as possible. Make essential fixes only. Do not refactor classes or interfaces. When writing new code, use the existing interfaces, even if they allow (or demand) unsafe use.</p>
<p>There is something to be said for this approach. Dogtag has bugs, but it is “battle hardened”. It is used by large organisations in security-critical infrastructure. Changing things introduces a risk of breaking things. The bigger the change, the bigger the risk. And Dogtag users are some of the biggest, most security-conscious and risk-conscious organisations out there.</p>
<p>On the other hand, persisting with the old code has some drawbacks too. First, there are certainly undiscovered bugs. Avoiding change except when there is a known defect means those bugs will stay hidden—until they manifest themselves in an unpleasant way! Second, old interfaces that require, for example, unsafe mutation of objects, can lead to new bugs when we do fix bugs or implement new features. Finally, existing code that is difficult to reason about, and interfaces that are difficult to use, slow down fixes and new development.</p>
<h2 id="case-study-acls">Case study: ACLs</h2>
<p>Dogtag uses <em>access control lists (ACLs)</em> to govern what users can do in the system. The text representation of an ACL (with wrapping and indication for presentation only) looks like:</p>
<pre><code>certServer.ca.authorities
  :create,modify
  :allow (list,read) user=&quot;anybody&quot;
    ;allow (create,modify,delete) group=&quot;Administrators&quot;
  :Administrators may create and modify lightweight authorities</code></pre>
<p>The fields are:</p>
<ol style="list-style-type: decimal">
<li>Name of the ACL</li>
<li>List of permissions covered by the ACLs</li>
<li>List of ACL entries. Each entry either grants or denies the listed permissions to users matching an expression</li>
<li>Comment</li>
</ol>
<p>The above ACL grants lightweight CA read permission to all users, while only members of the <code>Administrators</code> group can create, modify or delete them. A typical Dogtag CA subsystem might have around 60 such ACLs. The <em>authorisation subsystem</em> is responsible for loading and enforcing ACLs.</p>
<p>I have touched the ACL machinery a few times in the last couple of years. Most of the changes were bug fixes but I also implemented a small enhancement for merging ACLs with the same name. These were tiny changes; most ACL code is unchanged from prehistoric (pre-Git repo) times. The implementation has several significant issues. Let’s look at a few aspects.</p>
<h3 id="broken-parsing">Broken parsing</h3>
<p>The <code>ACL.parseACL</code> method (<a href="https://github.com/dogtagpki/pki/blob/223e6980c3f3f7a075890897bbb74140cb95279a/base/common/src/com/netscape/certsrv/acls/ACL.java#L191-L289">source</a>) converts the textual representation of an ACL into an internal representation. It’s about 100 lines of Java. Internally it calls <code>ACLEntry.parseACLEntry</code> which is another 40 lines.</p>
<p>The implementation is ad-hoc and inflexible. Fields are found by scanning for delimiters, and their contents are handled in a variety of ways. For fields that can have multiple values, <code>StringTokenizer</code> is used, as in the following (simplified) example:</p>
<div class="sourceCode"><pre class="sourceCode java"><code class="sourceCode java"><span class="bu">StringTokenizer</span> st = <span class="kw">new</span> <span class="bu">StringTokenizer</span>(entriesString, <span class="st">&quot;;&quot;</span>);
<span class="kw">while</span> (st.<span class="fu">hasMoreTokens</span>()) {
    <span class="bu">String</span> entryString = st.<span class="fu">nextToken</span>();
    ACLEntry entry = ACLEntry.<span class="fu">parseACLEntry</span>(acl, entryString);
    <span class="kw">if</span> (entry == <span class="kw">null</span>)
        <span class="kw">throw</span> <span class="kw">new</span> <span class="fu">EACLsException</span>(<span class="st">&quot;failed to parse ACL entries&quot;</span>);
    entry.<span class="fu">setACLEntryString</span>(entryString);
    acl.<span class="fu">entries</span>.<span class="fu">add</span>(entry);
}</code></pre></div>
<p>So what happens if you have an ACL like the following? Note the semicolon in the group name.</p>
<pre><code>certificate:issue:allow (read) group=&quot;sysadmin;pki&quot;
  :PKI sysadmins can read certificates</code></pre>
<p>The current parser will either fail, or succeed but yield an ACL that makes no sense (I’m not quite sure which). I found a similar issue in real world use where group names contained a colon. The parser was scanning forward for a colon to determine the end of the ACL entries field:</p>
<div class="sourceCode"><pre class="sourceCode java"><code class="sourceCode java"><span class="dt">int</span> finalDelimIdx = unparsedInput.<span class="fu">indexOf</span>(<span class="st">&quot;:&quot;</span>);
<span class="bu">String</span> entriesString = unparsedInput.<span class="fu">substring</span>(<span class="dv">0</span>, finalDelimIdx);</code></pre></div>
<p>This was fixed by scanning backwards from the end of the string for the final colon:</p>
<div class="sourceCode"><pre class="sourceCode java"><code class="sourceCode java"><span class="dt">int</span> finalDelimIdx = unparsedInput.<span class="fu">lastIndexOf</span>(<span class="st">&quot;:&quot;</span>);
<span class="bu">String</span> entriesString = unparsedInput.<span class="fu">substring</span>(<span class="dv">0</span>, finalDelimIdx);</code></pre></div>
<p>Now colons in group names work as expected. But it is broken in a different way: if the comment contains a colon, parsing will fail. These kinds of defects are symptomatic of the ad-hoc, brittle parser implementation.</p>
<h3 id="incomplete-parsing">Incomplete parsing</h3>
<p><code>ACLEntry.parseACLEntry</code> method does not actually parse the access expressions. An ACL expression can look like:</p>
<pre><code>user=&quot;caadmin&quot; || group=&quot;Administrators&quot;</code></pre>
<p>The expression is saved in the <code>ACLEntry</code> as-is, i.e. as a string. Parsing is deferred to ACL evaluation. Parsing work is repeated every time the entry is evaluated. The deferral also means that invalid expressions are silently allowed and can only be noticed when they are evaluated. The effect of an invalid expression depends on the kind of syntax error, and the behaviour of the access evaluator.</p>
<h3 id="access-evaluator-expressions">Access evaluator expressions</h3>
<p>The code that parses access evaluator expressions (e.g. <code>user=&quot;bob&quot;</code>) will accept any of <code>=</code>, <code>!=</code>, <code>&gt;</code> or <code>&lt;</code>, even when the nominated access evaluator does not handle the given operator. For example, <code>user&gt;&quot;bob&quot;</code> will be accepted, but the <code>user</code> access evaluator only handles <code>=</code> and <code>!=</code>. It is up to each access evaluator to handle invalid operators appropriately. This is a burden on the programmer. It’s also confusing for users in that semantically invalid expressions like <code>user&gt;&quot;bob&quot;</code> do not result in an error.</p>
<p>Furthermore, the set of access evaluator operators is not extensible. Dogtag administrators can write their own access evaluators and configure Dogtag to use them. But these can only use the <code>=</code>, <code>!=</code>, <code>&gt;</code> or <code>&lt;</code> operators. If you need more than four operators, need non-binary operators, or would prefer different operator symbols, too bad.</p>
<h3 id="acl-evaluation">ACL evaluation</h3>
<p>The <code>AAclAuthz</code> class (<a href="https://github.com/dogtagpki/pki/blob/223e6980c3f3f7a075890897bbb74140cb95279a/base/server/cms/src/com/netscape/cms/authorization/AAclAuthz.java">source</a>) contains around 400 lines of code for evaluating an ACLs for a given user and permissions. (This includes the expression parsing discussed above). In addition, the typical access evaluator class (<code>UserAccessEvaluator</code>, <code>GroupAccessEvaluator</code>, etc.) has about 20 to 40 lines of code dealing with evaluation. The logic is not straightforward to follow.</p>
<p>There is at least one major bug in this code. There is a global configuration that controls whether an ACL’s <em>allow</em> rules or <em>deny</em> rules are processed first. The default is <em>deny,allow</em>, but if you change it to <em>allow,deny</em>, then a matching <em>allow</em> rule will cause denial! Observe (example simplified and commentary added by me):</p>
<div class="sourceCode"><pre class="sourceCode java"><code class="sourceCode java"><span class="kw">if</span> (order.<span class="fu">equals</span>(<span class="st">&quot;deny&quot;</span>)) {
    <span class="co">// deny,allow, the default</span>
    entries = <span class="fu">getDenyEntries</span>(nodes, perm);
} <span class="kw">else</span> {
    <span class="co">// allow,deny</span>
    entries = <span class="fu">getAllowEntries</span>(nodes, perm);
}

<span class="kw">while</span> (entries.<span class="fu">hasMoreElements</span>()) {
    ACLEntry entry = entries.<span class="fu">nextElement</span>();
    <span class="kw">if</span> (<span class="fu">evaluateExpressions</span>(
            authToken,
            entry.<span class="fu">getAttributeExpressions</span>())) {
        <span class="co">// if we are in allow,deny mode, we just hit</span>
        <span class="co">// a matching *allow* rule, and deny access</span>
        <span class="kw">throw</span> <span class="kw">new</span> <span class="fu">EACLsException</span>(<span class="st">&quot;permission denied&quot;</span>);
    }
}</code></pre></div>
<p>The next step of this routine is to process the next set of rules. Like above, if we are in <em>allow,deny</em> mode and encounter a matching <em>deny</em> rule, access will be granted.</p>
<p>This is a serious bug! It completely reverses the meaning of ACLs. In most cases the environment will be completely broken. It also poses a security issue. Because of how broken this setting is, the Dogtag team thinks that it’s unlikely that anyone is running in <em>allow,deny</em> mode. But we can’t be sure, so the bug was assigned <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1556657">CVE-2018-1080</a>.</p>
<p>This defect is present in the initial commit in the Dogtag Git repository (2008). It might have been present in the original implementation. But whenever it was introduced, the problem was not noticed. Several developers who made small changes over the years to the ACL code (logging, formatting, etc) did not notice it. Including me, until very recently.</p>
<p>How has this bug existed for so long? There are several possible factors:</p>
<ul>
<li>Lack of tests, or at least lack of testing in <em>allow,deny</em> mode</li>
<li>Verbose, hard to read code makes it hard to notice a bug that might be more obvious in “pseudo-code”.</li>
<li><a href="https://existentialtype.wordpress.com/2011/03/15/boolean-blindness/">Boolean blindness</a>. A boolean is just a bit, divorced from the context that constructed it. This can lead to misinterpretation. In this case, the boolean result of <code>evaluateExpressions</code> was misinterpreted as <em>allow|deny</em>; the correct interpretation is <em>match|no-match</em>.</li>
<li>Lack of code review. Perhaps peer code review was not practiced when the original implementation was written. Today all patches are reviewed by another Dogtag developer before being merged (we use <a href="https://www.gerritcodereview.com/">Gerrit</a> for that). There is a chance (but not a guarantee) we might have noticed that bug. Maybe a systematic review of old code is warranted.</li>
</ul>
<h2 id="a-better-way">A better way?</h2>
<p>So, looking at one small but important part of Dogtag, we see an old, broken implementation. Some of these problems can be fixed easily (the <em>allow,deny</em> bug). Others require more work (fixing the parsing, extensible access evaluator operators).</p>
<p>Is it worth fixing the non-critical issues? Taking Java as an assumption, it is debatable. The implementation could be cleaned up, type safety improved, bugs fixed. But Java being what it is, even if a lot of the parsing complexity was handled by libraries, the result would still be fairly verbose. Readability and maintainability would still be limited, because of the limitations of Java itself.</p>
<p>So let’s refine our assumption. Instead of <em>Java</em>, we will assume <em>JVM</em>. This opens up to us a bunch of languages that target the JVM, and libraries written using those languages. Dogtag will probably never leave the JVM, for various reasons. But there’s no technical reason we can’t replace old, worn out parts made of Java with new implementations written using languages that have more to offer in terms of correctness, readability and maintainability.</p>
<p>There are <a href="https://en.wikipedia.org/wiki/List_of_JVM_languages">many languages</a> that target the JVM and interoperate with Java. One such language is <a href="https://www.haskell.org/">Haskell</a>, an advanced, pure functional programming (FP) language. JVM support for Haskell comes in the guise of <a href="https://eta-lang.org/">Eta</a>. Eta is a fork of GHC (the most popular Haskell compiler) version 7.10, so any pure Haskell code that worked with GHC 7.10 will work with Eta. I won’t belabour any more gory details of the toolchain right now. Instead, we can dive right into a prototype of ACLs written in Haskell/Eta.</p>
<h2 id="i-haskell-an-acl">I Haskell an ACL</h2>
<p>I assembled a Haskell prototype (<a href="https://github.com/frasertweedale/notes-redhat/tree/master/fp-examples/acl">source code</a>) of the ACL machinery in one day. Much of this time was spent reading the Java implementation so I could preserve its semantics.</p>
<p>The prototype is not complete. It does not support serialisation of ACLs or the heirarchical nature of ACL evaluation (i.e. checking an authorisation on resource <code>foo.bar.baz</code> would check ACLs named <code>foo.bar.baz</code>, <code>foo.bar</code> and <code>foo</code>). It does support parsing and evaluation. We shall see that it resolves the problems in the Java implementation discussed above.</p>
<p>The implementation is about 250 lines of code, roughly ⅓ the size of the Java implementation. It is much easier to read and reason about. Let’s look at a few highlights.</p>
<p>The definitions of the <code>ACL</code> data type, and its constituents, are straightforward:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">Permission</span> <span class="fu">=</span> <span class="dt">Text</span>  <span class="co">-- type synonym, for convenience</span>

<span class="kw">data</span> <span class="dt">ACLRuleType</span> <span class="fu">=</span> <span class="dt">Allow</span> <span class="fu">|</span> <span class="dt">Deny</span>
  <span class="kw">deriving</span> (<span class="dt">Eq</span>) <span class="co">-- auto-derive an equality</span>
                <span class="co">-- test (==) for this type</span>

<span class="co">-- a record type with 3 fields</span>
<span class="kw">data</span> <span class="dt">ACLRule</span> <span class="fu">=</span> <span class="dt">ACLRule</span>
  {<span class="ot"> aclRuleType ::</span> <span class="dt">ACLRuleType</span>
  ,<span class="ot"> aclRulePermissions ::</span> [<span class="dt">Permission</span>]
  ,<span class="ot"> aclRuleExpression ::</span> <span class="dt">ACLExpression</span>
  }

<span class="kw">data</span> <span class="dt">ACL</span> <span class="fu">=</span> <span class="dt">ACL</span>
  {<span class="ot"> aclName ::</span> <span class="dt">Text</span>
  ,<span class="ot"> aclPermissions ::</span> [<span class="dt">Permission</span>]
  ,<span class="ot"> aclRules ::</span> [<span class="dt">ACLRule</span>]
  ,<span class="ot"> aclDescription ::</span> <span class="dt">Text</span>
  }</code></pre></div>
<p>The definition of the ACL parser follows the structure of the data type. This aids readability and assists reasoning about correctness:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">acl ::</span> [<span class="dt">Parser</span> <span class="dt">AccessEvaluator</span>] <span class="ot">-&gt;</span> <span class="dt">Parser</span> <span class="dt">ACL</span>
acl ps <span class="fu">=</span> <span class="dt">ACL</span>
  <span class="fu">&lt;$&gt;</span> takeWhile1 (<span class="fu">/=</span> <span class="ch">&#39;:&#39;</span>) <span class="fu">&lt;*</span> char <span class="ch">&#39;:&#39;</span>
  <span class="fu">&lt;*&gt;</span> (permission <span class="ot">`sepBy1`</span> char <span class="ch">&#39;,&#39;</span>) <span class="fu">&lt;*</span> char <span class="ch">&#39;:&#39;</span>
  <span class="fu">&lt;*&gt;</span> (rule ps <span class="ot">`sepBy1`</span> spaced (char <span class="ch">&#39;;&#39;</span>)) <span class="fu">&lt;*</span> char <span class="ch">&#39;:&#39;</span>
  <span class="fu">&lt;*&gt;</span> takeText</code></pre></div>
<p>Each line is a parser for one of the fields of the <code>ACL</code> data type. The <code>&lt;$&gt;</code> and <code>&lt;*&gt;</code> <em>infix</em> functions combine these smaller parsers into a parser for the whole <code>ACL</code> type. <code>permission</code> and <code>rule</code> are parsers for the <code>Permission</code> and <code>ACLRule</code> data types, respectively. The <code>sepBy1</code> combinator turns a parser for a single thing into a parser for a list of things.</p>
<p>Note that several of these <em>combinators</em> are not specific to parsers but are derived from, or part of, a common abstraction that parsers happen to inhabit. The actual parser library used is incidental. A simple parser type and all the combinators used in this ACL implementation, written from scratch, would take all of 50 lines.</p>
<p>The <code>[Parser AccessEvaluator]</code> argument (named <code>ps</code>) is a list of parsers for <code>AccessEvaluator</code>. This provides the access evaluator extensibility we desire while ensuring that invalid expressions are rejected. The details are down inside the implementation of <code>rule</code> and are not discussed here.</p>
<p>Next we’ll look at how ACLs are evaluated:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">ACLRuleOrder</span> <span class="fu">=</span> <span class="dt">AllowDeny</span> <span class="fu">|</span> <span class="dt">DenyAllow</span>

<span class="kw">data</span> <span class="dt">ACLResult</span> <span class="fu">=</span> <span class="dt">Allowed</span> <span class="fu">|</span> <span class="dt">Denied</span>

evaluateACL
<span class="ot">  ::</span> <span class="dt">ACLRuleOrder</span>
  <span class="ot">-&gt;</span> <span class="dt">AuthenticationToken</span>
  <span class="ot">-&gt;</span> <span class="dt">Permission</span>
  <span class="ot">-&gt;</span> <span class="dt">ACL</span>
  <span class="ot">-&gt;</span> <span class="dt">ACLResult</span>
evaluateACL order tok perm (<span class="dt">ACL</span> _ _ rules _ ) <span class="fu">=</span>
  fromMaybe <span class="dt">Denied</span> result  <span class="co">-- deny if no rules matched</span>
  <span class="kw">where</span>
    permRules <span class="fu">=</span>
      filter (elem perm <span class="fu">.</span> aclRulePermissions) rules

    orderedRules <span class="fu">=</span> <span class="kw">case</span> order <span class="kw">of</span>
      <span class="dt">DenyAllow</span> <span class="ot">-&gt;</span> denyRules <span class="fu">&lt;&gt;</span> allowRules
      <span class="dt">AllowDeny</span> <span class="ot">-&gt;</span> allowRules <span class="fu">&lt;&gt;</span> denyRules
    denyRules <span class="fu">=</span>
      filter ((<span class="fu">==</span> <span class="dt">Deny</span>) <span class="fu">.</span> aclRuleType) permRules
    allowRules <span class="fu">=</span>
      filter ((<span class="fu">==</span> <span class="dt">Allow</span>) <span class="fu">.</span> aclRuleType) permRules

    <span class="co">-- the first matching rule wins</span>
    result <span class="fu">=</span> getFirst
      (foldMap (<span class="dt">First</span> <span class="fu">.</span> evaluateRule tok) orderedRules)</code></pre></div>
<p>Given an <code>ACLRuleOrder</code>, an <code>AuthenticationToken</code> bearing user data, a <code>Permission</code> on the resource being accessed and an <code>ACL</code> for that resource, <code>evaluateACL</code> returns an <code>ACLResult</code> (either <code>Allowed</code> or <code>Denied</code>. The implementation filters rules for the given permission, orders the rules according to the <code>ACLRuleOrder</code>, and returns the result of the first matching rule, or <code>Denied</code> if no rules were matched.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">evaluateRule
<span class="ot">  ::</span> <span class="dt">AuthenticationToken</span>
  <span class="ot">-&gt;</span> <span class="dt">ACLRule</span>
  <span class="ot">-&gt;</span> <span class="dt">Maybe</span> <span class="dt">ACLResult</span>
evaluateRule tok (<span class="dt">ACLRule</span> ruleType _ expr) <span class="fu">=</span>
  <span class="kw">if</span> evaluateExpression tok expr
    <span class="kw">then</span> <span class="dt">Just</span> (result ruleType)
    <span class="kw">else</span> <span class="dt">Nothing</span>
  <span class="kw">where</span>
    result <span class="dt">Deny</span> <span class="fu">=</span> <span class="dt">Denied</span>
    result <span class="dt">Allow</span> <span class="fu">=</span> <span class="dt">Allowed</span></code></pre></div>
<p>Could the <em>allow,deny</em> bug from the Java implementation occur here? It cannot. Instead of the rule evaluator returning a <code>boolean</code> as in the Java implementation, <code>evaluateRule</code> returns a <code>Maybe ACLResult</code>. If a rule does not match, its result is <code>Nothing</code>. If it does match, the result is <code>Just Denied</code> for <code>Deny</code> rules, or <code>Just Allowed</code> for <code>Allow</code> rules. The first <code>Just</code> result encountered is used directly. It’s still possible to mess up the implementation, for example:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">result <span class="dt">Deny</span> <span class="fu">=</span> <span class="dt">Allowed</span>
result <span class="dt">Allow</span> <span class="fu">=</span> <span class="dt">Deny</span></code></pre></div>
<p>But this kind of error is less likely to occur and more likely to be noticed. Boolean blindness is not a factor.</p>
<h2 id="benefits-of-fp-for-prototyping">Benefits of FP for prototyping</h2>
<p>There are benefits to using functional programming for prototyping or re-implementing parts of a system written in less expressive langauges.</p>
<p>First, a tool like Haskell lets you express the nature of a problem succinctly, and leverage the type system as a design tool as you work towards a solution. The solution can then be translated into Java (or Python, or whatever). Because of the less powerful (or nonexistent) type system, there will be a trade-off. You will either have to throw away some of the type safety, or incur additional complexity to keep it (how much complexity depends on the target language). It would be better if we didn’t have to make this trade-off (e.g. by using Eta). But the need to make the trade-off does not diminish the usefulness of FP as a design tool.</p>
<p>It’s also a great way of learning about an existing part of Dogtag, and checking assumptions. And for finding bugs, and opportunities for improving type safety, APIs or performance. I learned a lot about Dogtag’s ACL implementation by reading the code to understand the problem, then solving the problem using FP. Later, I was able to translate some aspects of the Haskell implementation (e.g. using unary sum types to represent ACL rule types and the evaluation order setting) back into the Java implementation (as <code>enum</code> types). This improved type safety and readability.</p>
<p>Going forward, for significant new code and for fixes or refactorings in isolated parts of Dogtag’s implementation, I will spend some time representing the problems and designing solutions in Haskell. The resulting programs will be useful artifacts in their own right; a kind of documentation.</p>
<h2 id="where-to-from-here">Where to from here?</h2>
<p>I’ve demonstrated some of the benefits of the Haskell implementation of ACLs. If the Dogtag development team were to agree that we should begin using FP in Dogtag itself, what would the next steps be?</p>
<p>Eta is not yet packaged for Fedora, let alone RHEL. So as a first step we would have to talk to product managers and release engineers about bringing Eta into RHEL. This is probably the biggest hurdle. One team asking for a large and rather green toolchain that’s not used anywhere else (yet) to be brought into RHEL, where it will have to be supported forever, is going to raise eyebrows.</p>
<p>If we clear that hurdle, then comes the work of packaging Eta. Someone (me) will have to become the package mantainer. And by the way, Eta is written in (GHC) Haskell, so we’ll also need to package GHC for RHEL (or RHEL-extras). Fortunately, GHC <em>is</em> packaged for Fedora, so there is less to do there.</p>
<p>The final stage would be integrating Eta into Dogtag. The build system will need to be updated, and we’ll need to work out how we want to use Eta-based functions and objects from Java (and vice-versa). For the ACLs system, we might want to make the old and new implementations available side by side, for a while. We could even run both implementations simultaneously in a <em>sanity check</em> mode, checking that results are consistent and emitting a warning when they diverge.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This post started with a discussion of the costs and risks of making (or avoiding) significant changes in a legacy system. We then looked in detail at the ACLs implementation in Dogtag, noting some of its problems.</p>
<p>We examined a prototype (re)implementation of ACLs in <em>Haskell</em>, noting several advantages over the legacy implementation. FP’s usefulness as a design tool was discussed. Then we discussed the possibility of using FP in Dogtag itself. What would it take to start using Haskell in Dogtag, via the <em>Eta</em> compiler which targets the JVM? There are several hurdles, technical and non-technical.</p>
<p>Is it worth all this effort, just to be in a position where we can (re)write even a small component of Dogtag in a language other than Java? A language that assists the programmer in writing correct, readable and maintainable software? In answering this question, the costs and risks of persisting with legacy languages and APIs must be considered. I believe the answer is “yes”.</p>]]></summary>
</entry>
<entry>
    <title>DN attribute value encoding in X.509</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2018-03-15-x509-dn-attribute-encoding.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2018-03-15-x509-dn-attribute-encoding.html</id>
    <published>2018-03-15T00:00:00Z</published>
    <updated>2018-03-15T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="dn-attribute-value-encoding-in-x.509">DN attribute value encoding in X.509</h1>
<p>X.509 certificates use the X.500 <em>Distinguished Name (DN)</em> data type to represent issuer and subject names. X.500 names may contain a variety of fields including <em>CommonName</em>, <em>OrganizationName</em>, <em>Country</em> and so on. This post discusses how these values are encoded and compared, and problematic circumstances that can arise.</p>
<h2 id="asn.1-string-types-and-encodings">ASN.1 string types and encodings</h2>
<p>ASN.1 offers a large number of string types, including:</p>
<ul>
<li><code>NumericString</code></li>
<li><code>PrintableString</code></li>
<li><code>IA5String</code></li>
<li><code>UTF8String</code></li>
<li><code>BMPString</code></li>
<li>…several others</li>
</ul>
<p>When serialising an ASN.1 object, each of these string types has a different tag. Some of the types have a shared representation for serialisation but differ in which characters they allow. For example, <code>NumericString</code> and <code>PrintableString</code> are both represented in DER using one byte per character. But <code>NumericString</code> only allows digits (<code>0</code>–<code>9</code>) and <code>SPACE</code>, whereas <code>PrintableString</code> admits the full set of ASCII printable characters. In contrast, <code>BMPString</code> uses two bytes to represent each character; it is equivalent to UTF-16BE. <code>UTF8String</code>, unsurprisingly, uses UTF-8.</p>
<h2 id="asn.1-string-types-for-x.509-name-attributes">ASN.1 string types for X.509 name attributes</h2>
<p>Each of the various X.509 name attribute types uses a specific ASN.1 string type. Some types have a size constraint. For example:</p>
<pre><code>X520countryName      ::= PrintableString (SIZE (2))
DomainComponent      ::= IA5String
X520CommonName       ::= DirectoryName (SIZE (1..64))
X520OrganizationName ::= DirectoryName (SIZE (1..64))</code></pre>
<p>Hold on, what is <code>DirectoryName</code>? It is not a universal ASN.1 type; it is specified as a sum of string types:</p>
<pre><code>DirectoryName ::= CHOICE {
    teletexString     TeletexString,
    printableString   PrintableString,
    universalString   UniversalString,
    utf8String        UTF8String,
    bmpString         BMPString }</code></pre>
<p>Note that a size constraint on <code>DirectoryName</code> propagates to each of the cases. The constraint gives a maximum length in <em>characters</em>, not bytes.</p>
<p>Most X.509 attribute types use <code>DirectoryName</code>, including <em>common name (CN)</em>, <em>organization name (O)</em>, <em>organizational unit (OU)</em>, <em>locality (L)</em>, <em>state or province name (ST)</em>. For these attribute types, which encoding should be used? <a href="">RFC 5280 §4.1.2.6</a> provides some guidance:</p>
<pre><code>The DirectoryString type is defined as a choice of PrintableString,
TeletexString, BMPString, UTF8String, and UniversalString.  CAs
conforming to this profile MUST use either the PrintableString or
UTF8String encoding of DirectoryString, with two exceptions.</code></pre>
<p>The current version of X.509 only allows <code>PrintableString</code> and <code>UTF8String</code>. Earlier versions allowed any of the types in <code>DirectoryString</code>. The <em>exceptions</em> mentioned are grandfather clauses that permit the use of the now-prohibited types in environments that were already using them.</p>
<p>So for strings containing non-ASCII code points <code>UTF8String</code> is the only type you can use. But for ASCII-only strings, there is still a choice, and the RFC does not make a recommendation on which to use. Both are common in practice.</p>
<p>This poses an interesting question. Suppose two encoded DNs have the same attributes in the same order, but differ in the string encodings used. Are they the same DN?</p>
<h2 id="comparing-dns">Comparing DNs</h2>
<p><a href="https://tools.ietf.org/html/rfc5280#section-7.1">RFC 5280 §7.1</a> outlines the procedure for comparing DNs. To compare strings you must convert them to Unicode, translate or drop some special-purpose characters, and perform case folding and normalisation. The resulting strings are then compared case-insensitively. According to this rule, DNs that use different string encodings but are otherwise the same are <strong>equal</strong>.</p>
<p>But the situation is more complex in practice. Earlier versions of X.509 required only binary comparison of DNs. For example, <a href="https://tools.ietf.org/html/rfc3280">RFC 3280</a> states:</p>
<pre><code>Conforming implementations are REQUIRED to implement the following
name comparison rules:

   (a)  attribute values encoded in different types (e.g.,
   PrintableString and BMPString) MAY be assumed to represent
   different strings;

   (b) attribute values in types other than PrintableString are case
   sensitive (this permits matching of attribute values as binary
   objects);

   (c)  attribute values in PrintableString are not case sensitive
   (e.g., &quot;Marianne Swanson&quot; is the same as &quot;MARIANNE SWANSON&quot;); and

   (d)  attribute values in PrintableString are compared after
   removing leading and trailing white space and converting internal
   substrings of one or more consecutive white space characters to a
   single space.</code></pre>
<p>Futhermore, RFC 5280 and earlier versions of X.509 state:</p>
<pre><code>The X.500 series of specifications defines rules for comparing
distinguished names that require comparison of strings without regard
to case, character set, multi-character white space substring, or
leading and trailing white space.  This specification relaxes these
requirements, requiring support for binary comparison at a minimum.</code></pre>
<p>This is a contradiction. The above states that binary comparison of DNs is acceptable, but other sections require a more sophisticated comparison algorithm. The combination of this contradiction, historical considerations and (no doubt) programmer laziness means that many X.509 implementations only perform <strong>binary comparison</strong> of DNs.</p>
<h2 id="how-cas-should-handle-dn-attribute-encoding">How CAs should handle DN attribute encoding</h2>
<p>To ease certification path construction with clients that only perform binary matching of DNs, RFC 5280 states the following requirement:</p>
<pre><code>When the subject of the certificate is a CA, the subject
field MUST be encoded in the same way as it is encoded in the
issuer field (Section 4.1.2.4) in all certificates issued by
the subject CA.  Thus, if the subject CA encodes attributes
in the issuer fields of certificates that it issues using the
TeletexString, BMPString, or UniversalString encodings, then
the subject field of certificates issued to that CA MUST use
the same encoding.</code></pre>
<p>This is confusing wording, but in practical terms there are two requirements:</p>
<ol style="list-style-type: decimal">
<li>The Issuer DN on a certificate must be byte-identical to the Subject DN of the CA that issued it.</li>
<li>The attribute encodings in a CA’s Subject DN must not change (e.g. when the CA certificate gets renewed).</li>
</ol>
<p>If a CA violates either of these requirements breakage will ensue. Programs that do binary DN comparison will be unable to construct a certification path to the CA.</p>
<p>For <em>end-entity</em> (or <em>leaf</em>) certificates, the subject DN is not use in any links of the certification path. Changing the subject attribute encoding when renewing an end-entity certificate will not break validation. But it could still confuse some programs that only do binary comparison of DNs (e.g. they might display two distinct subjects).</p>
<h2 id="processing-certificate-requests">Processing certificate requests</h2>
<p>What about when processing certificate requests—should CAs respect the attribute encodings in the CSR? In my experience, CA programs are prone to issuing certificates with the subject encoded differently from how it was encoded in the CSR. CAs may do various kinds of validation, substitution or addition of subject name attributes. Or they may enforce the use of a particular encoding regardless of the encoding in the CSR.</p>
<p>Is this a problem? It depends on the client program. In my experience most programs can handle this situation. Problems mainly arise when the issuer or subject encoding changes <em>upon renewal</em> (for the reasons discussed above).</p>
<p>If a CSR-versus-certificate encoding mismatch does cause a problem for you, you may have to create a new CSR with the attributes encoding you expect the CA to use for the certificate. In many programs this is not straightforward, if it is possible at all. If you control the CA you might be able to configure it to use particular encodings for string attributes, or to respect the encodings in the CSR. The options available and how to configure them vary among CA programs.</p>
<h2 id="recap">Recap</h2>
<p>X.509 requires the use of either <code>PrintableString</code> or <code>UTF8String</code> for most DN attribute types. Strings consisting of printable 7-bit ASCII characters can be represented using either encoding. This ambiguity can lead to problems in certification path construction.</p>
<p>Formally, two DNs that have the same attributes and values are the same DN, regardless of the string encodings used. But there are many programs that only perform binary matching of DNs. To avoid causing problems for such programs a CA:</p>
<ul>
<li><em>must</em> ensure that the Issuer DN field on all certificates it issues is identical to its own Subject DN;</li>
<li><em>must</em> ensure that Subject DN attribute encodings on CA certificates it issues to a given subject do not change upon renewal;</li>
<li><em>should</em> ensure that Subject DN attribute encodings on end-entity certificates it issues to a given subject do not change upon renewal.</li>
</ul>
<p>CAs will often issue certificates with values encoded differently from how they were presented in the CSR. This usually does not cause problems. But if it does cause problems, you might be able to configure the client program to produce a CSR with different attribute encodings. If you control the CA you may be able to configure it to have a different treatment for attribute encodings. How to do these things was beyond the scope of this article.</p>]]></summary>
</entry>
<entry>
    <title>Changing a CA’s Subject DN; Part II: FreeIPA</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2017-11-22-changing-ca-subject-dn-part-ii-freeipa.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2017-11-22-changing-ca-subject-dn-part-ii-freeipa.html</id>
    <published>2017-11-22T00:00:00Z</published>
    <updated>2017-11-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="changing-a-cas-subject-dn-part-ii-freeipa">Changing a CA’s Subject DN; Part II: FreeIPA</h1>
<p>In the <a href="2017-11-20-changing-ca-subject-dn-part-i.html">previous post</a> I explained how the CA Subject DN is an integral part of X.509 any why you should not change it. Doing so can break path validation, CRLs and OCSP, and many programs will not copye with the change. I proposed some alternative approaches that avoid these problems: re-chaining the CA, and creating subordinate CAs.</p>
<p>If you were thinking of changing your CA’s Subject DN, I hope that I dissuaded you. But if I failed, or you absolutely do need to change the Subject DN of your CA, where there’s a will there’s way. The purpose of this post is to explore how to do this in FreeIPA, and discuss the implications.</p>
<p>This is a <strong>long post</strong>. If you are really changing the CA subject DN, don’t skip anything. Otherwise don’t feel bad about skimming or jumping straight to the <a href="#discussion">discussion</a>. Even skimming the article will give you an idea of the steps involved, and how to repair the ensuing breakage.</p>
<h2 id="changing-the-freeipa-cas-subject-dn">Changing the FreeIPA CA’s Subject DN</h2>
<p>Before writing this post, I had never even attempted to do this. I am unaware of anyone else trying or whether they were successful. But the question of how to do it has come up several times, so I decided to investigate. The format of this post follows my exploration of the topic as I poked and prodded a FreeIPA deployment, working towards the goal.</p>
<p>What was the goal? Let me state the goal, and some assumptions:</p>
<ul>
<li>The goal is to give the FreeIPA CA a new Subject DN. The deployment should look and behave as though it were originally installed with the new Subject.</li>
<li>We want to keep the old CA certificate in the relevant certificate stores and databases, alongside the new certificate.</li>
<li>The CA is not being re-keyed (I will deal with re-keying in a future article).</li>
<li>We want to be able to do this with both self-signed and externally-signed CAs. It’s okay if the process differs.</li>
<li>It’s okay to have manual steps that the administrator must perform.</li>
</ul>
<p>Let’s begin on the deployment’s <em>CA renewal master</em>.</p>
<h3 id="certmonger-first-attempt">Certmonger (first attempt)</h3>
<p>There is a Certmonger tracking request for the FreeIPA CA, which uses the <code>dogtag-ipa-ca-renew-agent</code> CA helper. The <code>getcert resubmit</code> command lets you change the Subject DN when you resubmit a request, via the <code>-N</code> option. I know the internals of the CA helper and I can see that there will be problems <em>after</em> renewing the certificate this way. Storing the certificate in the <code>ca_renewal</code> LDAP container will fail. But the renewal itself <em>might</em> succeed so I’ll try it and see what happens:</p>
<pre><code>[root@f27-2 ~]# getcert resubmit -i 20171106062742 \
  -N &#39;CN=IPA.LOCAL CA 2017.11.09&#39;
Resubmitting &quot;20171106062742&quot; to &quot;dogtag-ipa-ca-renew-agent&quot;.</code></pre>
<p>After waiting about 10 seconds for Certmonger to do its thing, I check the state of the tracking request:</p>
<pre><code>[root@f27-2 ~]# getcert list -i 20171106062742
Request ID &#39;20171106062742&#39;:
  status: MONITORING
  CA: dogtag-ipa-ca-renew-agent
  issuer: CN=Certificate Authority,O=IPA.LOCAL 201711061603
  subject: CN=Certificate Authority,O=IPA.LOCAL 201711061603
  expires: 2037-11-06 17:26:21 AEDT
  ... (various fields omitted)</code></pre>
<p>The <code>status</code> and <code>expires</code> fields show that renewal succeeded, but the certificate still has the old Subject DN. This happened because the <code>dogtag-ipa-ca-renew-agent</code> helper doesn’t think it is renewing the CA certificate (which is true!)</p>
<h3 id="modifying-the-ipa-ca-entry">Modifying the IPA CA entry</h3>
<p>So let’s trick the Certmonger renewal helper. <code>dogtag-ipa-ca-renew-agent</code> looks up the CA Subject DN in the <code>ipaCaSubjectDn</code> attribute of the <code>ipa</code> CA entry (<code>cn=ipa,cn=cas,cn=ca,{basedn}</code>). This attribute is not writeable via the IPA framework but you can change it using regular LDAP tools (details out of scope). If the certificate is self-signed you should also change the <code>ipaCaIssuerDn</code> attribute. After modifying the entry run <code>ipa ca-show</code> to verify that these attributes have the desired values:</p>
<pre><code>[root@f27-2 ~]# ipa ca-show ipa
  Name: ipa
  Description: IPA CA
  Authority ID: cdbfeb5a-64d2-4141-98d2-98c005802fc1
  Subject DN: CN=IPA.LOCAL CA 2017.11.09
  Issuer DN: CN=IPA.LOCAL CA 2017.11.09
  Certificate: MIIDnzCCAoegAwIBAgIBCTANBgkqhkiG9w0...</code></pre>
<h3 id="certmonger-second-attempt">Certmonger (second attempt)</h3>
<p>Now let’s try and renew the CA certificate via Certmonger again:</p>
<pre><code>[root@f27-2 ~]# getcert resubmit -i 20171106062742 \
  -N &#39;CN=IPA.LOCAL CA 2017.11.09&#39;
Resubmitting &quot;20171106062742&quot; to &quot;dogtag-ipa-ca-renew-agent&quot;.</code></pre>
<p>Checking the <code>getcert list</code> output after a short wait:</p>
<pre><code>[root@f27-2 ~]# getcert list -i 20171106062742
Request ID &#39;20171106062742&#39;:
  status: MONITORING
  CA: dogtag-ipa-ca-renew-agent
  issuer: CN=Certificate Authority,O=IPA.LOCAL 201711061603
  subject: CN=IPA.LOCAL CA 2017.11.09
  expires: 2037-11-09 16:11:12 AEDT
  ... (various fields omitted)</code></pre>
<p>Progress! We now have a CA certificate with the desired Subject DN. The new certificate has the old (current) issuer DN. We’ll ignore that for now.</p>
<h3 id="checking-server-health">Checking server health</h3>
<p>Now I need to check the state of the deployment. Did anything go wrong during renewal? Is everything working?</p>
<p>First, I checked the Certmonger journal output to see if there were any problems. The journal contained the following messages (some fields omitted for brevity):</p>
<pre><code>16:11:17 /dogtag-ipa-ca-renew-agent-submit[1662]: Forwarding request to dogtag-ipa-renew-agent
16:11:17 /dogtag-ipa-ca-renew-agent-submit[1662]: dogtag-ipa-renew-agent returned 0
16:11:19 /stop_pkicad[1673]: Stopping pki_tomcatd
16:11:20 /stop_pkicad[1673]: Stopped pki_tomcatd
16:11:22 /renew_ca_cert[1710]: Updating CS.cfg
16:11:22 /renew_ca_cert[1710]: Updating CA certificate failed: no matching entry found
16:11:22 /renew_ca_cert[1710]: Starting pki_tomcatd
16:11:34 /renew_ca_cert[1710]: Started pki_tomcatd
16:11:34 certmonger[2013]: Certificate named &quot;caSigningCert cert-pki-ca&quot; in token &quot;NSS Certificate DB&quot; in database &quot;/etc/pki/pki-tomcat/alias&quot; issued by CA and saved.</code></pre>
<p>We can see that the renewal succeeded and Certmonger saved the new certificate in the NSSDB. Unfortunately there was an error in the <code>renew_ca_cert</code> post-save hook: it failed to store the new certificate in the LDAP certstore. That should be easy to resolve. I’ll make a note of that and continue checking deployment health.</p>
<p>Next, I checked whether Dogtag was functioning. <code>systemctl status pki-tomcatd@pki-tomcat</code> and the CA debug log (<code>/var/log/pki/pki-tomcat/ca/debug</code>) indicated that Dogtag started cleanly. Even better, the Dogtag NSSDB has the new CA certificate with the correct nickname:</p>
<pre><code>[root@f27-2 ~]# certutil -d /etc/pki/pki-tomcat/alias \
  -L -n &#39;caSigningCert cert-pki-ca&#39;
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 11 (0xb)
        Signature Algorithm: PKCS #1 SHA-256 With RSA Encryption
        Issuer: &quot;CN=Certificate Authority,O=IPA.LOCAL 201711061603&quot;
        Validity:
            Not Before: Thu Nov 09 05:11:12 2017
            Not After : Mon Nov 09 05:11:12 2037
        Subject: &quot;CN=IPA.LOCAL CA 2017.11.09&quot;
  ... (remaining lines omitted)</code></pre>
<p>We have not yet confirmed that the Dogtag uses the new CA Subject DN as the Issuer DN on new certificates (we’ll check this later).</p>
<p>Now let’s check the state of IPA itself. There is a problem in communication between the IPA framework and Dogtag:</p>
<pre><code>[root@f27-2 ~]# ipa ca-show ipa
ipa: ERROR: Request failed with status 500: Non-2xx response from CA REST API: 500.</code></pre>
<p>A quick look in <code>/var/log/httpd/access_log</code> showed that it was not a general problem but only occurred when accessing a particular resource:</p>
<pre><code>[09/Nov/2017:17:15:09 +1100] &quot;GET https://f27-2.ipa.local:443/ca/rest/authorities/cdbfeb5a-64d2-4141-98d2-98c005802fc1/cert HTTP/1.1&quot; 500 6201</code></pre>
<p>That is a Dogtag <em>lightweight authority</em> resource for the CA identified by <code>cdbfeb5a-64d2-4141-98d2-98c005802fc1</code>. That is the <em>CA ID</em> recorded in the FreeIPA <code>ipa</code> CA entry. This gives a hint about where the problem lies. An <code>ldapsearch</code> reveals more:</p>
<pre><code>[f27-2:~] ftweedal% ldapsearch -LLL \
    -D &#39;cn=directory manager&#39; -w DM_PASSWORD \
    -b &#39;ou=authorities,ou=ca,o=ipaca&#39; -s one
dn: cn=cdbfeb5a-64d2-4141-98d2-98c005802fc1,ou=authorities,ou=ca,o=ipaca
authoritySerial: 9
objectClass: authority
objectClass: top
cn: cdbfeb5a-64d2-4141-98d2-98c005802fc1
authorityID: cdbfeb5a-64d2-4141-98d2-98c005802fc1
authorityKeyNickname: caSigningCert cert-pki-ca
authorityEnabled: TRUE
authorityDN: CN=Certificate Authority,O=IPA.LOCAL 201711061603
description: Host authority

dn: cn=008a4ded-fd4b-46fe-8614-68518123c95f,ou=authorities,ou=ca,o=ipaca
objectClass: authority
objectClass: top
cn: 008a4ded-fd4b-46fe-8614-68518123c95f
authorityID: 008a4ded-fd4b-46fe-8614-68518123c95f
authorityKeyNickname: caSigningCert cert-pki-ca
authorityEnabled: TRUE
authorityDN: CN=IPA.LOCAL CA 2017.11.09
description: Host authority</code></pre>
<p>There are now two authority entries when there should be one. During startup, Dogtag makes sure it has an authority entry for the main (“host”) CA. It compares the Subject DN from the signing certificate in its NSSDB to the authority entries. If it doesn’t find a match it creates a new entry, and that’s what happened here.</p>
<p>The resolution is straightforward:</p>
<ol style="list-style-type: decimal">
<li>Stop Dogtag</li>
<li>Update the <code>authorityDN</code> and <code>authoritySerial</code> attributes of the <em>original</em> host authority entry.</li>
<li>Delete the <em>new</em> host authority entry.</li>
<li>Restart Dogtag.</li>
</ol>
<p>Now the previous <code>ldapsearch</code> returns one entry, with the original authority ID and correct attribute values:</p>
<pre><code>[f27-2:~] ftweedal% ldapsearch -LLL \
    -D &#39;cn=directory manager&#39; -w DM_PASSWORD \
    -b &#39;ou=authorities,ou=ca,o=ipaca&#39; -s one
dn: cn=cdbfeb5a-64d2-4141-98d2-98c005802fc1,ou=authorities,ou=ca,o=ipaca
authoritySerial: 11
authorityDN: CN=IPA.LOCAL CA 2017.11.09
objectClass: authority
objectClass: top
cn: cdbfeb5a-64d2-4141-98d2-98c005802fc1
authorityID: cdbfeb5a-64d2-4141-98d2-98c005802fc1
authorityKeyNickname: caSigningCert cert-pki-ca
authorityEnabled: TRUE
description: Host authority</code></pre>
<p>And the operations that were failing before (e.g. <code>ipa ca-show ipa</code>) now succeed. So we’ve confirmed, or restored, the basic functionality on this server.</p>
<h3 id="ldap-certificate-stores">LDAP certificate stores</h3>
<p>There are two LDAP certificate stores in FreeIPA. The first is <code>cn=ca_renewal,cn=ipa,cn=etc,{basedn}</code>. It is only used for replicating Dogtag CA and system certificates from the CA renewal master to CA replicas. The <code>dogtag-ipa-ca-renew-agent</code> Certmonger helper should update the <code>cn=caSigningCert cert-pki-ca,cn=ca_renewal,cn=ipa,cn=etc,{basedn}</code> entry after renewing the CA certificate. A quick <code>ldapsearch</code> shows that this succeeded, so there is nothing else to do here.</p>
<p>The other certificate store is <code>cn=certificates,cn=ipa,cn=etc,{basedn}</code>. This store contains trusted CA certificates. FreeIPA clients and servers retrieve certificates from this directory when updating their certificate trust stores. Certificates are stored in this container with a <code>cn</code> based on the Subject DN, except for the IPA CA which is stored with <code>cn={REALM-NAME} IPA CA</code>. (In my case, this is <code>cn=IPA.LOCAL IPA CA</code>.)</p>
<p>We discovered the failure to update this certificate store earlier (in the Certmonger journal). Now we must fix it up. We still want to trust certificates with the old Issuer DN, otherwise we would have to reissue <em>all of them</em>. So we need to keep the old CA certificate in the store, alongside the new.</p>
<p>The process to fix up the certificate store is:</p>
<ol style="list-style-type: decimal">
<li><p>Export the new CA certificate from the Dogtag NSSDB to a file:</p>
<pre><code>[root@f27-2 ~]# certutil -d /etc/pki/pki-tomcat/alias \
   -L -a -n &#39;caSigningCert cert-pki-ca&#39; &gt; new-ca.crt</code></pre></li>
<li><p>Add the new CA certificate to the certificate store:</p>
<pre><code>[root@f27-2 ~]# ipa-cacert-manage install new-ca.crt
Installing CA certificate, please wait
CA certificate successfully installed
The ipa-cacert-manage command was successful</code></pre></li>
<li>Rename (<code>modrdn</code>) the existing <code>cn={REALM-NAME} IPA CA</code> entry. The new <code>cn</code> RDN is based on the old CA Subject DN.</li>
<li>Rename the new CA certificate entry. The current <code>cn</code> is the new Subject DN. Rename it to <code>cn={REALM-NAME} IPA CA</code>. I encountered a 389DS attribute uniqueness error when I attempted to do this as a <code>modrdn</code> operation. I’m not sure why it happened. To work around the problem I deleted the entry and added it back with the new <code>cn</code>.</li>
</ol>
<p>At the end of this procedure the certificate store is as it should be. The CA certificate with new Subject DN is installed as <code>{REALM-NAME} IPA CA</code> and the old CA certificate has been preserved under a different RDN.</p>
<h3 id="updating-certificate-databases">Updating certificate databases</h3>
<p>The LDAP certificate stores have the new CA certificate. Now we need to update the other certificate databases so that the programs that use them will trust certificates with the new Issuer DN. These databases include:</p>
<dl>
<dt><code>/etc/ipa/ca.crt</code></dt>
<dd><p>CA trust store used by the IPA framework</p>
</dd>
<dt><code>/etc/ipa/nssdb</code></dt>
<dd><p>An NSSDB used by FreeIPA</p>
</dd>
<dt><code>/etc/dirsrv/slapd-{REALM-NAME}</code></dt>
<dd><p>NSSDB used by 389DS</p>
</dd>
<dt><code>/etc/httpd/alias</code></dt>
<dd><p>NSSDB used by Apache HTTPD</p>
</dd>
<dt><code>/etc/pki/ca-trust/source/ipa.p11-kit</code></dt>
<dd><p>Adds FreeIPA CA certificates to the system-wide trust store</p>
</dd>
</dl>
<p>Run <code>ipa-certupdate</code> to update these databases with the CA certificates from the LDAP CA certificate store:</p>
<pre><code>[root@f27-2 ~]# ipa-certupdate
trying https://f27-2.ipa.local/ipa/json
[try 1]: Forwarding &#39;schema&#39; to json server &#39;https://f27-2.ipa.local/ipa/json&#39;
trying https://f27-2.ipa.local/ipa/session/json
[try 1]: Forwarding &#39;ca_is_enabled/1&#39; to json server &#39;https://f27-2.ipa.local/ipa/session/json&#39;
[try 1]: Forwarding &#39;ca_find/1&#39; to json server &#39;https://f27-2.ipa.local/ipa/session/json&#39;
failed to update IPA.LOCAL IPA CA in /etc/dirsrv/slapd-IPA-LOCAL: Command &#39;/usr/bin/certutil -d /etc/dirsrv/slapd-IPA-LOCAL -A -n IPA.LOCAL IPA CA -t C,, -a -f /etc/dirsrv/slapd-IPA-LOCAL/pwdfile.txt&#39; returned non-zero exit status 255.
failed to update IPA.LOCAL IPA CA in /etc/httpd/alias: Command &#39;/usr/bin/certutil -d /etc/httpd/alias -A -n IPA.LOCAL IPA CA -t C,, -a -f /etc/httpd/alias/pwdfile.txt&#39; returned non-zero exit status 255.
failed to update IPA.LOCAL IPA CA in /etc/ipa/nssdb: Command &#39;/usr/bin/certutil -d /etc/ipa/nssdb -A -n IPA.LOCAL IPA CA -t C,, -a -f /etc/ipa/nssdb/pwdfile.txt&#39; returned non-zero exit status 255.
Systemwide CA database updated.
Systemwide CA database updated.
The ipa-certupdate command was successful
[root@f27-2 ~]# echo $?
0</code></pre>
<p><code>ipa-certupdate</code> reported that it was successful and it exited cleanly. But a glance at the output shows that not all went well. There were failures added the new CA certificate to several NSSDBs. Running one of the commands manually to see the command output doesn’t give us much more information:</p>
<pre><code>[root@f27-2 ~]# certutil -d /etc/ipa/nssdb -f /etc/ipa/nssdb/pwdfile.txt \
    -A -n &#39;IPA.LOCAL IPA CA&#39; -t C,, -a &lt; ~/new-ca.crt
certutil: could not add certificate to token or database: SEC_ERROR_ADDING_CERT: Error adding certificate to database.
[root@f27-2 ~]# echo $?
255</code></pre>
<p>At this point I guessed that because there is already a certificate stored with the nickname <code>IPA.LOCAL IPA CA</code>, NSS refuses to add a certificate with a different Subject DN under the same nickname. So I will delete the certificates with this nickname from each of the NSSDBs, then try again. For some reason the nickname appeared twice in each NSSDB:</p>
<pre><code>[root@f27-2 ~]# certutil -d /etc/dirsrv/slapd-IPA-LOCAL -L

Certificate Nickname                                         Trust Attributes
                                                             SSL,S/MIME,JAR/XPI

CN=alt-f27-2.ipa.local,O=Example Organization                u,u,u
CN=CA,O=Example Organization                                 C,,
IPA.LOCAL IPA CA                                             CT,C,C
IPA.LOCAL IPA CA                                             CT,C,C</code></pre>
<p>So for each NSSDB, to delete the certificate I had to execute the <code>certutil</code> command twice. For the 389DS NSSDB, the command was:</p>
<pre><code>[root@f27-2 ~]# certutil -d /etc/httpd/alias -D -n &quot;IPA.LOCAL IPA CA&quot;</code></pre>
<p>The commands for the other NSSDBs were similar. With the problematic certificates removed, I tried running <code>ipa-certupdate</code> again:</p>
<pre><code>[root@f27-2 ~]# ipa-certupdate
trying https://f27-2.ipa.local/ipa/session/json
[try 1]: Forwarding &#39;ca_is_enabled/1&#39; to json server &#39;https://f27-2.ipa.local/ipa/session/json&#39;
[try 1]: Forwarding &#39;ca_find/1&#39; to json server &#39;https://f27-2.ipa.local/ipa/session/json&#39;
Systemwide CA database updated.
Systemwide CA database updated.
The ipa-certupdate command was successful
[root@f27-2 ~]# echo $?
0</code></pre>
<p>This time there were no errors. <code>certutil</code> shows an <code>IPA.LOCAL IPA CA</code> certificate in the database, and it’s the right certificate:</p>
<pre><code>[root@f27-2 ~]# certutil -d /etc/dirsrv/slapd-IPA-LOCAL -L

Certificate Nickname                                         Trust Attributes
                                                             SSL,S/MIME,JAR/XPI

CN=alt-f27-2.ipa.local,O=Example Organization                u,u,u
CN=CA,O=Example Organization                                 C,,
CN=Certificate Authority,O=IPA.LOCAL 201711061603            CT,C,C
CN=Certificate Authority,O=IPA.LOCAL 201711061603            CT,C,C
IPA.LOCAL IPA CA                                             C,,
[root@f27-2 ~]# certutil -d /etc/dirsrv/slapd-IPA-LOCAL -L -n &#39;IPA.LOCAL IPA CA&#39;
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 11 (0xb)
        Signature Algorithm: PKCS #1 SHA-256 With RSA Encryption
        Issuer: &quot;CN=Certificate Authority,O=IPA.LOCAL 201711061603&quot;
        Validity:
            Not Before: Thu Nov 09 05:11:12 2017
            Not After : Mon Nov 09 05:11:12 2037
        Subject: &quot;CN=IPA.LOCAL CA 2017.11.09&quot;
        ...</code></pre>
<p>I also confirmed that the old and new CA certificates are present in the <code>/etc/ipa/ca.crt</code> and <code>/etc/pki/ca-trust/source/ipa.p11-kit</code> files. So all the certificate databases now include the new CA certificate.</p>
<h3 id="renewing-the-ca-certificate-again">Renewing the CA certificate (again)</h3>
<p>Observe that (in the self-signed FreeIPA CA case) the Issuer DN of the new CA certificate is the Subject DN of the old CA certificate. So we have not quite reached out goal. The original CA certificate was self-signed, so we want a self-signed certificate with the new Subject.</p>
<p>Renewing the CA certificate one more time should result in a self-signed certificate. The current situation is not likely to result in operational issues. So you can consider this an optional step. Anyhow, let’s give it a go:</p>
<pre><code>[root@f27-2 ~]# getcert list -i 20171106062742 | egrep &#39;status|issuer|subject&#39;
        status: MONITORING
        issuer: CN=Certificate Authority,O=IPA.LOCAL 201711061603
        subject: CN=IPA.LOCAL CA 2017.11.09
[root@f27-2 ~]# getcert resubmit -i 20171106062742
Resubmitting &quot;20171106062742&quot; to &quot;dogtag-ipa-ca-renew-agent&quot;.
[root@f27-2 ~]# sleep 5
[root@f27-2 ~]# getcert list -i 20171106062742 | egrep &#39;status|issuer|subject&#39;
        status: MONITORING
        issuer: CN=IPA.LOCAL CA 2017.11.09
        subject: CN=IPA.LOCAL CA 2017.11.09</code></pre>
<p>Now we have a self-signed CA cert with the new Subject DN. This step has also confirmed that that the certificate issuance is working fine with the new CA subject.</p>
<h3 id="renewing-freeipa-service-certificates">Renewing FreeIPA service certificates</h3>
<p>This is another optional step, because we have kept the old CA certificate in the trust store. I want to check that certificate renewals via the FreeIPA framework are working, and this is a fine way to do that.</p>
<p>I’ll renew the HTTP service certificate. This deployment is using an externally-signed HTTP certificate so first I had to track it:</p>
<pre><code>[root@f27-2 ~]# getcert start-tracking \
  -d /etc/httpd/alias -p /etc/httpd/alias/pwdfile.txt \
  -n &#39;CN=alt-f27-2.ipa.local,O=Example Organization&#39; \
  -c IPA -D &#39;f27-2.ipa.local&#39; -K &#39;HTTP/f27-2.ipa.local@IPA.LOCAL&#39;
New tracking request &quot;20171121071700&quot; added.</code></pre>
<p>Then I resubmitted the tracking request. I had to include the <code>-N &lt;SUBJECT&gt;</code> option because the current Subject DN would be rejected by FreeIPA. I also had to include the <code>-K &lt;PRINC_NAME&gt;</code> option due to <a href="https://pagure.io/certmonger/issue/85">a bug in Certmonger</a>.</p>
<pre><code>[root@f27-2 ~]# getcert resubmit -i 20171121073608 \
  -N &#39;CN=f27-2.ipa.local&#39; \
  -K &#39;HTTP/f27-2.ipa.local@IPA.LOCAL&#39;
Resubmitting &quot;20171121073608&quot; to &quot;IPA&quot;.
[root@f27-2 ~]# sleep 5
[root@f27-2 ~]# getcert list -i 20171121073608 \
  | egrep &#39;status|error|issuer|subject&#39;
      status: MONITORING
      issuer: CN=IPA.LOCAL CA 2017.11.09
      subject: CN=f27-2.ipa.local,O=IPA.LOCAL 201711061603</code></pre>
<p>The renewal succeeded, proving that certificate issuance via the FreeIPA framework is working.</p>
<h2 id="checking-replica-health">Checking replica health</h2>
<p>At this point, I’m happy with the state of the FreeIPA server. But so far I have only dealt with one server in the topology (the renewal master, whose hostname is <code>f27-2.ipa.local</code>). What about other CA replicas?</p>
<p>I log onto <code>f27-1.ipa.local</code> (a CA replica). As a first step I execute <code>ipa-certupdate</code>. This failed in the same was as on the renewal master, and the steps to resolve were the same.</p>
<p>Next I tell Certmonger to renew the CA certificate. This should not renew the CA certificate, only retrieve the certificate from the LDAP certificate store:</p>
<pre><code>[root@f27-1 ~]# getcert list -i 20171106064548 \
  | egrep &#39;status|error|issuer|subject&#39;
        status: MONITORING
        issuer: CN=Certificate Authority,O=IPA.LOCAL 201711061603
        subject: CN=Certificate Authority,O=IPA.LOCAL 201711061603
[root@f27-1 ~]# getcert resubmit -i 20171106064548
Resubmitting &quot;20171106064548&quot; to &quot;dogtag-ipa-ca-renew-agent&quot;.
[root@f27-1 ~]# sleep 30
[root@f27-1 ~]# getcert list -i 20171106064548 | egrep &#39;status|error|issuer|subject&#39;
        status: MONITORING
        issuer: CN=Certificate Authority,O=IPA.LOCAL 201711061603
        subject: CN=Certificate Authority,O=IPA.LOCAL 201711061603</code></pre>
<p>Well, that did not work. Instead of retrieving the new CA certificate from LDAP, the CA replica issued a new certificate:</p>
<pre><code>[root@f27-1 ~]# certutil -d /etc/pki/pki-tomcat/alias -L \
    -n &#39;caSigningCert cert-pki-ca&#39;
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 268369927 (0xfff0007)
        Signature Algorithm: PKCS #1 SHA-256 With RSA Encryption
        Issuer: &quot;CN=Certificate Authority,O=IPA.LOCAL 201711061603&quot;
        Validity:
            Not Before: Tue Nov 21 08:18:09 2017
            Not After : Fri Nov 06 06:26:21 2037
        Subject: &quot;CN=Certificate Authority,O=IPA.LOCAL 201711061603&quot;
        ...</code></pre>
<p>This was caused by the first problem we faced when renewing the CA certificate with a new Subject DN. Once again, a mismatch between the Subject DN in the CSR and the FreeIPA CA’s Subject DN has confused the renewal helper.</p>
<p>The resolution in this case is to delete all the certificates with nickname <code>caSigningCert cert-pki-ca</code> or <code>IPA.LOCAl IPA CA</code> from Dogtag’s NSSDB then add the new CA certificate to the NSSDB. Then run <code>ipa-certupdate</code> again. Dogtag must not be running during this process:</p>
<pre><code>[root@f27-1 ~]# systemctl stop pki-tomcatd@pki-tomcat
[root@f27-1 ~]# cd /etc/pki/pki-tomcat/alias
[root@f27-1 ~]# certutil -d . -D -n &#39;caSigningCert cert-pki-ca&#39;
[root@f27-1 ~]# certutil -d . -D -n &#39;caSigningCert cert-pki-ca&#39;
[root@f27-1 ~]# certutil -d . -D -n &#39;caSigningCert cert-pki-ca&#39;
[root@f27-1 ~]# certutil -d . -D -n &#39;caSigningCert cert-pki-ca&#39;
certutil: could not find certificate named &quot;caSigningCert cert-pki-ca&quot;: SEC_ERROR_BAD_DATABASE: security library: bad database.
[root@f27-1 ~]# certutil -d . -D -n &#39;IPA.LOCAL IPA CA&#39;
[root@f27-1 ~]# certutil -d . -D -n &#39;IPA.LOCAL IPA CA&#39;
[root@f27-1 ~]# certutil -d . -D -n &#39;IPA.LOCAL IPA CA&#39;
certutil: could not find certificate named &quot;IPA.LOCAL IPA CA&quot;: SEC_ERROR_BAD_DATABASE: security library: bad database.
[root@f27-1 ~]# certutil -d . -A \
    -n &#39;caSigningCert cert-pki-ca&#39; -t &#39;CT,C,C&#39; &lt; /root/ipa-ca.pem
[root@f27-1 ~]# ipa-certupdate
trying https://f27-1.ipa.local/ipa/json
[try 1]: Forwarding &#39;ca_is_enabled&#39; to json server &#39;https://f27-1.ipa.local/ipa/json&#39;
[try 1]: Forwarding &#39;ca_find/1&#39; to json server &#39;https://f27-1.ipa.local/ipa/json&#39;
Systemwide CA database updated.
Systemwide CA database updated.
The ipa-certupdate command was successful
[root@f27-1 ~]# systemctl start pki-tomcatd@pki-tomcat</code></pre>
<p>Dogtag started without issue and I was able to issue a certificate via the <code>ipa cert-request</code> command on this replica.</p>
<h2 id="discussion">Discussion</h2>
<p>It took a while and required a lot of manual effort, but I reached the goal of changing the CA Subject DN. The deployment seems to be operational, although my testing was not exhaustive and there may be breakage that I did not find.</p>
<p>One of the goals was to define the process for both self-signed and externally-signed CAs. I did not deal with the externally-signed CA case. This article (and the process of writing it) was long enough without it! But much of the process, and problems encountered, will be the same.</p>
<p>There are some important concerns and caveats to be aware of.</p>
<p>First, CRLs generated after the Subject DN change may be bogus. They will be issued by the new CA but will contain serial numbers of revoked certificates that were issued by the old CA. Such assertions are invalid but not harmful in practice because those serial numbers will never be reused with the new CA. This is an implementation detail of Dogtag and not true in general.</p>
<p>But there is a bigger problem related to CRLs. After the CA name change, the old CA will never issue another CRL. This means that revoked certificates with the old Issuer DN will never again appear on a CRL issued by the old CA. Worse, the Dogtag OCSP responder errors when you query the status of a certificate with the old Issuer DN. In sum, this means that there is no way for Dogtag to revoke a certificate with the old Issuer DN. Because many systems <em>“fail open”</em> in the event of missing or invalid CRLs or OCSP errors, this is a potentially <strong>severe security issue</strong>.</p>
<p>Changing a FreeIPA installation’s CA Subject DN, whether by the procedure outlined in this post or by any other, is <strong>unsupported</strong>. If you try to do it and break your installation, we (the FreeIPA team) may try to help you recover, to a point. But we can’t guarantee anything. <em>Here be dragons</em> and all that.</p>
<p>If you think you need to change your CA Subject DN and have not read the <a href="2017-11-20-changing-ca-subject-dn-part-i.html">previous post</a> on this topic, please go and read it. It proposes some alternatives that, if applicable, avoid the messy process and security issues detailed here. Despite showing you how to change a FreeIPA installation’s CA Subject DN, my advice remains: <strong>don’t do it</strong>. I hope you will heed it.</p>]]></summary>
</entry>
<entry>
    <title>Changing a CA’s Subject DN; Part I: Don’t Do That</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2017-11-20-changing-ca-subject-dn-part-i.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2017-11-20-changing-ca-subject-dn-part-i.html</id>
    <published>2017-11-20T00:00:00Z</published>
    <updated>2017-11-20T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="changing-a-cas-subject-dn-part-i-dont-do-that">Changing a CA’s Subject DN; Part I: Don’t Do That</h1>
<p>When you deploy an X.509 certificate authority (CA), you choose a <em>Subject Distinguished Name</em> for that CA. It is sometimes abbreviated as <em>Subject DN</em>, <em>Subject Name</em>, <em>SDN</em> or just <em>Subject</em>.</p>
<p>The Subject DN cannot be changed; it is “for life”. But sometimes someone wants to change it anyway. In this article I’ll speculate why someone might want to change a CA’s Subject DN, discuss why it is problematic to do so, and propose some alternative approaches.</p>
<h2 id="what-is-the-subject-dn">What is the Subject DN?</h2>
<p>A distinguished name (DN) is a sequence of sets of name attribute types and values. Common attribute types include <em>Common Name (CN)</em>, <em>Organisation (O)</em>, <em>Organisational Unit (OU)</em>, <em>Country (C)</em> and so on. DNs are encoded in ASN.1, but have a well defined string representation. Here’s an example CA subject DN:</p>
<pre><code>CN=DigiCert Global Root CA,OU=www.digicert.com,O=DigiCert Inc,C=US</code></pre>
<p>All X.509 certificates contain an <em>Issuer DN</em> field and a <em>Subject DN</em> field. If the same value is used for both issuer and subject, it is a <em>self-signed certificate</em>. When a CA issues a certificate, the <em>Issuer DN</em> on the issued certificate shall be the <em>Subject DN</em> of the CA certificate. This relationship is a “link” in the chain of signatures from some <em>root CA</em> to <em>end entity</em> (or <em>leaf</em>) certificate.</p>
<p>The Subject DN uniquely identifies a CA. <strong>It is the CA</strong>. A CA can have multiple concurrent certificates, possibly with different public keys and key types. But if the Subject DN is the same, they are just different certificates for a single CA. Corollary: if the Subject DN differs, it is a different CA <em>even if the key is the same</em>.</p>
<h2 id="ca-subject-dn-in-freeipa">CA Subject DN in FreeIPA</h2>
<p>A standard installation of FreeIPA includes a CA. It can be a root CA or it can be signed by some other CA (e.g. the Active Directory CA of the organisation). As of FreeIPA v4.5 you can specify any CA Subject DN. Earlier versions required the subject to start with <code>CN=Certificate Authority</code>.</p>
<p>If you don’t explicitly specify the subject during installation, it defaults to <code>CN=Certificate Authority, O=EXAMPLE.COM</code> (replace <code>EXAMPLE.COM</code> with the actual realm name).</p>
<h2 id="why-change-the-ca-subject-dn">Why change the CA Subject DN?</h2>
<p>Why would someone want to change a CA’s Subject DN? Usually it is because there is some organisational or regulatory requirement for the Subject DN to have a particular form. For whatever reason the Subject DN doesn’t comply, and now they want to bring it into compliance. In the FreeIPA case, we often see that the default CA Subject DN was accepted, only to later realise that a different name is needed.</p>
<p>To be fair, the FreeIPA installer does not prompt for a CA Subject DN but rather uses the default form unless explicitly told otherwise via options. Furthermore, the CA Subject DN is not mentioned in the summary of the installation parameters prior to confirming and proceeding with the installation. And there are the aforementioned restrictions in FreeIPA &lt; v4.5. So in most cases where a FreeIPA administrator wants to change the CA Subject DN, it is not because <em>they chose</em> the wrong one, rather they were <em>not given an opportunity</em> to choose the right one.</p>
<h2 id="implications-of-changing-the-ca-subject-dn">Implications of changing the CA Subject DN</h2>
<p>In the X.509 data model the Subject DN is the essence of a CA. So what happens if we do change it? There are several areas of concern, and we will look at each in turn.</p>
<h3 id="certification-paths">Certification paths</h3>
<p>Normally when you renew a CA certificate, you don’t need to keep the old CA certificates around in your trust stores. If the new CA certificate is within its validity period you can just replace the old certificate, and everything will keep working.</p>
<p>But if you change the Subject DN, you need to keep the old certificate around, because previously issued certificates will bear the <em>old</em> Issuer DN. Conceptually this is not a problem, but many programs and libraries cannot cope with multiple subjects using the same key. In this case the only workaround is to reissue every certificate, with the new Issuer DN. This is a nightmare.</p>
<h3 id="crls">CRLs</h3>
<p>A <em>certificate revocation list</em> is a signed list of non-expired certificates that have been revoked. A CRL issuer is either the CA itself, or a trusted delegate. A CRL signing delegate has its own signing key and an X.509 certificate issued by the CA, which asserts that the subject is a CRL issuer. Like certificates, CRLs have an Issuer DN field.</p>
<p>So if the CA’s Subject DN changes, then CRLs issued by that CA must use the new name in the Issuer field. But recall that certificates are uniquely identified by the Issuer DN and Serial (think of this as a composite primary key). So if the CRL issuer changes (or the issuer of the CRL issuer), all the old revocation information is invalid. Now you must maintain two CRLs:</p>
<ul>
<li>One for the old CA Subject. Even after the name change, this CRL may grow as certificates that were issued using the old CA subject are revoked.</li>
<li>One for the new CA Subject. It will start off empty.</li>
</ul>
<p>If a CRL signing delegate is used, there is further complexity. You need two separate CRL signing certificates (one with the old Issuer DN, one with the new), and must</p>
<p>Suffice to say, a lot of CA programs do not handle these scenarios nicely or at all.</p>
<h3 id="ocsp">OCSP</h3>
<p>The <em>Online Certificate Status Protocol</em> is a protocol for checking the revocation status of a single certificate. Like CRLs, OCSP responses may be signed by the issuing CA itself, or a delegate.</p>
<p>As in the CRL delegation case, different OCSP delegates must be used depending on which DN was the Issuer of the certificate whose status is being checked. If performing direct OCSP signing, if identifying the Responder ID by name, then the old or new name would be included depending on the Issuer of the certificate.</p>
<h3 id="performing-the-change">Performing the change</h3>
<p>Most CA programs do not offer a way to change the Subject DN. This is not surprising, given that the operation just doesn’t fit into X.509 at all, to say nothing of the implementation considerations that arise.</p>
<p>It may be possible to change the CA Subject DN with some manual effort. In a follow-up post I’ll demonstrate how to change the CA Subject DN in a FreeIPA deployment.</p>
<h2 id="alternative-approaches">Alternative approaches</h2>
<p>I have outlined reasons why renaming a CA is a Bad Idea. So what other options are there?</p>
<p>Whether any of the follow options are viable depends on the use case or requirements. They might not be viable. If you have any other ideas about this I would love to have your feedback! So, let’s look at a couple of options.</p>
<h3 id="do-nothing">Do nothing</h3>
<p>If you only want to change the CA Subject DN for cosmetic reasons, don’t. Unless there is a clear business or organisational imperative, just accept the way things are. Your efforts would be better spent somewhere else, I promise!</p>
<h3 id="re-chaining-your-ca">Re-chaining your CA</h3>
<p>If there is a requirement for your <strong>root</strong> CA to have a Subject DN of a particular form, you could create a CA that satisfies the requirement somewhere else (e.g. a separate instance of Dogtag or even a standalone OpenSSL CA). Then you can <em>re-chain</em> your FreeIPA CA up to this new external CA. That is, you renew the CA certificate, but the issuer of the new IPA CA certificate is the new external CA.</p>
<p>The new external CA becomes a trusted root CA, and your FreeIPA infrastructure and clients continue to function as normal. The FreeIPA CA is now an <em>intermediate</em> CA. No certificates need to be reissued, although some server configurations may need to be updated to include the new FreeIPA CA in their certificate chains.</p>
<h3 id="subordinate-ca">Subordinate CA</h3>
<p>If certain end-entity certificates have to be issued by a CA whose Subject DN meets certain requirements, you could create a <em>subordinate CA</em> (or <em>sub-CA</em> for short) with a compliant name. That is, the FreeIPA CA issues an intermediate CA certificate with the desired Subject DN, and that CA issues the leaf certificates.</p>
<p>FreeIPA support Dogtag <em>lightweight sub-CAs</em> as of v4.4 and there are no restrictions on the Subject DN (except uniqueness). Dogtag lightweight CAs live within the same Dogtag instance as the main FreeIPA CA. See <code>ipa help ca</code> for plugin documentation. One major caveat is that CRLs are not yet supported for lightweight CAs (there is an <a href="https://pagure.io/dogtagpki/issue/1627">open ticket</a>).</p>
<p>You could also use the FreeIPA CA to issue a CA certificate for some other CA program (possible another deployment of Dogtag or FreeIPA).</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this post I explained what a CA’s Subject DN is, and how it is an integral part of how X.509 works. We discussed some of the conceptual and practical issues that arise when you change a CA’s Subject DN. In particular, path validation, CRLs and OCSP are affected, and a lot of software will break when encountering a “same key, different subject” scenario.</p>
<p>The general recommendation for changing a CA’s subject DN is <strong>don’t</strong>. But if there is a real business reason why the current subject is unsuitable, we looked at a couple of alternative approaches that could help: re-chaining the CA, and creating sub-CAs.</p>
<p>In my next post we will have an in-depth look how to change a FreeIPA CA’s Subject DN: how to do it, and how to deal with the inevitable breakage.</p>]]></summary>
</entry>
<entry>
    <title>Changing the X.509 signature algorithm in FreeIPA</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2017-11-10-freeipa-changing-signature-algorithm.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2017-11-10-freeipa-changing-signature-algorithm.html</id>
    <published>2017-11-10T00:00:00Z</published>
    <updated>2017-11-10T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="changing-the-x.509-signature-algorithm-in-freeipa">Changing the X.509 signature algorithm in FreeIPA</h1>
<p>X.509 certificates are an application of <em>digital signatures</em> for identity verification. TLS uses X.509 to create a <em>chain of trust</em> from a trusted CA to a service certificate. An X.509 certificate binds a public key to a <em>subject</em> by way of a secure and verifiable <em>signature</em> made by a <em>certificate authority (CA)</em>.</p>
<p>A signature algorithm has two parts: a public key signing algorithm (determined by the type of the CA’s signing key) and a <em>collision-resistant</em> hash function. The hash function <em>digests</em> the certified data into a small value that is hard to find collision for, which gets signed.</p>
<p>Computers keep getting faster and attacks on cryptography always get better. So over time older algorithms need to be deprecated, and newer algorithms adopted for use with X.509. In the past the MD5 and SHA-1 digests were often used with X.509, but today SHA-256 (a variant of SHA-2) is the most used algorithm. SHA-256 is also the weakest digest accepted by many programs (e.g. web browsers). Stronger variants of SHA-2 are widely supported.</p>
<p>FreeIPA currently uses the <code>sha256WithRSAEncryption</code> signature algorithm by default. Sometimes we get asked about how to use a stronger digest algorithm. In this article I’ll explain how to do that and discuss the motivations and implications.</p>
<h2 id="implications-of-changing-the-digest-algorithm">Implications of changing the digest algorithm</h2>
<p>Unlike re-keying or changing the CA’s Subject DN, re-issuing a certificate signed by the same key, but using a different digest, should Just Work. As long as a client knows about the digest algorithm used, it will be able to verify the signature. It’s fine to have a chain of trust that uses a variety of signature algorithms.</p>
<h2 id="configuring-the-signature-algorithm-in-freeipa">Configuring the signature algorithm in FreeIPA</h2>
<p>The signature algorithm is configured in each Dogtag certificate profile. Different profiles can use different signature algorithms. The public key signing algorithm depends on the CA’s key type (e.g. RSA) so you can’t change it; you can only change the digest used.</p>
<h3 id="modifying-certificate-profiles">Modifying certificate profiles</h3>
<p>Before FreeIPA 4.2 (RHEL 7.2), Dogtag stored certificate profile configurations as flat files. Dogtag 9 stores them in <code>/var/lib/pki-ca/profiles/ca</code> and Dogtag &gt;= 10 stores them in <code>/var/lib/pki/pki-tomcat/ca/profiles/ca</code>. When Dogtag is using file-based profile storage you must modify profiles on all CA replicas for consistent behaviour. After modifying a profile, Dogtag requires a restart to pick up the changes.</p>
<p>As of FreeIPA 4.2, Dogtag uses LDAP-based profile storage. Changes to profiles get replicated among the CA replicas, so you only need to make the change once. Restart is not required. The <code>ipa certprofile</code> plugin provides commands for importing, exporting and modifying certificate profiles.</p>
<p>Because of the variation among versions, I won’t detail the process of modifying profiles. We’ll look at what modifications to make, but skip over how to apply them.</p>
<h3 id="profile-configuration-changes">Profile configuration changes</h3>
<p>For service certificates, the profile to modify is <code>caIPAserviceCert</code>. If you want to renew the CA signing cert with a different algorithm, modify the <code>caCACert</code> profile. The relevant profile policy components are <code>signingAlgConstraintImpl</code> and <code>signingAlgDefaultImpl</code>. Look for these components in the profile configuration:</p>
<pre><code>policyset.serverCertSet.8.constraint.class_id=signingAlgConstraintImpl
policyset.serverCertSet.8.constraint.name=No Constraint
policyset.serverCertSet.8.constraint.params.signingAlgsAllowed=SHA1withRSA,SHA256withRSA,SHA512withRSA,MD5withRSA,MD2withRSA,SHA1withDSA,SHA1withEC,SHA256withEC,SHA384withEC,SHA512withEC
policyset.serverCertSet.8.default.class_id=signingAlgDefaultImpl
policyset.serverCertSet.8.default.name=Signing Alg
policyset.serverCertSet.8.default.params.signingAlg=-</code></pre>
<p>Update the <code>policyset.&lt;name&gt;.&lt;n&gt;.default.params.signingAlg</code> parameter; replace the <code>-</code> with the desired signing algorithm. (I set it to <code>SHA512withRSA</code>.) Ensure that the algorithm appears in the <code>policyset.&lt;name&gt;.&lt;n&gt;.constraint.params.signingAlgsAllowed</code> parameter (if not, add it).</p>
<p>After applying this change, certificates issued using the modified profile will use the specified algorithm.</p>
<h2 id="results">Results</h2>
<p>After modifying the <code>caIPAserviceCert</code> profile, we can renew the HTTP certificate and see that the new certificate uses <code>SHA512withRSA</code>. Use <code>getcert list</code> to find the Certmonger tracking request ID for this certificate. We find the tracking request in the output:</p>
<pre><code>...
Request ID &#39;20171109075803&#39;:
  status: MONITORING
  stuck: no
  key pair storage: type=NSSDB,location=&#39;/etc/httpd/alias&#39;,nickname=&#39;Server-Cert&#39;,token=&#39;NSS Certificate DB&#39;,pinfile=&#39;/etc/httpd/alias/pwdfile.txt&#39;
  certificate: type=NSSDB,location=&#39;/etc/httpd/alias&#39;,nickname=&#39;Server-Cert&#39;,token=&#39;NSS Certificate DB&#39;
  CA: IPA
  issuer: CN=Certificate Authority,O=IPA.LOCAL
  subject: CN=rhel69-0.ipa.local,O=IPA.LOCAL
  expires: 2019-11-10 07:53:11 UTC
  ...
...</code></pre>
<p>So the tracking request ID is <code>20171109075803</code>. Now resubmit the request:</p>
<pre><code>[root@rhel69-0 ca]# getcert resubmit -i 20171109075803
Resubmitting &quot;20171109075803&quot; to &quot;IPA&quot;.</code></pre>
<p>After a few moments, check the status of the request:</p>
<pre><code>[root@rhel69-0 ca]# getcert list -i 20171109075803
Number of certificates and requests being tracked: 8.
Request ID &#39;20171109075803&#39;:
  status: MONITORING
  stuck: no
  key pair storage: type=NSSDB,location=&#39;/etc/httpd/alias&#39;,nickname=&#39;Server-Cert&#39;,token=&#39;NSS Certificate DB&#39;,pinfile=&#39;/etc/httpd/alias/pwdfile.txt&#39;
  certificate: type=NSSDB,location=&#39;/etc/httpd/alias&#39;,nickname=&#39;Server-Cert&#39;,token=&#39;NSS Certificate DB&#39;
  CA: IPA
  issuer: CN=Certificate Authority,O=IPA.LOCAL
  subject: CN=rhel69-0.ipa.local,O=IPA.LOCAL
  expires: 2019-11-11 00:02:56 UTC
  ...</code></pre>
<p>We can see by the <code>expires</code> field that renewal succeeded. Pretty-printing the certificate shows that it is using the new signature algorithm:</p>
<pre><code>[root@rhel69-0 ca]# certutil -d /etc/httpd/alias -L -n &#39;Server-Cert&#39;
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 12 (0xc)
        Signature Algorithm: PKCS #1 SHA-512 With RSA Encryption
        Issuer: &quot;CN=Certificate Authority,O=IPA.LOCAL&quot;
        Validity:
            Not Before: Fri Nov 10 00:02:56 2017
            Not After : Mon Nov 11 00:02:56 2019
        Subject: &quot;CN=rhel69-0.ipa.local,O=IPA.LOCAL&quot;</code></pre>
<p>It is using SHA-512/RSA. Mission accomplished.</p>
<h2 id="discussion">Discussion</h2>
<p>In this article I showed how to configure the signing algorithm in a Dogtag certificate profile. Details about how to modify profiles in particular versions of FreeIPA was out of scope.</p>
<p>In the example I modified the default service certificate profile <code>caIPAserviceCert</code> to use <code>SHA512withRSA</code>. Then I renewed the HTTP TLS certificate to confirm that the configuration change had the intended effect. To change the signature algorithm on the FreeIPA CA certificate, you would modify the <code>caCACert</code> profile then renew the CA certificate. This would only work if the FreeIPA CA is <em>self-signed</em>. If it is externally-signed, it is up to the external CA what digest to use.</p>
<p>In FreeIPA version 4.2 and later, we support the addition of custom certificate profiles. If you want to use a different signature algorithm for a specific use case, instead of modifying the default profile (<code>caIPAserviceCert</code>) you might add a new profile.</p>
<p>The default signature digest algorithm in Dogtag is currently SHA-256. This is appropriate for the present time. There are few reasons why you would need to use something else. Usually it is because of an arbitrary security decision imposed on FreeIPA administrators. There are currently no plans to make the default signature algorithm configurable. But you can control the signature algorithm for a self-signed FreeIPA CA certificate via the <code>ipa-server-install</code> <code>--ca-signing-algorithm</code> option.</p>
<p>In the introduction I mentioned that the CA’s key type determines the public key signature algorithm. That was hand-waving; some key types support multiple signature algorithms. For example, RSA keys support two signature algorithms: <em>PKCS #1 v1.5</em> and <em>RSASSA-PSS</em>. The latter is seldom used in practice.</p>
<p>The SHA-2 family of algorithms (SHA-256, SHA-384 and SHA-512) are the “most modern” digest algorithms standardised for use in X.509 (<a href="https://tools.ietf.org/html/rfc4055#section-2.1">RFC 4055</a>). The Russian <em>GOST R</em> digest and signature algorithms are also supported (<a href="https://tools.ietf.org/html/rfc4491">RFC 4491</a>) although support is not widespread. In 2015 NIST published SHA-3 (based on the <em>Keccak</em> sponge construction). The use of SHA-3 in X.509 has not yet been standardised. There was an <a href="https://tools.ietf.org/html/draft-turner-lamps-adding-sha3-to-pkix-01">Internet-Draft in 2017</a>, but it expired. The current cryptanalysis of SHA-2 suggests there is no urgency to move to SHA-3. But it took a long time to move from SHA-1 (which is now insecure for applications requiring collision resistance) to SHA-2. Therefore it would be good to begin efforts to standardise SHA-3 in X.509 and add library/client support as soon as possible.</p>]]></summary>
</entry>
<entry>
    <title>Running Keycloak in OpenShift</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2017-09-04-keycloak-openshift.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2017-09-04-keycloak-openshift.html</id>
    <published>2017-09-04T00:00:00Z</published>
    <updated>2017-09-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="running-keycloak-in-openshift">Running Keycloak in OpenShift</h1>
<p>At PyCon Australia in August I gave a presentation about federated and social identity. I demonstrated concepts using <a href="http://www.keycloak.org/">Keycloak</a>, an Open Source, feature rich <em>identity broker</em>. Keycloak is deployed in JBoss, so I wasn’t excited about the prospect of setting up Keycloak from scratch. Fortunately there is an <a href="https://hub.docker.com/r/jboss/keycloak/">official Docker image</a> for Keycloak, so with that as the starting point I took an opportunity to finally learn about OpenShift v3, too.</p>
<p>This post is simply a recounting of how I ran Keycloak on OpenShift. Along the way we will look at how to get the containerised Keycloak to trust a private certificate authority (CA).</p>
<p>One thing that is not discussed is how to get Keycloak to persist configuration and user records to a database. This was not required for my demo, but it will be important in a production deployment. Nevertheless I hope this article is a useful starting point for someone wishing to deploy Keycloak on OpenShift.</p>
<h2 id="bringing-up-a-local-openshift-cluster">Bringing up a local OpenShift cluster</h2>
<p>To deploy Keycloak on OpenShift, one must first have an OpenShift. <a href="https://www.openshift.com/">OpenShift Online</a> is Red Hat’s public PaaS offering. Although running the demo on a public PaaS was my first choice, OpenShift Online was experiencing issues at the time I was setting up my demo. So I sought a local solution. This approach would have the additional benefit of not being subject to the whims of conference networks (or, it was supposed to - but that is a story for another day!)</p>
<h3 id="oc-cluster-up"><code>oc cluster up</code></h3>
<p>Next I tried <code>oc cluster up</code>. <code>oc</code> is the official OpenShift client program. On Fedora, it is provided by the <code>origin-clients</code> package. <code>oc cluster up</code> command pulls required images and brings up an OpenShift cluster running on the system’s Docker infrastructure. The command takes no further arguments; it really is that simple! Or is it…?</p>
<pre><code>% oc cluster up
-- Checking OpenShift client ... OK
-- Checking Docker client ... OK
-- Checking Docker version ... OK
-- Checking for existing OpenShift container ... OK
-- Checking for openshift/origin:v1.5.0 image ...
   Pulling image openshift/origin:v1.5.0
   Pulled 0/3 layers, 3% complete
   ...
   Pulled 3/3 layers, 100% complete
   Extracting
   Image pull complete
-- Checking Docker daemon configuration ... FAIL
   Error: did not detect an --insecure-registry argument on the Docker daemon
   Solution:

     Ensure that the Docker daemon is running with the following argument:
        --insecure-registry 172.30.0.0/16</code></pre>
<p>OK, so it is not that simple. But it got a fair way along, and (kudos to the OpenShift developers) they have provided actionable feedback about how to resolve the issue. I added <code>--insecure-registry 172.30.0.0/16</code> to the <code>OPTIONS</code> variable in <code>/etc/sysconfig/docker</code>, then restarted Docker and tried again:</p>
<pre><code>% oc cluster up
-- Checking OpenShift client ... OK
-- Checking Docker client ... OK
-- Checking Docker version ... OK
-- Checking for existing OpenShift container ... OK
-- Checking for openshift/origin:v1.5.0 image ... OK
-- Checking Docker daemon configuration ... OK
-- Checking for available ports ... OK
-- Checking type of volume mount ...
   Using nsenter mounter for OpenShift volumes
-- Creating host directories ... OK
-- Finding server IP ...
   Using 192.168.0.160 as the server IP
-- Starting OpenShift container ...
   Creating initial OpenShift configuration
   Starting OpenShift using container &#39;origin&#39;
   Waiting for API server to start listening
-- Adding default OAuthClient redirect URIs ... OK
-- Installing registry ... OK
-- Installing router ... OK
-- Importing image streams ... OK
-- Importing templates ... OK
-- Login to server ... OK
-- Creating initial project &quot;myproject&quot; ... OK
-- Removing temporary directory ... OK
-- Checking container networking ... OK
-- Server Information ... 
   OpenShift server started.
   The server is accessible via web console at:
       https://192.168.0.160:8443

   You are logged in as:
       User:     developer
       Password: developer

   To login as administrator:
       oc login -u system:admin</code></pre>
<p>Success! Unfortunately, on my machine with several virtual network, <code>oc cluster up</code> messed a bit too much with the routing tables, and when I deployed Keycloak on this cluster it was unable to communicate with my VMs. No doubt these issues could have been solved, but being short on time and with other approaches to try, I abandoned this approach.</p>
<h3 id="minishift"><em>Minishift</em></h3>
<p><a href="https://www.openshift.org/minishift/">Minishift</a> is a tool that launches a single-node OpenShift cluster in a VM. It supports a variety of operating systems and hypervisors. On GNU+Linux it supports KVM and VirtualBox.</p>
<p>First install <a href="https://github.com/docker/machine/releases">docker-machine</a> and <a href="https://github.com/dhiltgen/docker-machine-kvm/releases">docker-machine-driver-kvm</a>. (follow the instructions at the preceding links). Unfortunately these are not yet packaged for Fedora.</p>
<p>Download and extract the Minishift release for your OS from <a href="https://github.com/minishift/minishift/releases" class="uri">https://github.com/minishift/minishift/releases</a>.</p>
<p>Run <code>minishift start</code>:</p>
<pre><code>% ./minishift start
-- Installing default add-ons ... OK
Starting local OpenShift cluster using &#39;kvm&#39; hypervisor...
Downloading ISO &#39;https://github.com/minishift/minishift-b2d-iso/releases/download/v1.0.2/minishift-b2d.iso&#39;

... wait a while ...</code></pre>
<p>It downloads a <a href="http://boot2docker.io/"><em>boot2docker</em></a> VM image containing the openshift cluster, boots the VM, and the console output then resembles the output of <code>oc cluster up</code>. I deduce that <code>oc cluster up</code> is being executed on the VM.</p>
<p>At this point, we’re ready to go. Before I continue, it is important to note that once you have access to an OpenShift cluster, the user experience of creating and managing applications is essentially the same. The commands in the following sections are relevant, regardless whether you are running your app on OpenShift online, on a cluster running on your workstation, or anything in between.</p>
<h2 id="preparing-the-keycloak-image">Preparing the Keycloak image</h2>
<p>The JBoss project provides official Docker images, including an <a href="https://hub.docker.com/r/jboss/keycloak/">official Docker image</a> for Keycloak. This image runs fine in plain Docker but the directory permissions are not correct for running in OpenShift.</p>
<p>The <code>Dockerfile</code> for this image is found in the <a href="https://github.com/jboss-dockerfiles/keycloak"><em>jboss-dockerfiles/keycloak</em> repository</a> on GitHub. Although they do not publish an official image for it, this repository also contains a <code>Dockerfile</code> for Keycloak on OpenShift! I was able to build that image myself and upload it to <a href="https://hub.docker.com/r/frasertweedale/keycloak-openshift/">my <em>Docker Hub</em> account</a>. The steps were as follows.</p>
<p>First clone the <code>jboss-dockerfiles</code> repo:</p>
<pre><code>% git clone https://github.com/jboss-dockerfiles/keycloak docker-keycloak
Cloning into &#39;docker-keycloak&#39;...
remote: Counting objects: 1132, done.
remote: Compressing objects: 100% (22/22), done.
remote: Total 1132 (delta 14), reused 17 (delta 8), pack-reused 1102
Receiving objects: 100% (1132/1132), 823.50 KiB | 158.00 KiB/s, done.
Resolving deltas: 100% (551/551), done.
Checking connectivity... done.</code></pre>
<p>Next build the Docker image for OpenShift:</p>
<pre><code>% docker build docker-keycloak/server-openshift
Sending build context to Docker daemon 2.048 kB
Step 1 : FROM jboss/keycloak:latest
 ---&gt; fb3fc6a18e16
Step 2 : USER root
 ---&gt; Running in 21b672e19722
 ---&gt; eea91ef53702
Removing intermediate container 21b672e19722
Step 3 : RUN chown -R jboss:0 $JBOSS_HOME/standalone &amp;&amp;     chmod -R g+rw $JBOSS_HOME/standalone
 ---&gt; Running in 93b7d11f89af
 ---&gt; 910dc6c4a961
Removing intermediate container 93b7d11f89af
Step 4 : USER jboss
 ---&gt; Running in 8b8ccba42f2a
 ---&gt; c21eed109d12
Removing intermediate container 8b8ccba42f2a
Successfully built c21eed109d12</code></pre>
<p>Finally, tag the image into the repo and push it:</p>
<pre><code>% docker tag c21eed109d12 registry.hub.docker.com/frasertweedale/keycloak-openshift

% docker login -u frasertweedale registry.hub.docker.com
Password:
Login Succeeded

% docker push registry.hub.docker.com/frasertweedale/keycloak-openshift
... wait for upload ...
latest: digest: sha256:c82c3cc8e3edc05cfd1dae044c5687dc7ebd9a51aefb86a4bb1a3ebee16f341c size: 2623</code></pre>
<h3 id="adding-ca-trust">Adding CA trust</h3>
<p>For my demo, I used a local FreeIPA installation to issue TLS certificates for the the Keycloak app. I was also going to carry out a scenario where I configure Keycloak to use that FreeIPA installation’s LDAP server to authenticate users. I wanted to use TLS everywhere (eat your own dog food!) I needed the Keycloak application to trust the CA of one of my local FreeIPA installations. This made it necessary to build another Docker image based on the <code>keycloak-openshift</code> image, with the appropriate CA trust built in.</p>
<p>The content of the <code>Dockerfile</code> is:</p>
<pre><code>FROM frasertweedale/keycloak-openshift:latest
USER root
COPY ca.pem /etc/pki/ca-trust/source/anchors/ca.pem
RUN update-ca-trust
USER jboss</code></pre>
<p>The file <code>ca.pem</code> contains the CA certificate to add. It must be in the same directory as the <code>Dockerfile</code>. The build copies the CA certificate to the appropriate location and executes <code>update-ca-trust</code> to ensure that applications - including Java programs - will trust the CA.</p>
<p>Following the <code>docker build</code> I tagged the new image into my <code>hub.docker.com</code> repository (tag: <code>f25-ca</code>) and pushed it. And with that, we are ready to deploy Keycloak on OpenShift.</p>
<h2 id="creating-the-keycloak-application-in-openshift">Creating the Keycloak application in OpenShift</h2>
<p>At this point we have a local OpenShift cluster (via <em>Minishift</em>) and a Keycloak image (<code>frasertweedale/keycloak-openshift:f25-ca</code>) to deploy. When deploying the app we need to set some environment variables:</p>
<dl>
<dt><code>KEYCLOAK_USER=admin</code></dt>
<dd><p>A username for the Keycloak admin account to be created</p>
</dd>
<dt><code>KEYCLOAK_PASSWORD=secret123</code></dt>
<dd><p>Passphrase for the admin user</p>
</dd>
<dt><code>PROXY_ADDRESS_FORWARDING=true</code></dt>
<dd><p>Because the application will be running behind OpenShift’s HTTP proxy, we need to tell Keycloak to use the “external” hostname when creating hyperlinks, rather than Keycloak’s own view.</p>
</dd>
</dl>
<p>Use the <code>oc new-app</code> command to create and deploy the application:</p>
<pre><code>% oc new-app --docker-image frasertweedale/keycloak-openshift:f25-ca \
    --env KEYCLOAK_USER=admin \
    --env KEYCLOAK_PASSWORD=secret123 \
    --env PROXY_ADDRESS_FORWARDING=true
--&gt; Found Docker image 45e296f (4 weeks old) from Docker Hub for &quot;frasertweedale/keycloak-openshift:f25-ca&quot;

    * An image stream will be created as &quot;keycloak-openshift:f25-ca&quot; that will track this image
    * This image will be deployed in deployment config &quot;keycloak-openshift&quot;
    * Port 8080/tcp will be load balanced by service &quot;keycloak-openshift&quot;
      * Other containers can access this service through the hostname &quot;keycloak-openshift&quot;

--&gt; Creating resources ...
    imagestream &quot;keycloak-openshift&quot; created
    deploymentconfig &quot;keycloak-openshift&quot; created
    service &quot;keycloak-openshift&quot; created
--&gt; Success
    Run &#39;oc status&#39; to view your app.</code></pre>
<p>The app gets created immediately but it is not ready yet. The download of the image and deployment of the container (or <em>pod</em> in OpenShift / Kubernetes terminology) will proceed in the background.</p>
<p>After a little while (depending on how long it takes to download the ~300MB Docker image) <code>oc status</code> will show that the deployment is up and running:</p>
<pre><code>% oc status
In project My Project (myproject) on server https://192.168.42.214:8443

svc/keycloak-openshift - 172.30.198.217:8080
  dc/keycloak-openshift deploys istag/keycloak-openshift:f25-ca 
    deployment #2 deployed 3 minutes ago - 1 pod

View details with &#39;oc describe &lt;resource&gt;/&lt;name&gt;&#39; or list everything with &#39;oc get all&#39;.</code></pre>
<p>(In my case, the first deployment failed because the 10-minute timeout elapsed before the image download completed; hence <code>deployment #2</code> in the output above.)</p>
<h3 id="creating-a-secure-route">Creating a secure route</h3>
<p>Now the Keycloak application is running, but we cannot reach it from outside the Keycloak project itself. In order to be able to reach it there must be a <em>route</em>. The <code>oc create route</code> command lets us create a route that uses TLS (so clients can authenticate the service). We will use the domain name <code>keycloak.ipa.local</code>. The public/private keypair and certificate have already been generated (how to do that is outside the scope of this article). The certificate was signed by the CA we added to the image earlier. The service name - visible in the <code>oc status</code> output above - is <code>svc/keycloak-openshift</code>.</p>
<pre><code>% oc create route edge \
  --service svc/keycloak-openshift \
  --hostname keycloak.ipa.local \
  --key /home/ftweedal/scratch/keycloak.ipa.local.key \
  --cert /home/ftweedal/scratch/keycloak.ipa.local.pem
route &quot;keycloak-openshift&quot; created</code></pre>
<p>Assuming there is a DNS entry pointing <code>keycloak.ipa.local</code> to the OpenShift cluster, and that the system trusts the CA that issued the certificate, we can now visit our Keycloak application:</p>
<pre><code>% curl https://keycloak.ipa.local/
&lt;!--
  ~ Copyright 2016 Red Hat, Inc. and/or its affiliates
  ~ and other contributors as indicated by the @author tags.
  ~
  ~ Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
  ~ you may not use this file except in compliance with the License.
  ~ You may obtain a copy of the License at
  ~
  ~ http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  --&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;&gt;

&lt;html&gt;
&lt;head&gt;
    &lt;meta http-equiv=&quot;refresh&quot; content=&quot;0; url=/auth/&quot; /&gt;
    &lt;meta name=&quot;robots&quot; content=&quot;noindex, nofollow&quot;&gt;
    &lt;script type=&quot;text/javascript&quot;&gt;
        window.location.href = &quot;/auth/&quot;
    &lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
    If you are not redirected automatically, follow this &lt;a href=&#39;/auth&#39;&gt;link&lt;/a&gt;.
&lt;/body&gt;
&lt;/html&gt;</code></pre>
<p>If you visit in a browser, you will be able to log in using the admin account credentials specified in the <code>KEYCLOAK_USER</code> and <code>KEYCLOAK_PASSWORD</code> environment variables specified when the app was created. And from there you can create and manage authentication realms, but that is beyond the scope of this article.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this post I discussed how to run Keycloak in OpenShift, from bringing up an OpenShift cluster to building the Docker image and creating the application and route in OpenShift. I recounted that I found <em>OpenShift Online</em> unstable at the time I tried it, and that although <code>oc cluster up</code> did successfully bring up a cluster I had trouble getting the Docker and VM networks to talk to each other. Eventually I tried <em>Minishift</em> which worked well.</p>
<p>We saw that although there is no official Docker image for Keycloak in OpenShift, there is a <code>Dockerfile</code> that builds a working image. It is easy to further extend the image to add trust for private CAs.</p>
<p>Creating the Keycloak app in OpenShift, and adding the routes, is straightforward. There are a few important environment variables that must be set. The <code>oc create route</code> command was used to create a secure route to access the application from the outside.</p>
<p>We did not discuss how to set up Keycloak with a database for persisting configuration and user records. The deployment we created is ephemeral. This satisfied my needs for demonstration purposes but production deployments will require persistence. There are official JBoss Docker images that extend the base Keycloak image and add <a href="https://hub.docker.com/r/jboss/keycloak-postgres/">support for PostgreSQL</a>, <a href="https://hub.docker.com/r/jboss/keycloak-mysql/">MySQL</a> and <a href="https://hub.docker.com/r/jboss/keycloak-mongo/">MongoDB</a>. I have not tried these but I’d suggest starting with one of these images if you are looking to do a production deployment. Keep in mind that these images may not include the changes that are required for deploying in OpenShift.</p>]]></summary>
</entry>
<entry>
    <title>Installing FreeIPA with an Active Directory subordinate CA</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2017-08-14-ad-cs.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2017-08-14-ad-cs.html</id>
    <published>2017-08-14T00:00:00Z</published>
    <updated>2017-08-14T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="installing-freeipa-with-an-active-directory-subordinate-ca">Installing FreeIPA with an Active Directory subordinate CA</h1>
<p>FreeIPA is often installed in enterprise environments for managing Unix and Linux hosts and services. Most commonly, enterprises use Microsoft <em>Active Directory</em> for managing users, Windows workstations and Windows servers. Often, Active Directory is deployed with <em>Active Directory Certificate Services (AD CS)</em> which provides a CA and certificate management capabilities. Likewise, FreeIPA includes the <em>Dogtag</em> CA, and when deploying FreeIPA in an enterprise using AD CS, it is often desired to make the FreeIPA CA a subordinate CA of the AD CS CA.</p>
<p>In this blog post I’ll explain what is required to issue an AD sub-CA, and how to do it with FreeIPA, including a step-by-step guide to configuring AD CS.</p>
<h2 id="ad-cs-certificate-template-overview">AD CS certificate template overview</h2>
<p>AD CS has a concept of <em>certificate templates</em>, which define the characteristics an issued certificate shall have. The same concept exists in Dogtag and FreeIPA except that in those projects we call them <em>certificate profiles</em>, and the mechanism to select which template/profile to use when issuing a certificate is different.</p>
<p>In AD CS, the template to use is indicated by an X.509 extension in the certificate signing request (CSR). The template specifier can be one of two extensions. The first, older extension has OID <code>1.3.6.1.4.1.311.20.2</code> and allows you to specify a template by name:</p>
<pre><code>CertificateTemplateName ::= SEQUENCE {
   Name            BMPString
}</code></pre>
<p>(Note that some documents specify <code>UTF8String</code> instead of <code>BMPString</code>. <code>BMPString</code> works and is used in practice. I am not actually sure if <code>UTF8String</code> even works.)</p>
<p>The second, <em>Version 2</em> template specifier extension has OID <code>1.3.6.1.4.1.311.21.7</code> and allows you to specify a template by OID and version:</p>
<pre><code>CertificateTemplate ::= SEQUENCE {
    templateID              EncodedObjectID,
    templateMajorVersion    TemplateVersion,
    templateMinorVersion    TemplateVersion OPTIONAL
}

TemplateVersion ::= INTEGER (0..4294967295)</code></pre>
<p>Note that some documents also show <code>templateMajorVersion</code> as optional, but it is actually required.</p>
<p>When submitting a CSR for signing, AD CS looks for these extensions in the request, and uses the extension data to select the template to use.</p>
<h2 id="external-ca-installation-in-freeipa">External CA installation in FreeIPA</h2>
<p>FreeIPA supports installation with an externally signed CA certificate, via <code>ipa-server-install --external-ca</code> or (for existing CA-less installations <code>ipa-ca-install --external-ca</code>). The installation takes several steps. First, a key is generated and a CSR produced:</p>
<pre><code>$ ipa-ca-install --external-ca

Directory Manager (existing master) password: XXXXXXXX

Configuring certificate server (pki-tomcatd). Estimated time: 3 minutes
  [1/8]: configuring certificate server instance
The next step is to get /root/ipa.csr signed by your CA and re-run /sbin/ipa-ca-install as:
/sbin/ipa-ca-install --external-cert-file=/path/to/signed_certificate --external-cert-file=/path/to/external_ca_certificate</code></pre>
<p>The installation program exits while the administrator submits the CSR to the external CA. After they receive the signed CA certificate, the administrator resumes the installation, giving the installation program the CA certificate and a chain of one or more certificates up to the root CA:</p>
<pre><code>$ ipa-ca-install --external-cert-file ca.crt --external-cert-file ipa.crt
Directory Manager (existing master) password: XXXXXXXX

Configuring certificate server (pki-tomcatd). Estimated time: 3 minutes
  [1/29]: configuring certificate server instance
  ...
  [29/29]: configuring certmonger renewal for lightweight CAs
Done configuring certificate server (pki-tomcatd).</code></pre>
<p>Recall, however, that if the external CA is AD CS, a CSR must bear one of the certificate template specifier extensions. There is an additional installation program option to add the template specifier:</p>
<pre><code>$ ipa-ca-install --external-ca --external-ca-type=ms-cs</code></pre>
<p>This adds a <em>name-based</em> template specifier to the CSR, with the name <code>SubCA</code> (this is the name of the default sub-CA template in AD CS).</p>
<h2 id="specifying-an-alternative-ad-cs-template">Specifying an alternative AD CS template</h2>
<p>Everything discussed so far is already part of FreeIPA. Until now, there is no way to specify a different template to use with AD CS.</p>
<p>I have been working on a feature that allows an alternative AD CS template to be specified. Both kinds of template specifier extension are supported, via the new <code>--external-ca-profile</code> installation program option:</p>
<pre><code>$ ipa-ca-install --external-ca --external-ca-type=ms-cs \
  --external-ca-profile=1.3.6.1.4.1.311.21.8.8950086.10656446.2706058.12775672.480128.147.7130143.4405632:1</code></pre>
<p>(Note: huge OIDs like the above are commonly used by Active Directory for installation-specific objects.)</p>
<p>To specify a template by name, the <code>--external-ca-profile</code> value should be:</p>
<pre><code>--external-ca-profile=NAME</code></pre>
<p>To specify a template by OID, the OID and major version must be given, and optionally the minor version too:</p>
<pre><code>--external-ca-profile=OID:MAJOR[:MINOR]</code></pre>
<p>Like <code>--external-ca</code> and <code>--external-ca-type</code>, the new <code>--external-ca-profile</code> option is available with both <code>ipa-server-install</code> and <code>ipa-ca-install</code>.</p>
<p>With this feature, it is now possible to specify an alternative or custom certificate template when using AD CS to sign the FreeIPA CA certificate. The feature has not yet been merged but there an <a href="https://github.com/freeipa/freeipa/pull/930">open pull request</a>. I have also made a <a href="https://copr.fedorainfracloud.org/coprs/ftweedal/freeipa-adcs-template/">COPR build</a> for anyone interested in testing the feature.</p>
<p>The remainder of this post is a short guide to configuring Active Directory Certificate Services, defining a custom CA profile, and submitting a CSR to issue a certificate.</p>
<h2 id="renewing-the-certificate">Renewing the certificate</h2>
<p>FreeIPA provides the <code>ipa-cacert-manage renew</code> command for renewing an externally-signed CA certificate. Like installation with an externally-signed CA, this is a two-step procedure. In the first step, the command prompts Certmonger to generate a new CSR for the CA certificate, and saves the CSR so that the administrator can submit it to the external CA.</p>
<p>For renewing a certificate signed by AD CS, as in the installation case a template specifier extension is needed. Therefore the <code>ipa-cacert-manage renew</code> command has also learned the <code>--external-ca-profile</code> option:</p>
<pre><code># ipa-cacert-manage renew --external-ca-type ms-cs \
  --external-ca-profile MySubCA
Exporting CA certificate signing request, please wait
The next step is to get /var/lib/ipa/ca.csr signed by your CA and re-run ipa-cacert-manage as:
ipa-cacert-manage renew --external-cert-file=/path/to/signed_certificate --external-cert-file=/path/to/external_ca_certificate
The ipa-cacert-manage command was successful</code></pre>
<p>The the above example the CSR that was generated will contain a <em>version 1</em> template extension, using the name <code>MySubCA</code>. Like the installation commands, the <em>version 2</em> extension is also supported.</p>
<p>This part of the feature requires some changes to Certmonger as well as FreeIPA. At time of writing these changes haven’t been merged. There is a <a href="https://pagure.io/certmonger/pull-request/81">Certmonger pull request</a> and a <a href="https://copr.fedorainfracloud.org/coprs/ftweedal/certmonger-v2template/">Certmonger COPR build</a> if you’d like to test the feature.</p>
<h2 id="appendix-a-installing-and-configuring-ad-cs">Appendix A: installing and configuring AD CS</h2>
<p>Assuming an existing installation of Active Directory, AD CS installation and configuration will take 10 to 15 minutes. Open <strong>Server Manager</strong>, invoke the <strong>Add Roles and Features Wizard</strong> and select the AD CS <strong>Certification Authority</strong> role:</p>
<p><img src="../images/ms-ca/ms-ca-installation.png" alt="image" /></p>
<p>Proceed, and wait for the installation to complete…</p>
<p><img src="../images/ms-ca/ms-ca-installation-progress.png" alt="image" /></p>
<p>After installation has finished, you will see <strong>AD CS</strong> in the Server Manager sidebar, and upon selecting it you will see a notification that <strong>Configuration required for Active Directory Certificate Services</strong>.</p>
<p><img src="../images/ms-ca/ad-cs-configuration-required.png" alt="image" /></p>
<p>Click <strong>More…</strong>, and up will come the <strong>All Servers Task Details</strong> dialog showing that the <strong>Post-deployment Configuration</strong> action is pending. Click the action to continue:</p>
<p><img src="../images/ms-ca/ad-cs-post-deployment-configuration.png" alt="image" /></p>
<p>Now comes the <strong>AD CS Configuration</strong> assistant, which contains several steps. Proceed past the <strong>Specify credentials to configure role services</strong> step.</p>
<p>In the <strong>Select Role Services to configure</strong> step, select <strong>Certification Authority</strong> then continue:</p>
<p><img src="../images/ms-ca/ad-cs-post-deploy-2.png" alt="image" /></p>
<p>In the <strong>Specify the setup type of the CA</strong> step, choose <strong>Enterprise CA</strong> then continue:</p>
<p><img src="../images/ms-ca/ad-cs-post-deploy-3-enterprise.png" alt="image" /></p>
<p>The <strong>Specify the type of the CA</strong> step lets you choose whether the AD CS CA will be a root CA or chained to an external CA (just like how FreeIPA lets you create root or subordinate CA!) Installing AD CS as a Subordinate CA is outside the scope of this guide. Choose <strong>Root CA</strong> and continue:</p>
<p><img src="../images/ms-ca/ad-cs-post-deploy-4-root.png" alt="image" /></p>
<p>The next step lets you <strong>Specify the type of the private key</strong>. You can use an existing private key or <strong>Create a new private key</strong>, the continue.</p>
<p>The <strong>Specify the cryptographic options</strong> step lets you specify the <strong>Key length</strong> and <strong>hash algorithm</strong> for the signature. Choose a key length of at least <strong>2048</strong> bits, and the <strong>SHA-256</strong> digest:</p>
<p><img src="../images/ms-ca/ad-cs-post-deploy-6-algs.png" alt="image" /></p>
<p>Next, <strong>Specify the name of the CA</strong>. This sets the <em>Subject Distinguished Name</em> of the CA. Accept defaults and continue.</p>
<p>The next step is to <strong>Specify the validity period</strong>. CA certificates (especially root CAs) typically need a long validity period. Choose a value like <strong>5 Years</strong>, then continue:</p>
<p><img src="../images/ms-ca/ad-cs-post-deploy-8-validity.png" alt="image" /></p>
<p>Accept defauts for the <strong>Specify the database locations</strong> step.</p>
<p>Finally, you will reach the <strong>Confirmation</strong> step, which summarises the chosen configuration options. Review the settings then <strong>Configure</strong>:</p>
<p><img src="../images/ms-ca/ad-cs-post-deploy-10-confirmation.png" alt="image" /></p>
<p>The configuration will take a few moments, then the <strong>Results</strong> will be displayed:</p>
<p><img src="../images/ms-ca/ad-cs-post-deploy-11-done.png" alt="image" /></p>
<p>AD CS is now configured and you can begin issuing certificates.</p>
<h2 id="appendix-b-creating-a-custom-sub-ca-certificate-template">Appendix B: creating a custom sub-CA certificate template</h2>
<p>In this section we look at how to create a new <em>certificate template</em> for sub-CAs by duplicating an existing template, then modifying it.</p>
<p>To manage certificate templates, from <strong>Server Manager</strong> right-click the server and open the <strong>Certification Authority</strong> program:</p>
<p><img src="../images/ms-ca/ad-cs-manage-1-open.png" alt="image" /></p>
<p>In the sidebar tree view, <em>right-click</em> <strong>Certificate Templates</strong> then select <strong>Manage</strong>.</p>
<p><img src="../images/ms-ca/ad-cs-manage-2-templates.png" alt="image" /></p>
<p>The <strong>Certificate Templates Console</strong> will open. The default profile for sub-CAs has the Template Display Name <em>Subordinate Certification Authority</em>. <em>Right-click</em> this template and choose <strong>Duplicate Template</strong>.</p>
<p><img src="../images/ms-ca/ad-cs-manage-4-duplicate.png" alt="image" /></p>
<p>The new template is created and the <strong>Properties of New Template</strong> dialog appears, allowing the administrator to customise the template. You can set a new <strong>Template display name</strong>, <strong>Template name</strong> and so on:</p>
<p><img src="../images/ms-ca/ad-cs-manage-5-new-template.png" alt="image" /></p>
<p>You can also change various aspects of certificate issuance including which extensions will appear on the issued certificate, and the values of those extensions. In the following screenshot, we see a new <em>Certificate Policies</em> OID being defined for addition to certificates issued via this template:</p>
<p><img src="../images/ms-ca/ad-cs-manage-6-policy-ext.png" alt="image" /></p>
<p>Also under <strong>Extensions</strong>, you can discover the OID for this template by looking at the <strong>Certificate Template Information</strong> extension description.</p>
<p>Finally, having defined the new certificate template, we have to activate it for use with the AD CA. Back in the <strong>Certification Authority</strong> management window, <em>right-click</em> <strong>Certificate Templates</strong> and select <strong>Certificate Template to Issue</strong>:</p>
<p><img src="../images/ms-ca/ad-cs-manage-7-enable-template.png" alt="image" /></p>
<p>This will pop up the <strong>Enable Certificate Templates</strong> dialog, containing a list of templates available for use with the CA. Select the new template and click <strong>OK</strong>. The new certificate template is now ready for use.</p>
<h2 id="appendix-c-issuing-a-certificate">Appendix C: issuing a certificate</h2>
<p>In this section we look at how to use AD CS to issue a certificate. It is assumed that the CSR to be signed exists and Active Directory can access it.</p>
<p>In the <strong>Certification Authority</strong> window, in the sidebar <em>right-click</em> the CA and select <strong>All Tasks &gt;&gt; Submit new request…</strong>:</p>
<p><img src="../images/ms-ca/ad-cs-request-1-menu.png" alt="image" /></p>
<p>This will bring up a file chooser dialog. Find the CSR and <strong>Open</strong> it:</p>
<p><img src="../images/ms-ca/ad-cs-request-2-choose-csr.png" alt="image" /></p>
<p>Assuming all went well (including the CSR indicating a known certificate template), the certificate is immediately issued and the <strong>Save Certificate</strong> dialog appear, asking where to save the issued certificate.</p>]]></summary>
</entry>
<entry>
    <title>Implications of Common Name deprecation for Dogtag and FreeIPA</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2017-07-11-cn-deprecation.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2017-07-11-cn-deprecation.html</id>
    <published>2017-07-11T00:00:00Z</published>
    <updated>2017-07-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="implications-of-common-name-deprecation-for-dogtag-and-freeipa">Implications of Common Name deprecation for Dogtag and FreeIPA</h1>
<p>Or, <em><code>ERR_CERT_COMMON_NAME_INVALID</code>, and what we are doing about it.</em></p>
<p>Google Chrome version 58, released in April 2017, removed support for the X.509 certificate Subject <strong>Common Name (CN)</strong> as a source of naming information when validating certificates. As a result, certificates that do not carry all relevant domain names in the <strong>Subject Alternative Name</strong> (SAN) extension result in validation failures.</p>
<p>At the time of writing this post Chrome is just the first mover, but Mozilla Firefox and other programs and libraries will follow suit. The public PKI used to secure the web and other internet communiations is largely unaffected (browsers and CAs moved a long time ago to ensure that certificates issued by publicly trusted CAs carried all DNS naming information in the SAN extension), but some enterprises running internal PKIs are feeling the pain.</p>
<p>In this post I will provide some historical and technical context to the situation, and explain what we are are doing in Dogtag and FreeIPA to ensure that we issue valid certificates.</p>
<h2 id="background">Background</h2>
<p>X.509 certificates carry subject naming information in two places: the <strong>Subject Distinguished Name (DN)</strong> field, and the <strong>Subject Alternative Name</strong> extension. There are many types of attributes available in the DN, including <em>organisation</em>, <em>country</em>, and <em>common name</em>. The definitions of these attribute types came from X.500 (the precursor to LDAP) and all have an ASN.1 representation.</p>
<p>Within the X.509 standard, the CN has no special interpretation, but when certificates first entered widespread use in the SSL protocol, it was used to carry the domain name of the subject site or service. When connecting to a web server using TLS/SSL, the client would check that the CN matches the domain name they used to reach the server. If the certificate is chained to a trusted CA, the signature checks out, and the domain name matches, then the client has confidence that all is well and continues the handshake.</p>
<p>But there were a few problems with using the Common Name. First, what if you want a certificate to support multiple domain names? This was especially a problem for virtual hosts in the pre-<a href="https://en.wikipedia.org/wiki/Server_Name_Indication">SNI</a> days where one IP address could only have one certificate associated with it. You can have multiple CNs in a Distinguished Name, but the semantics of X.500 DNs is strictly heirarichical. It is not an appropriate use of the DN to cram multiple, possibly non-hierarchical domain names into it.</p>
<p>Second, the CN in X.509 has a length limit of 64 characters. DNS names can be longer. The length limit is too restrictive, especially in the world of IaaS and PaaS where hosts and services are spawned and destroyed <em>en masse</em> by orchestration frameworks.</p>
<p>Third, some types of subject names do not have a corresponding X.500 attribute, including domain names. The solution to all three of these problems was the introduction of the <em>Subject Alternative Name</em> X.509 extension, to allow more types of names to be used in a certificate. (The SAN extensions is itself extensible; apart from DNS names other important name types include IP addresses, email addresses, URIs and Kerberos principal names). TLS clients added support for validating SAN DNSName values in addition to the CN.</p>
<p>The use of the CN field to carry DNS names was never a standard. The Common Name field does not have these semantics; but using the CN in this way was an approach that worked. This interpretation was later formalised by the CA/B Forum in their <em>Baseline Requirements</em> for CAs, but only as a reflection of a current practice in SSL/TLS server and client implementations. Even in the Baseline Requirements the CN was a second-class citizen; they mandated that if the CN was present at all, it must reflect one of the DNSName or IP address values from the SAN extension. All public CAs had to comply with this requirement, which is why Chrome’s removal of CN support is only affecting private PKIs, not public web sites.</p>
<h2 id="why-remove-cn-validation">Why remove CN validation?</h2>
<p>So, Common Name was not ideal for carrying DNS naming information, but given that we now have SAN, was it really necessary to deprecate it, and is it really necessary to follow through and actually stop using it, causing non-compliant certificates that were previously accepted to now be rejected?</p>
<p>The most important reason for deprecating CN validation is the X.509 <strong>Name Constraints</strong> extension. Name Constraints, if they appear in a CA certificate or intermediate CA certificate, constrain the valid subject names on leaf certificates. Various name types are supported including DNS names; a DNS name constraint restricts the domain of validity to the domain(s) listed and subdomains thereof. For example, if the DNS name <code>example.com</code> appears in a CA certificate’s Name Constraints extension, leaf certificates with a DNS name of <code>example.com</code> or <code>foo.example.com</code> could be valid, but a DNS name of <code>foo.example</code><strong><code>.net</code></strong> could not be valid. Conforming X.509 implementations must enforce these constraints.</p>
<p>But these constraints only apply to SAN DNSName values, <strong>not to the CN</strong>. This is why accepting DNS naming information in the CN had to be deprecated - the name constraints cannot be properly enforced!</p>
<p>So back in May 2000 the use of Common Name for carrying a DNS name was <a href="https://tools.ietf.org/html/rfc2818#section-3.1">deprecated by RFC 2818</a>. Although it deprecated the practice this RFC <strong>required</strong> clients to fall back to the Common Name if there were no SAN DNSName values on the certificate. Then in 2011 <a href="https://tools.ietf.org/html/rfc6125#section-6.4.4">RFC 6125</a> removed the requirement for clients to fall back to the common name, making this optional behaviour. Over recent years, some TLS clients began emitting warnings when they encountered certificates without SAN DNSNames, or where a DNS name in the CN did not also appear in the SAN extension. Finally, Chrome has become the first widely used client to remove support.</p>
<p>Despite more than 15 years notice on the deprecation of this use of Common Name, a lot of CA software and client tooling still does not have first-class support for the SAN extension. Most tools used to generate CSRs do not even ask about SAN, and require complex configuration to generate a request bearing the SAN extension. Similarly, some CA programs does not do a good job of issuing RFC-compliant certificates. Right now, this includes Dogtag and FreeIPA.</p>
<h2 id="subject-alternative-name-and-freeipa">Subject Alternative Name and FreeIPA</h2>
<p>For some years, FreeIPA (in particular, the default profile for host and service certificates, called <code>caIPAserviceCert</code>) has supported the SAN extension, but the client is required to submit a CSR containing the desired SAN extension data. The names in the CSR (the CN and all alternative names) get validated against the subject principal, and then the CA would issue the certificate with exactly those names. There was no way to ensure that the domain name in the CN was also present in the SAN extension.</p>
<p>We could add this requirement to FreeIPA’s CSR validation routine, but this imposes an unreasonable burden on the user to “get it right”. Tools like OpenSSL have poor usability and complex configuration. Certmonger supports generating a CSR with the SAN extension but it must be explicitly requested. For FreeIPA’s own certificates, we have (in recent major releases) ensured that they have contained the SAN extension, but <em>this is not the default behaviour</em> and that is a problem.</p>
<p>FreeIPA 4.5 brought with it a <strong>CSR autogeneration</strong> feature that, for a given certificate profile, lets the administrator specify how to construct a CSR appropriate for that profile. This reduces the burden on the end user, but they must still opt in to this process.</p>
<h2 id="subject-alternative-name-and-dogtag">Subject Alternative Name and Dogtag</h2>
<p>Until Dogtag 10.4, there were two ways to produce a certificate with the SAN extension. One was the <code>SubjectAltNameExtDefault</code> profile component, which, for a given profile, supports a fixed number of names, either hard coded or based on particular request attributes (e.g. the CN, the email address of the authenticated user, etc). The other was the <code>UserExtensionDefault</code> which copies a given extension from the CSR to the final certificate verbatim (no validation of the data occurs). We use <code>UserExtensionDefault</code> in FreeIPA’s certificate profile (all names are validated by the FreeIPA framework before the request is submitted to Dogtag).</p>
<p>Unfortunately, <code>SubjectAltNameExtDefault</code> and <code>UserExtensionDefault</code> are not compatible with each other. If a profile uses both and the CSR contains the SAN extension, issuance will fail with an error because Dogtag tried to add two SAN extensions to the certificate.</p>
<p>In Dogtag 10.4 we introduced a new profile component that improves the situation, especially for dealing with the removal of client CN validation. The <code>CommonNameToSANDefault</code> will cause any profile that uses it to examine the Common Name, and if it looks like a DNS name, it will add it to the SAN extension (creating the extension if necessary).</p>
<p>Ultimately, what is needed is a way to define a certificate profile that just makes the right certificate, without placing an undue burden on the client (be it a human user or a software agent). The complexity and burden should rest with Dogtag, for the sake of all users. We are gradually making steps toward this, but it is still a long way off. I have discussed this utopian vision <a href="2015-11-04-freeipa-pki-future.html">in a previous post</a>.</p>
<h2 id="configuring-commonnametosandefault">Configuring <code>CommonNameToSANDefault</code></h2>
<p>If you have Dogtag 10.4, here is how to configure a profile to use the <code>CommonNameToSANDefault</code>. Add the following policy directives (the <code>policyset</code> and <code>serverCertSet</code> and index <code>12</code> are indicative only, but the index must not collide with other profile components):</p>
<pre><code>policyset.serverCertSet.12.constraint.class_id=noConstraintImpl
policyset.serverCertSet.12.constraint.name=No Constraint
policyset.serverCertSet.12.default.class_id=commonNameToSANDefaultImpl
policyset.serverCertSet.12.default.name=Copy Common Name to Subject</code></pre>
<p>Add the index to the list of profile policies:</p>
<pre><code>policyset.serverCertSet.list=1,2,3,4,5,6,7,8,9,10,11,12</code></pre>
<p>Then import the modified profile configuration, and you are good to go. There are a few minor caveats to be aware of:</p>
<ul>
<li>Names containing wildcards are not recognised as DNS names. The rationale is twofold; wildcard DNS names, although currently recognised by most programs, are technically a violation of the X.509 specification (RFC 5280), and they are <a href="https://tools.ietf.org/html/rfc6125#section-7.2">discouraged by RFC 6125</a>. Therefore if the CN contains a wildcard DNS name, <code>CommonNameToSANDefault</code> will not copy it to the SAN extension.</li>
<li>Single-label DNS names are not copied. It is unlikely that people will use Dogtag to issue certificates for top-level domains. If <code>CommonNameToSANDefault</code> encounters a single-label DNS name, it will assume it is actually not a DNS name at all, and will not copy it to the SAN extension.</li>
<li>The <code>CommonNameToSANDefault</code> policy index must come after <code>UserExtensionDefault</code>, <code>SubjectAltNameExtDefault</code>, or any other component that adds the SAN extension, otherwise an error may occur because the older components do not gracefully handle the situation where the SAN extension is already present.</li>
</ul>
<h2 id="what-we-are-doing-in-freeipa">What we are doing in FreeIPA</h2>
<p>Updating FreeIPA profiles to use <code>CommonNameToSANDefault</code> is trickier - FreeIPA configures Dogtag to use LDAP-based profile storage, and mixed-version topologies are possible, so updating a profile to use the new component could break certificate requests on other CA replicas if they are not all at the new versions. We do not want this situation to occur.</p>
<p>The long-term fix is to develop a general, version-aware profile update mechanism that will import the best version of a profile supported by all CA replicas in the topology. I will be starting this effort soon. When it is in place we will be able to safely update the FreeIPA-defined profiles in existing deployments.</p>
<p>In the meantime, we will bump the Dogtag dependency and update the default profile <strong>for new installations only</strong> in the <strong>4.5.3</strong> point release. This will be safe to do because you can only install replicas at the same or newer versions of FreeIPA, and it will avoid the CN validation problems for all new installations.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this post we looked at the technical reasons for deprecating and removing support for CN domain validation in X.509 certificates, and discussed the implications of this finally happening, namely: none for the public CA world, but big problems for some private PKIs and programs including FreeIPA and Dogtag. We looked at the new <code>CommonNameToSANDefault</code> component in Dogtag that makes it easier to produce compliant certs even when the tools to generate the CSR don’t help you much, and discussed upcoming and proposed changes in FreeIPA to improve the situation there.</p>
<p>One big takeaway from this is to be more proactive in dealing with deprecated features in standards, APIs or programs. It is easy to punt on the work, saying <em>“well yes it is deprecated but all the programs still support it…”</em> The thing is, tomorrow they may not support it anymore, and when it was deprecated for good reasons you really cannot lay the blame at Google (or whoever). On the FreeIPA team we (and especially me as <em>PKI wonk in residence</em>) were aware of these issues but kept putting off the work. Then one day users and customers start having problems accessing their internal services in Chrome! 15 years should have been enough time to deal with it… but we (I) did not.</p>
<p>Lesson learned.</p>]]></summary>
</entry>
<entry>
    <title>Wildcard SAN certificates in FreeIPA</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2017-06-26-freeipa-wildcard-san.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2017-06-26-freeipa-wildcard-san.html</id>
    <published>2017-06-26T00:00:00Z</published>
    <updated>2017-06-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="wildcard-san-certificates-in-freeipa">Wildcard SAN certificates in FreeIPA</h1>
<p>In <a href="2017-02-20-freeipa-wildcard-certs.html">an earlier post</a> I discussed how to make a certificate profile for wildcard certificates in FreeIPA, where the wildcard name appeared in the <em>Subject Common Name (CN)</em> (but not the <em>Subject Alternative Name (SAN)</em> extension). Apart from the technical details that post also explained that wildcard certificates are deprecated, <em>why</em> they are deprecated, and therefore why I was not particularly interested in pursuing a way to get wildcard DNS names into the SAN extension.</p>
<p>But, as was portended long ago (more than 15 years, when <a href="https://tools.ietf.org/html/rfc2818">RFC 2818</a> was published) DNS name assertions via the CN field are deprecated, and finally some client software removed CN name processing support. The Chrome browser is first off the rank, but it won’t be the last!</p>
<p>Unfortunately, programs that have typically used wildcard certificates (hosting services/platforms, PaaS, and sites with many subdomains) are mostly still using wildcard certificates, and FreeIPA still needs to support these programs. As much as I would like to say “just use <em>Let’s Encrypt</em> / ACME!”, it is not realistic for all of these programs to update in so short a time. Some may never be updated. So for now, wildcard DNS names in SAN is more than a “nice to have” - it is a <strong>requirement</strong> for a handful of valid use cases.</p>
<h2 id="configuration">Configuration</h2>
<p>Here is how to do it in FreeIPA. Most of the steps are the same as in <a href="2017-02-20-freeipa-wildcard-certs.html">the earlier post</a> so I will not repeat them here. The only substantive difference is in the Dogtag profile configuration.</p>
<p>In the profile configuration, set the following directives (note that the key <code>serverCertSet</code> and the index <code>12</code> are indicative only; the index does not matter as long as it is different from the other profile policy components):</p>
<pre><code>policyset.serverCertSet.12.constraint.class_id=noConstraintImpl
policyset.serverCertSet.12.constraint.name=No Constraint
policyset.serverCertSet.12.default.class_id=subjectAltNameExtDefaultImpl
policyset.serverCertSet.12.default.name=Subject Alternative Name Extension Default
policyset.serverCertSet.12.default.params.subjAltNameNumGNs=2
policyset.serverCertSet.12.default.params.subjAltExtGNEnable_0=true
policyset.serverCertSet.12.default.params.subjAltExtType_0=DNSName
policyset.serverCertSet.12.default.params.subjAltExtPattern_0=*.$request.req_subject_name.cn$
policyset.serverCertSet.12.default.params.subjAltExtGNEnable_1=true
policyset.serverCertSet.12.default.params.subjAltExtType_1=DNSName
policyset.serverCertSet.12.default.params.subjAltExtPattern_1=$request.req_subject_name.cn$</code></pre>
<p>Also be sure to add the index to the directive containing the list of profile policies:</p>
<pre><code>policyset.serverCertSet.list=1,2,3,4,5,6,7,8,9,10,11,12</code></pre>
<p>This configuration will cause two SAN DNSName values to be added to the certificate - one using the CN from the CSR, and the other using the CN from the CSR preceded by a wildcard label.</p>
<p>Finally, be aware that because the <code>subjectAltNameExtDefaultImpl</code> component adds the SAN extension to a certificate, it conflicts with the <code>userExtensionDefault</code> component when configured to copy the SAN extension from a CSR to the new certificate. This profile component will have a configuration like the following:</p>
<pre><code>policyset.serverCertSet.11.constraint.class_id=noConstraintImpl
policyset.serverCertSet.11.constraint.name=No Constraint
policyset.serverCertSet.11.default.class_id=userExtensionDefaultImpl
policyset.serverCertSet.11.default.name=User Supplied Extension Default
policyset.serverCertSet.11.default.params.userExtOID=2.5.29.17</code></pre>
<p>Again the numerical index is indicative only, but the OID is not; <code>2.5.29.17</code> is the OID for the SAN extension. If your starting profile configuration contains the same directives, <strong>remove them</strong> from the configuration, and remove the index from the policy list too:</p>
<pre><code>policyset.serverCertSet.list=1,2,3,4,5,6,7,8,9,10,12</code></pre>
<h2 id="discussion">Discussion</h2>
<p>The profile containing the configuration outlined above will issue certificates with a wildcard DNS name in the SAN extension, alongside the DNS name from the CN. Mission accomplished; but note the following caveats.</p>
<p>This configuration cannot contain the <code>userExtensionDefaultImpl</code> component, which copies the SAN extension from the CSR to the final certificate if present in the CSR, because any CSR that contains a SAN extension would cause Dogtag to attempt to add a second SAN extension to the certificate (this is an error). It would be better if the conflicting profile components somehow “merged” the SAN values, but this is not their current behaviour.</p>
<p>Because we are not copying the SAN extension from the CSR, any SAN extension in the CSR get ignored by Dogtag - <em>but not by FreeIPA</em>; the FreeIPA CSR validation machinery always fully validates the subject alternative names it sees in a CSR, regardless of the Dogtag profile configuration.</p>
<p>If you work on software or services that currently use wildcard certificates please start planning to move away from this. CN validation was deprecated for a long time and is finally being phased out; <strong>wildcard certificates are also deprecated</strong> (<a href="https://tools.ietf.org/html/rfc6125#section-7.2">RFC 6125</a>) and they too may eventually be phased out. Look at services and technologies like <em>Let’s Encrypt</em> (a free, automated, publicly trusted CA) and <em>ACME</em> (the protocol that powers it) for acquiring all the certificates you need without administrator or operator intervention.</p>]]></summary>
</entry>
<entry>
    <title>Supporting large key sizes in FreeIPA certificates</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2017-03-21-freeipa-8192-bit-certs.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2017-03-21-freeipa-8192-bit-certs.html</id>
    <published>2017-03-21T00:00:00Z</published>
    <updated>2017-03-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="supporting-large-key-sizes-in-freeipa-certificates">Supporting large key sizes in FreeIPA certificates</h1>
<p>A couple of issues around key sizes in FreeIPA certificates have come to my attention this week: how to issue certificates for large key sizes, and how to deploy FreeIPA with a 4096-bit key. In this post I’ll discuss the situation with each of these issues. Though related, they are different issues so I’ll address each separately.</p>
<h2 id="issuing-certificates-with-large-key-sizes">Issuing certificates with large key sizes</h2>
<p>While researching the second issue I stumbled across issue <a href="https://pagure.io/freeipa/issue/6319">#6319: ipa cert-request limits key size to 1024,2048,3072,4096 bits</a>. To wit:</p>
<pre><code>ftweedal% ipa cert-request alice-8192.csr --principal alice
ipa: ERROR: Certificate operation cannot be completed:
  Key Parameters 1024,2048,3072,4096 Not Matched</code></pre>
<p>The solution is straightforward. Each certificate profile configures the key types and sizes that will be accepted by that profile. The default profile is configured to allow up to 4096-bit keys, so the certificate request containing an 8192-bit key fails. The profile configuration parameter involved is:</p>
<pre><code>policyset.&lt;name&gt;.&lt;n&gt;.constraint.params.keyParameters=1024,2048,3072,4096</code></pre>
<p>If you append <code>8192</code> to that list and update the profile configuration via <code>ipa certprofile-mod</code> (or create a new profile via <code>ipa certprofile-import</code>), then everything will work!</p>
<h2 id="deploying-freeipa-with-ipa-ca-signing-key-2048-bits">Deploying FreeIPA with IPA CA signing key &gt; 2048-bits</h2>
<p>When you deploy FreeIPA today, the IPA CA has a 2048-bit RSA key. There is currently no way to change this, but Dogtag does support configuring the key size when spawning a CA instance, so it should not be hard to support this in FreeIPA. I created issue <a href="https://pagure.io/freeipa/issue/6790">#6790</a> to track this.</p>
<p>Looking beyond RSA, there is also issue <a href="https://pagure.io/freeipa/issue/3951">#3951: ECC Support for the CA</a> which concerns supporting a elliptic curve signing key in the FreeIPA CA. Once again, Dogtag supports EC signing algorithms, so supporting this in FreeIPA should be a matter of deciding the <code>ipa-server-install(1)</code> options and mechanically adjusting the <code>pkispawn</code> configuration.</p>
<p>If you have use cases for large signing keys and/or NIST ECC keys or other algorithms, please do not hesitate to leave comments in the issues linked above, or get in touch with the FreeIPA team on the <code>freeipa-users@lists.fedorahosted.org</code> mailing list or <code>#freeipa</code> on Freenode.</p>]]></summary>
</entry>

</feed>
