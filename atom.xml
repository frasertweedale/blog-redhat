<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Fraser's IdM Blog</title>
    <link href="https://frasertweedale.github.io/blog-redhat/atom.xml" rel="self" />
    <link href="https://frasertweedale.github.io/blog-redhat" />
    <id>https://frasertweedale.github.io/blog-redhat/atom.xml</id>
    <author>
        <name>Fraser Tweedale</name>
        <email>frase@frase.id.au</email>
    </author>
    <updated>2020-11-05T00:00:00Z</updated>
    <entry>
    <title>OpenShift and user namespaces</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2020-11-05-openshift-user-namespace.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2020-11-05-openshift-user-namespace.html</id>
    <published>2020-11-05T00:00:00Z</published>
    <updated>2020-11-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="openshift-and-user-namespaces">OpenShift and user namespaces</h1>
<p>FreeIPA in its current form is very much not a “cloud native” application. Likewise the current FreeIPA container, which runs all the required services under Systemd. My current team is working on operationalising FreeIPA for the OpenShift container platform. Our initial efforts are focused around this “monolithic” container, trying to get it to run in OpenShift, securely. Although we recognise we may eventually need to split up the container, it will be a major engineering effort. We want to have a working proof of concept as early as possible, so that we (and others) can start the important integration work (e.g. with Keycloak / RHSSO).</p>
<p>This “lift and shift” of a complex traditional application to OpenShift results in a container that needs to run several processes as a variety of users, including <code>root</code>. OpenShift isolates containers (actually pods, which consist of one or more containers) in their own PID namespace. This is good, but if we are to run container processes as <code>root</code> (in the container), we do not want them to also be <code>root</code> on the host. Rather, they should map to an unprivileged account. If we want secure multitenancy of multiple IDM servers on a single worker node, we want the user accounts on different IDM pods to map to disjoint sets of unprivileged users on the host.</p>
<p>Linux <code>user_namespaces(7)</code> provide this kind of isolation. To what extend are user namespaces supported in OpenShift? We needed to find out, in order to decide how to proceed with the FreeIPA OpenShift effort. In this blog post I discuss my investigation and findings.</p>
<h2 id="investigating-current-openshift-behaviour">Investigating current OpenShift behaviour</h2>
<p>To investigate the use (or not) of user namespaces I deployed pods on our team’s OpenShift cluster and ran commands as various users, observing the effects on the worker node.</p>
<p>As cluster admin, I created a new project:</p>
<pre><code>% oc new-project test
Now using project &quot;test&quot; on server &quot;https://api.permanent.idmocp.lab.eng.rdu2.redhat.com:6443&quot;.
...</code></pre>
<p>To avoid the cluster admin user’s SCC applying to pod creation, I created a user <code>test</code> and granted it the <em>project</em> <code>admin</code> role. Subsequent pod creation operations will be performed as <code>test</code>.</p>
<pre><code>% oc create user test
user.user.openshift.io/test created

% oc adm policy add-role-to-user admin test
clusterrole.rbac.authorization.k8s.io/admin added: &quot;test&quot;</code></pre>
<p>Next I deployed a basic pod (as user <code>test</code>) and inspected it to find out which worker node it was scheduled on, and the CRI-O conatiner ID:</p>
<pre><code>% cat pod-test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: test
spec:
  containers:
  - name: idm-test
    image: freeipa/freeipa-server:fedora-31
    command: [&quot;sleep&quot;, &quot;3600&quot;]

% oc --as test create -f pod-test.yaml
pod/test created

% oc get -o json pod test \
    | jq .spec.nodeName
&quot;permanent-bdd7p-worker-9r4b6&quot;

% oc get -o json pod test \
    | jq &quot;.status.containerStatuses[0].containerID&quot;
&quot;cri-o://a9c0cf0ac9c0c352b82a74cccf830dfa8c33aae28138808eb7bdd9d53aae2d1f&quot;</code></pre>
<p>Next, opening a debug shell on the worker node I inspected the container to find out the PID:</p>
<pre><code>% oc debug node/permanent-bdd7p-worker-9r4b6
Starting pod/permanent-bdd7p-worker-9r4b6-debug ...
To use host binaries, run `chroot /host`
Pod IP: 10.8.3.215
If you don&#39;t see a command prompt, try pressing enter.
sh-4.2# chroot /host
sh-4.4# crictl inspect a9c0cf0ac | jq .pid
1311115</code></pre>
<p>Next I looked at which user the process is running under, and the UID map of the process:</p>
<pre><code>sh-4.4# ls -l -d /proc/1311115
dr-xr-xr-x. 9 1000620000 root 0 Nov  5 05:34 /proc/1311115

sh-4.4# cat /proc/1311115/uid_map
         0          0 4294967295</code></pre>
<p>The process was running as user <code>1000620000</code>, and UID map has an offset of <code>0</code> and a size of <code>2^32</code>. Which is to say, this process is running in the same user namespace as the host. We can use the <code>lsns</code> command to confirm that everything on this node–including all container processes–is sharing the single user namespace:</p>
<pre><code>sh-4.4# lsns -t user
        NS TYPE  NPROCS PID USER COMMAND
4026531837 user     296   1 root /usr/lib/systemd/systemd --switched-root --system --deserialize 18</code></pre>
<p>As a result, if we use <code>runAsUser</code> to specify a different user under which to run the container, the container will run as the specified user both in the container <strong>and on the host</strong>. The following transcript demonstrates this.</p>
<p>Delete the pod <code>test</code>:</p>
<pre><code>% oc delete pod test
pod &quot;test&quot; deleted</code></pre>
<p>Add the <code>anyuid</code> SCC to user <code>test</code>:</p>
<pre><code>% oc adm policy add-scc-to-user anyuid test
securitycontextconstraints.security.openshift.io/anyuid added to: [&quot;test&quot;]</code></pre>
<p>Create the pod (as user <code>test</code>):</p>
<pre><code>% oc --as test create -f pod-test.yaml
pod/test created</code></pre>
<p>Following the same procedure as earlier, find the PID (<code>1381728</code>) and observe that it is running as <code>root</code> (UID <code>0</code>) on the host:</p>
<pre><code>sh-4.4# ls -l -d /proc/1381728
dr-xr-xr-x. 9 root root 0 Nov  5 05:55 /proc/1381728</code></pre>
<h2 id="consequences-for-freeipa">Consequences for FreeIPA</h2>
<p>Traditional applications sometimes assume they will run as <code>root</code> or some other “reserved” user. FreeIPA is such a case. Likewise, running Systemd in a container means running as UID 0 (from the container’s point of view).</p>
<p>The lack of user namespace use in OpenShift means that for a process to run under a particular UID in the container, it must run as that user on the host too. If you application needs to be <code>root</code>, it will be <code>root</code> on the host. Other kinds of namespaces (e.g. <code>pid</code>, <code>mnt</code>, <code>uts</code> among others) do mitigate the security risk. But if a rogue process can escalate privileges and escape the other sandbox(es) the result could be catastrophic.</p>
<p>FreeIPA, being composed of many components, some of which are large complex projects in their own right, and several of which are implemented in C or leverage C libraries, has a large attack surface. In the absense of user namespaces the risk of container host or co-tenant compromise—even by accident—seems high.</p>
<p>This all assumes that containers do not have user namespace isolation and that FreeIPA continues to require running processes in the FreeIPA container as fixed UIDs (probably including <code>root</code>). I will now discuss possible ways to eliminate these assumptions.</p>
<h2 id="user-namespace-support-in-kubernetes">User namespace support in Kubernetes</h2>
<p>OpenShift is built on the Kubernetes container platform. <em>Kubernetes Enhancement Proposal</em> <a href="https://github.com/kubernetes/enhancements/issues/127">KEP-127</a> proposes user namespace support. The ticket has been open for 4 years and has since seen several efforts to formalise the proposal, the most recent of which is <a href="https://github.com/kubernetes/enhancements/pull/2101">kubernetes/enhancements#2101</a> (<a href="https://github.com/kubernetes/enhancements/blob/9726c1a4cc5051d8be7eaf4cb64313df60ae8751/keps/sig-node/127-usernamespaces-support/README.md">rendered</a>). There have also been several experimental implementations (e.g. <a href="https://github.com/kubernetes/kubernetes/pull/55707">#55707</a>, <a href="https://github.com/kubernetes/kubernetes/pull/64005">#64005</a>), none of which was accepted (yet).</p>
<p>There has been a recent resurgence of interest and activity on this KEP, and related discussions and pull requests. But that has happened before. I believe that every new (or resurrected) discussion or experiment can move you closer to the goal, and that there can be several false starts before things happen. Maybe this time it will happen? But maybe not.</p>
<p>Right now there is no final proposal and no implementation plan. As a team we cannot proceed on the assumption that Kubernetes will support user namespaces. We will certainly present our case to OpenShift engineering internally at Red Hat, but we have to look at other options.</p>
<h2 id="user-namespace-support-in-cri-o">User namespace support in CRI-O</h2>
<p>The <a href="https://cri-o.io/">CRI-O</a> container runtime <a href="https://github.com/cri-o/cri-o/pull/3944">recently implemented</a> support for running each pod in a separate user namespace, via <em>annotations</em> on the pod, e.g.:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb11-1"><a href="#cb11-1"></a><span class="fu">apiVersion</span><span class="kw">:</span><span class="at"> v1</span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="fu">kind</span><span class="kw">:</span><span class="at"> Pod</span></span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="fu">metadata</span><span class="kw">:</span></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="at">  </span><span class="fu">annotations</span><span class="kw">:</span></span>
<span id="cb11-5"><a href="#cb11-5"></a><span class="at">    </span><span class="fu">io.kubernetes.cri-o.userns-mode</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;auto&quot;</span></span>
<span id="cb11-6"><a href="#cb11-6"></a><span class="fu">spec</span><span class="kw">:</span></span>
<span id="cb11-7"><a href="#cb11-7"></a><span class="at">  ...</span></span></code></pre></div>
<p>Using annotations means that no explicit support in Kubernetes is required. All that is required is that Kubernetes is using the CRI-O container runtime, and CRI-O is configured to enable this feature. OpenShift 4.x does use CRI-O, so we’re halfway there. The remaining step is to enable the feature in <code>crio.conf</code>:</p>
<pre><code>allow_userns_annotation = true</code></pre>
<p>The developer Giuseppe Scrivano kindly published a <a href="https://asciinema.org/a/351396">screencast showing the feature in action</a> (2 minutes). This feature is not yet in a supported release but is available on the v1.20 branch and is included in OpenShift <a href="">nightly builds</a>.</p>
<h2 id="splitting-the-freeipa-container">Splitting the FreeIPA container</h2>
<p>If Kubernetes or CRI-O user namespace support to does not solve our problem (in our desired timeframe) then there is more pressure to abandon the monolithic container and devote our efforts to a “split-service” FreeIPA/IDM application. In this scenario, the various services that make up FreeIPA (LDAP, KDC, HTTP, CA and others) would each run as an unprivileged process in its own container.</p>
<p>This would be a big engineering effort. Apart from FreeIPA as a whole, most of the constituent services are also “traditional” applications that make assumptions about their environment and execution context. Assumptions that do not hold in the OpenShift container paradigm.</p>
<p>There is a general (albeit unevenly distributed) feeling in the team that in the long run this effort is inevitable. I do hold this view myself, but also recognise that the sooner we can have a working proof of concept, the better. That is the main reason we are initially pursuing the monolithic container approach.</p>
<h2 id="next-steps">Next steps</h2>
<p>My next step will be to install an OpenShift cluster based on the nightly builds (which include CRI-O v1.20) and experiment with the annotation-based user namespace support. It seems to be what we want, or a big step in the right direction, but we need to confirm it. Expect a follow-up to this article with my findings, hopefully in the next week!</p>]]></summary>
</entry>
<entry>
    <title>Issuing certificates for long hostnames</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2020-10-20-ipa-cert-long-hostname.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2020-10-20-ipa-cert-long-hostname.html</id>
    <published>2020-10-20T00:00:00Z</published>
    <updated>2020-10-20T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="issuing-certificates-for-long-hostnames">Issuing certificates for long hostnames</h1>
<p>X.509, specified in <a href="https://tools.ietf.org/html/rfc5280">RFC 5280</a>, restricts the length of the <em>Common Name (CN)</em> attribute to 64 characters:</p>
<pre><code>X520CommonName ::= DirectoryName (SIZE (1..ub-common-name))
ub-common-name-length INTEGER ::= 64</code></pre>
<p>Although the use of the CN attribute to carry DNS names is deprecated, it is still common practice. Furthermore, FreeIPA still requires the CN to appear in a <em>Certificate Signing Request (CSR)</em> and validates that its value corresponds to the nominated <em>subject principal</em>.</p>
<p>As a consequence of this restriction, when a host or service has a DNS name longer than 64 characters, that name cannot be used as the CN. But it can still be included in the <em>Subject Alternative Name</em> extension, as a <em>dNSName</em> value.</p>
<p>How do we issue such a certificate in FreeIPA? The trick is to add a <em>principal alias</em> whose hostname is 64 characters or shorter. This shorter hostname will be the Common Name attribute value. The full hostname will appear in the Subject Alternative Name extension.</p>
<p>The following sections demonstrate the method. I conclude with an outline of what needs to be done to support certificates with empty Subject DN, which would avoid the problem and this workaround.</p>
<h2 id="creating-a-principal-with-a-long-hostname">Creating a principal with a long hostname</h2>
<p>To experiment and verify the workaround, I needed a principal with a hostname longer than 64 characters. The initial attempt failed:</p>
<pre><code>% ipa host-add --force \
    verylongverylongverylongverylongverylongverylonghostname.ipa.local
ipa: ERROR: invalid &#39;hostname&#39;: can be at most 64 characters</code></pre>
<p>FreeIPA has a default maximum hostname length of 64 characters, but this is configurable. After adjusting the limit, adding the host succeeded:</p>
<pre><code>% ipa config-mod --maxhostname 255
  Maximum username length: 32
  Maximum hostname length: 255
  ...

% ipa host-add --force \
    verylongverylongverylongverylongverylongverylonghostname.ipa.local
-------------------------------------------------------------------------------
Added host &quot;verylongverylongverylongverylongverylongverylonghostname.ipa.local&quot;
-------------------------------------------------------------------------------
  Host name: verylongverylongverylongverylongverylongverylonghostname.ipa.local
  Principal name: host/verylongverylongverylongverylongverylongverylonghostname.ipa.local@IPA.LOCAL
  Principal alias: host/verylongverylongverylongverylongverylongverylonghostname.ipa.local@IPA.LOCAL
  ...</code></pre>
<h2 id="adding-the-principal-alias">Adding the principal alias</h2>
<p>For a host principal, use the <code>ipa host-add-principal</code> command to add a principal alias. The alias must also be a host principal, i.e. must have the form <code>host/$hostname</code>:</p>
<pre><code>% ipa host-add-principal \
    verylongverylongverylongverylongverylongverylonghostname.ipa.local \
    host/longhostname.ipa.local
----------------------------------------------------------------------------------------------
Added new aliases to host &quot;verylongverylongverylongverylongverylongverylonghostname.ipa.local&quot;
----------------------------------------------------------------------------------------------
Host name: verylongverylongverylongverylongverylongverylonghostname.ipa.local
Principal alias: host/verylongverylongverylongverylongverylongverylonghostname.ipa.local@IPA.LOCAL,
                 host/longhostname.ipa.local@IPA.LOCAL</code></pre>
<p>For a service principal, use the <code>ipa service-add-principal</code> command. Ensure the principal alias has the same service type as the subject principal’s <em>canonical name</em> (i.e. the value its <code>krbcanonicalname</code> attribute). For example, if the canonical principal name is <code>HTTP/$LONGHOSTNAME</code>, then the principal alias should be <code>HTTP/$SHORTHOSTNAME</code>.</p>
<p>I omitted the realm parts of principal names (the default realm will be added automatically). For the avoidance of doubt, the princpial alias must have the same realm as the canonical principal.</p>
<h2 id="creating-a-csr">Creating a CSR</h2>
<p>There are many different ways to create a CSR. I will give a single example using OpenSSL. The private key already exists (file <code>key.pem</code>).</p>
<p>The configuration file:</p>
<pre><code>% cat longhostname.conf
[ req ]
prompt = no
encrypt_key = no

distinguished_name = dn
req_extensions = exts

[ dn ]
commonName = &quot;longhostname.ipa.local

[ exts ]
subjectAltName=DNS:verylongverylongverylongverylongverylongverylonghostname.ipa.local</code></pre>
<p>Create the CSR:</p>
<pre><code>% openssl req -new -key key.pem \
    -config longhostname.conf -extensions exts \
    &gt; longhostname.csr</code></pre>
<h2 id="issuing-the-certificate">Issuing the certificate</h2>
<p>Now we can issue the certificate:</p>
<pre><code>% ipa cert-request longhostname.csr \
    --principal host/verylongverylongverylongverylongverylongverylonghostname.ipa.local
  Issuing CA: ipa
  Certificate: MIIE...
  Subject: CN=longhostname.ipa.local,O=IPA.LOCAL 202009291726
  Subject DNS name: verylongverylongverylongverylongverylongverylonghostname.ipa.local,
                    longhostname.ipa.local
  Issuer: CN=Certificate Authority,O=IPA.LOCAL 202009291726
  Not Before: Mon Oct 19 13:46:16 2020 UTC
  Not After: Thu Oct 20 13:46:16 2022 UTC
  Serial number: 11
  Serial number (hex): 0xB</code></pre>
<p>The CN attribute contains the shorter host name, and the SAN extension contains both the long and shorter hostnames. (We did not include the short hostname in the CSR SAN extension, but the <code>CommonNameToSANDefault</code> profile component copied it there).</p>
<h2 id="supporting-san-only-certificates">Supporting SAN-only certificates</h2>
<p>This workaround is straightforward but it is not the ideal solution. A better approach is to enhance FreeIPA and Dogtag to support issuing certificates with an empty Subject DN, using only the Subject Alternative Name extension to carry subject information.</p>
<p>RFC 5280 allows an empty Subject DN in a certificate, in which case the certificate must include the SAN extension, which must be marked as <em>critical</em>. <a href="https://tools.ietf.org/html/rfc6125#section-2.3">RFC 6125</a> further clarifies that such a certificate is acceptable for use with TLS.</p>
<p><a href="https://pagure.io/freeipa/issue/5706">Upstream ticket #5706</a> requests support for SAN-only certificates. The work will involve:</p>
<ul>
<li>Change the <code>ipa cert-request</code> command to accept empty subjects. When the subject is empty ensure a non-empty SAN extension is present in the CSR, and that it is marked criticial. This is straightforward.</li>
<li>On the Dogtag side we must implement new behaviour in the request processor to ensure that the certificate to be issued satisfies the X.509 requirements about empty/non-empty Subject DN and the presence and criticality of the SAN extension.</li>
<li>It may be necessary to define a new profile default or constraint component that allows an empty subject DN.</li>
<li>It is likely that FreeIPA will need to either modify the default profile (<code>caIPAserviceCert</code>) to allow for an empty Subject DN, or ship a separate profile that is suitable.</li>
</ul>]]></summary>
</entry>
<entry>
    <title>Dogtag, number ranges and VLV indices</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2020-09-17-dogtag-vlv-corruption.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2020-09-17-dogtag-vlv-corruption.html</id>
    <published>2020-09-17T00:00:00Z</published>
    <updated>2020-09-17T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="dogtag-number-ranges-and-vlv-indices">Dogtag, number ranges and VLV indices</h1>
<p>In a <a href="2019-07-26-dogtag-replica-ranges.html">previous post</a> I explained Dogtag’s identifier range management. This is how a Dogtag replica knows what range it should use to assign serial numbers, request IDs, etc. What that article did not cover is how Dogtag at startup works out <em>where it is up to</em> in the range. In this post I explain how uses LDAP <em>Virtual List View</em> to do that, how it can break, and how to fix it.</p>
<h2 id="ldap-virtual-list-view">LDAP Virtual List View</h2>
<p>The LDAP protocol has an optional extension called <em>Virtual List View (VLV)</em>, which is specified in an <a href="https://datatracker.ietf.org/doc/draft-ietf-ldapext-ldapv3-vlv/">expired Internet-Draft</a>. VLV supports result <em>paging</em> and is an extension of the <em>Server Side Sort (SSS)</em> control (<a href="https://tools.ietf.org/html/rfc2891">RFC 2891</a>). For a search that is covered by a VLV index, a client can specify a page size and offset and get just that portion of the result. It can also seek a specified attribute value and return nearby results.</p>
<p>In 389DS / RHDS, a VLV index is defined by two objects under <code>cn=config</code>. One of the VLV indices used in Dogtag is the search of all certificates sorted by serial number:</p>
<pre class="ldif"><code>dn: cn=allCerts-pki-tomcat,
    cn=ipaca, cn=ldbm database, cn=plugins, cn=config
objectClass: top
objectClass: vlvSearch
cn: allCerts-pki-tomcat
vlvBase: ou=certificateRepository,ou=ca,o=ipaca
vlvScope: 1
vlvFilter: (certstatus=*)

dn: cn=allCerts-pki-tomcatIndex, cn=allCerts-pki-tomcat,
    cn=ipaca, cn=ldbm database, cn=plugins, cn=config
objectClass: top
objectClass: vlvIndex
cn: allCerts-pki-tomcatIndex
vlvSort: serialno
vlvEnabled: 0
vlvUses: 0</code></pre>
<p>The first object defines the search base and filter. When performing a VLV search, these <strong>must match</strong>. The second object declares which attribute is the sort key. To perform a VLV search the client must use both the SSS control (which chooses the sort key) and the VLV control (which selects the page or the value of interest).</p>
<h2 id="dogtag-range-initialisation">Dogtag range initialisation</h2>
<p>When Dogtag is starting up, for each active identifier range it has to determine the first unused number. It uses VLV searches to do this. For serial numbers, it uses the VLV index shown above. For request IDs and other ranges, there are other indices. The VLV search targets the upper limit of the range, and requests the preceding values. It then looks for the highest value in the result that is also within the active range. This is the last number that was used; we increment it to get the next available number.</p>
<p>To make it a bit more concrete, we can perform a VLV search ourselves using <code>ldapsearch</code>:</p>
<pre><code># ldapsearch -LLL -D &quot;cn=Directory Manager&quot; -w $DM_PASS \
    -b ou=certificateRepository,ou=ca,o=ipaca -s one \
    -E &#39;sss=serialno&#39; -E &#39;vlv=1/0:09267911168&#39; \
    &#39;(certStatus=*)&#39; 1.1
dn: cn=397,ou=certificateRepository,ou=ca,o=ipaca

dn: cn=267911185,ou=certificateRepository,ou=ca,o=ipaca

# sortResult: (0) Success
# vlvResultpos=2 count=177 context= (0) Success</code></pre>
<p>In this search the target value (end of the active range) is <code>09267911168</code>. This is the integer <code>267911168</code> preceded by a two-digit length value. This is needed because the <code>serialno</code> attribute has <code>Directory String</code> syntax, which is sorted lexicographically. The <code>1/0</code> part of the control is asking for one value preceding the target value, and zero values following it.</p>
<p>The result contains two objects: <code>397</code> (which precedes the target) and <code>267911185</code> (which follows it). Why did we get a number following the target value? The target entry is the first entry whose sort attribute value is <em>greater than or equal</em> the target value. In this way, results greater than the target can appear in the result, as happened here.</p>
<p>The search above relates to the range <code>1..267911168</code>. The result shows us to initialise the repository with <code>397</code> as the “last used” number. The next certificate issued by this replica will have serial number <code>398</code>.</p>
<h2 id="vlv-index-corruption">VLV index corruption</h2>
<p>If a VLV index is corrupt or incomplete, Dogtag could initialise a repository with a too-low “last used” number. This could happen for serial numbers, request IDs or any other kind of managed range. When that happens, CA operations including certificate issuance or CSR submission could fail.</p>
<p>In fact, the <code>ldapsearch</code> above is from a customer case. A full search of the <code>ou=certificateRepository</code> showed thousands of certificates that were not included in the VLV index. If CA operations are failing due to LDAP “Object already exists” errors, you can perform this check to confirm or rule out VLV index corruption as the source of the problem. Keep in mind that VLV indices are maintained separately on each replica. Checks have to be performed on the replica where the problem is occurring.</p>
<h2 id="rebuilding-vlv-indices">Rebuilding VLV indices</h2>
<p>389DS makes it easy to rebuild a VLV index. You create a <em>task</em> object and the DS takes care of it. For Dogtag, we even provide a template LDIF file for a task that reindexes <em>all</em> the VLV indices that Dogtag creates and uses.</p>
<p>First, copy and fill the template:</p>
<pre><code>$ /bin/cp /usr/share/pki/ca/conf/vlvtasks.ldif .
$ sed -i &quot;s/{instanceId}/pki-tomcat/g&quot; vlvtasks.ldif
$ sed -i &quot;s/{database}/ipaca/g&quot; vlvtasks.ldif</code></pre>
<p>Note that <code>{database}</code> should be replaced with <code>ipaca</code> in a FreeIPA instance, but for a standalone Dogtag deployment the correct value is usually <code>ca</code>. Now let’s look at the LDIF file:</p>
<pre class="ldif"><code>dn: cn=index1160589769, cn=index, cn=tasks, cn=config
objectclass: top
objectclass: extensibleObject
cn: index1160589769
ttl: 10
nsinstance: ipaca
nsindexVLVAttribute: allCerts-pki-tomcatIndex
# ... 33 more nsindexVLVAttribute values</code></pre>
<p>The <code>cn</code> is just a name for the task. I think you can put anything here. <code>ttl</code> specifies how many seconds 389DS will wait after the task finishes, before deleting it.</p>
<p>This task object refers to VLV indices in the Dogtag database. But you can see all that is needed to rebuild <em>any</em> VLV index is the <code>nsinstance</code> (name of the database) and the <code>nsindexVLVAttribute</code> (name of a VLV index).</p>
<p>Now we add the object, wait a few seconds, and have a look at it:</p>
<pre><code>$ ldapadd -x -D &quot;cn=Directory Manager&quot; -w $DM_PASS \
    -f vlvtasks.ldif
$ sleep 5
$ ldapsearch -x -D &quot;cn=Directory Manager&quot; -w $DM_PASS \
  -b &quot;cn=index1160589769,cn=index,cn=tasks,cn=config&quot;</code></pre>
<pre class="ldif"><code>dn: cn=index1160589769,cn=index,cn=tasks,cn=config
objectClass: top
objectClass: extensibleObject
cn: index1160589769
ttl: 10
nsinstance: ipaca
nsindexvlvattribute: allCerts-pki-tomcatIndex
# .. 33 more nsindexvlvattribute values
nsTaskCurrentItem: 0
nsTaskTotalItems: 1
nsTaskCreated: 20200916021128Z
nsTaskLog:: aXBhY2E6IEluZGV4aW #... (base64-encoded log)
nsTaskStatus: ipaca: Finished indexing.
nsTaskExitCode: 0</code></pre>
<p>We can see that the task finished successfully, and there is some (truncated) log output if we want more details. After a few more seconds, 389DS will delete the object. You can increase the <code>ttl</code> if you want to keep the objects for longer.</p>
<h2 id="discussion">Discussion</h2>
<p>This year I have encountered variations of this problem on several occasions. I don’t know what the cause(s) are, i.e. why VLV indices get corrupted or stop updating. Hopefully DS experts will be able to shed more light on the issue.</p>
<p>We are considering adding an automated check to the FreeIPA <em>Health Check</em> system, specifically for the range management VLVs. The <a href="">GitHub ticket</a> already contains some discussion and high level steps of how the check would work.</p>
<p>The proper fix for this issue is to move to UUIDs for all object identifiers. Serial numbers might need something different but it is the same idea. This work is on the roadmap. <em>So many problems</em> will go away when we make this change.</p>
<p>Historical commentary: I don’t know why the <code>serialno</code>, <code>requestId</code> and other attributes use Directory String syntax, which necessitates the length prefixing hack. Maybe SSS/VLV only work on strings (or it was thus in the past). The code predates our current VCS and the reasons are lost in time. The implication of this is that we can only handle numbers up to 99 decimal digits. Assumptions like this do bother me, but I think we are probably OK here. For my lifetime, anyway.</p>]]></summary>
</entry>
<entry>
    <title>Dynamic volume provisioning with OpenShift storage classes</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2020-08-13-openshift-storage-classes.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2020-08-13-openshift-storage-classes.html</id>
    <published>2020-08-13T00:00:00Z</published>
    <updated>2020-08-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="dynamic-volume-provisioning-with-openshift-storage-classes">Dynamic volume provisioning with OpenShift storage classes</h1>
<p>For containerised applications that require persistent storage, the Kubernetes <code>PersistentVolumeClaim</code> (PVC) object provides the link between a <code>PersistentVolume</code> (PV) and the pod. When scaling such an application or even deploying it the first time, the operator (human or otherwise) has to create the PVC; the pod specification can then refer to it.</p>
<p>For example, a <code>StatefulSet</code> object can optionally specify <code>volumeClaimTemplates</code> alongside the pod <code>template</code>. As the application creates pods, so will it create the associated PVCs according to the defined templates.</p>
<p>But PVCs need PVs to bind to. Can these also be created on the fly? And if so, how can we abstract over the details of the underlying storage provider(s), which may vary from cluster to cluster? In this post I provide an overview of <em>storage classes</em>, which solve these problems.</p>
<h2 id="creating-volumes">Creating volumes</h2>
<p>A cluster can provide a variety of types of volumes: Ceph, NFS, <code>hostPath</code>, iSCSI and several more. Storage types of the infrastructure the cluster is deployed in may also be available, e.g. AWS EBS, Azure Disk, GCE PersistentDisk (PD), Cinder (OpenStack), etc.</p>
<p>Creating a <code>PersistentVolume</code> requires knowing about what volume types are supported, and possibly additional details about that storage type. For example, to create a PV based on a GCE PD:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb1-1"><a href="#cb1-1"></a><span class="fu">apiVersion</span><span class="kw">:</span><span class="at"> v1</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="fu">kind</span><span class="kw">:</span><span class="at"> PersistentVolume</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu">metadata</span><span class="kw">:</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="at">  </span><span class="fu">name</span><span class="kw">:</span><span class="at"> pv-test</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="fu">spec</span><span class="kw">:</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="at">  </span><span class="fu">capacity</span><span class="kw">:</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="at">    </span><span class="fu">storage</span><span class="kw">:</span><span class="at"> 100Gi</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="at">  </span><span class="fu">accessModes</span><span class="kw">:</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="at">  </span><span class="kw">-</span><span class="at"> ReadWriteOnce</span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="at">  </span><span class="fu">gcePersistentDisk</span><span class="kw">:</span></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="at">    </span><span class="fu">pdName</span><span class="kw">:</span><span class="at"> my-data-disk</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="at">    </span><span class="fu">fsType</span><span class="kw">:</span><span class="at"> ext4</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="at">  </span><span class="fu">nodeAffinity</span><span class="kw">:</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="at">    </span><span class="fu">required</span><span class="kw">:</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="at">      </span><span class="fu">nodeSelectorTerms</span><span class="kw">:</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="at">      </span><span class="kw">-</span><span class="at"> </span><span class="fu">matchExpressions</span><span class="kw">:</span></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="fu">key</span><span class="kw">:</span><span class="at"> failure-domain.beta.kubernetes.io/zone</span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="at">          </span><span class="fu">operator</span><span class="kw">:</span><span class="at"> In</span></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="at">          </span><span class="fu">values</span><span class="kw">:</span></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="at">          </span><span class="kw">-</span><span class="at"> us-central1-a</span></span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="at">          </span><span class="kw">-</span><span class="at"> us-central1-b</span></span></code></pre></div>
<p>Creating this PV required:</p>
<ul>
<li>knowing that the cluster provides the GCE PD volume type</li>
<li>knowing the name and region/zones of the PD to use</li>
</ul>
<p>Having to know these details and encoding them into an application’s deployment manifests imposes a greater burden on administrators, or necessitates more complex operators, or results in a less portable application. Or some combination of those outcomes.</p>
<h2 id="storage-classes">Storage classes</h2>
<p>What we really want is to abstract over the storage implementations. We want to able to specify some high-level characteristics of the storage (e.g. block or file, fast or slow?). This is what <em>storage classes</em> provide. Then when we create a PVC, we can specify the desired capacity and class, and the cluster should <em>dynamically provision</em> an appropriate volume. As a result, applications are simpler to deploy and more portable.</p>
<p>To see the storage classes available in a cluster:</p>
<pre><code>ftweedal% oc get storageclass
NAME                 PROVISIONER            RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
standard (default)   kubernetes.io/cinder   Delete          WaitForFirstConsumer   true                   28d</code></pre>
<p>This cluster has only one storage class, called <code>standard</code>. It is also the default storage class for this cluster. To use dynamic provisioning, in the PVC spec instead of <code>volumeName</code> specify <code>storageClassName</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu">apiVersion</span><span class="kw">:</span><span class="at"> v1</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="fu">kind</span><span class="kw">:</span><span class="at"> PersistentVolumeClaim</span></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="fu">metadata</span><span class="kw">:</span></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="at">  </span><span class="fu">name</span><span class="kw">:</span><span class="at"> pvc-test</span></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="fu">spec</span><span class="kw">:</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="at">  </span><span class="fu">accessModes</span><span class="kw">:</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="at">    </span><span class="kw">-</span><span class="at"> ReadWriteOnce</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="at">  </span><span class="fu">resources</span><span class="kw">:</span></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="at">    </span><span class="fu">requests</span><span class="kw">:</span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="at">      </span><span class="fu">storage</span><span class="kw">:</span><span class="at"> 10Gi</span></span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="at">  </span><span class="fu">storageClassName</span><span class="kw">:</span><span class="at"> standard</span></span></code></pre></div>
<p>If you want to use the default storage class, you can even omit the <code>storageClassName</code> field:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb4-1"><a href="#cb4-1"></a><span class="fu">apiVersion</span><span class="kw">:</span><span class="at"> v1</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="fu">kind</span><span class="kw">:</span><span class="at"> PersistentVolumeClaim</span></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="fu">metadata</span><span class="kw">:</span></span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="at">  </span><span class="fu">name</span><span class="kw">:</span><span class="at"> pvc-test</span></span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="fu">spec</span><span class="kw">:</span></span>
<span id="cb4-6"><a href="#cb4-6"></a><span class="at">  </span><span class="fu">accessModes</span><span class="kw">:</span></span>
<span id="cb4-7"><a href="#cb4-7"></a><span class="at">    </span><span class="kw">-</span><span class="at"> ReadWriteOnce</span></span>
<span id="cb4-8"><a href="#cb4-8"></a><span class="at">  </span><span class="fu">resources</span><span class="kw">:</span></span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="at">    </span><span class="fu">requests</span><span class="kw">:</span></span>
<span id="cb4-10"><a href="#cb4-10"></a><span class="at">      </span><span class="fu">storage</span><span class="kw">:</span><span class="at"> 10Gi</span></span></code></pre></div>
<h2 id="dynamic-provisioning-in-action">Dynamic provisioning in action</h2>
<p>Let’s see what actually happens when we use dynamic provisioning. We will observe what objects are created and how their status changes as we create, use and delete a PVC that uses the default storage class.</p>
<p>First let’s see what PVs exist:</p>
<pre><code>ftweedal% oc get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                                             STORAGECLASS   REASON    AGE
pvc-d3bc7c81-8a24-4318-a914-296dbdc5ec3f   100Gi      RWO            Delete           Bound     openshift-image-registry/image-registry-storage   standard                 7d22h</code></pre>
<p>There is one PV, with a 100Gi capacity. It is used for the image registry.</p>
<p>Now, lets create <code>pvc-test</code> as specified above:</p>
<pre><code>ftweedal% oc create -f deploy/pvc-test.yaml
persistentvolumeclaim/pvc-test created

ftweedal% oc get pvc pvc-test
NAME       STATUS    VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc-test   Pending                                       standard       11s

ftweedal% oc get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                                             STORAGECLASS   REASON    AGE
pvc-d3bc7c81-8a24-4318-a914-296dbdc5ec3f   100Gi      RWO            Delete           Bound     openshift-image-registry/image-registry-storage   standard                 7d22h

ftweedal% oc get pvc pvc-test -o yaml |grep storageClassName
storageClassName: standard</code></pre>
<p>The PVC <code>pvc-test</code> was created and has status <code>pending</code>. No new PV has been created yet. Finally note that the PVC has <code>storageClassName: standard</code> (which is the cluster default).</p>
<p>Now lets create a pod that uses <code>pvc-test</code>, mounting it at <code>/data</code>. The pod spec is:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb7-1"><a href="#cb7-1"></a><span class="fu">apiVersion</span><span class="kw">:</span><span class="at"> v1</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="fu">kind</span><span class="kw">:</span><span class="at"> Pod</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="fu">metadata</span><span class="kw">:</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="at">  </span><span class="fu">name</span><span class="kw">:</span><span class="at"> pod-test</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="fu">spec</span><span class="kw">:</span></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="at">  </span><span class="fu">containers</span><span class="kw">:</span></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="at">    </span><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> pod-test-container</span></span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="at">      </span><span class="fu">image</span><span class="kw">:</span><span class="at"> freeipa/freeipa-server:fedora-31</span></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="at">      </span><span class="fu">volumeMounts</span><span class="kw">:</span></span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="fu">mountPath</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;/data&quot;</span></span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="at">          </span><span class="fu">name</span><span class="kw">:</span><span class="at"> data</span></span>
<span id="cb7-12"><a href="#cb7-12"></a><span class="at">      </span><span class="fu">command</span><span class="kw">:</span></span>
<span id="cb7-13"><a href="#cb7-13"></a><span class="at">        </span><span class="kw">-</span><span class="at"> sleep</span></span>
<span id="cb7-14"><a href="#cb7-14"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="st">&quot;3600&quot;</span></span>
<span id="cb7-15"><a href="#cb7-15"></a><span class="at">  </span><span class="fu">volumes</span><span class="kw">:</span></span>
<span id="cb7-16"><a href="#cb7-16"></a><span class="at">    </span><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> data</span></span>
<span id="cb7-17"><a href="#cb7-17"></a><span class="at">      </span><span class="fu">persistentVolumeClaim</span><span class="kw">:</span></span>
<span id="cb7-18"><a href="#cb7-18"></a><span class="at">        </span><span class="fu">claimName</span><span class="kw">:</span><span class="at"> pvc-test</span></span></code></pre></div>
<p>After creating the pod we will write a file under <code>/data</code>, delete then re-create the pod, and observe that the file we wrote persists.</p>
<pre><code>ftweedal% oc create -f deploy/pod-test.yaml
pod/pod-test created

ftweedal% oc exec pod-test -- sh -c &#39;echo &quot;hello world&quot; &gt; /data/foo&#39;

ftweedal% oc delete pod pod-test
pod &quot;pod-test&quot; deleted

ftweedal% oc create -f deploy/pod-test.yaml
pod/pod-test created

ftweedal% oc exec pod-test -- cat /data/foo
hello world

ftweedal% oc delete pod pod-test
pod &quot;pod-test&quot; deleted</code></pre>
<p>This confirms that the PVC works as intended. Let’s check the status of the PVC and PVs to see what happened behind the scenes:</p>
<pre><code>ftweedal% oc get pvc pvc-test
NAME       STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc-test   Bound     pvc-26d82d50-8e66-4938-bdee-f28ff2bcb49c   10Gi       RWO            standard       16m

ftweedal% oc get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                                             STORAGECLASS   REASON    AGE
pvc-26d82d50-8e66-4938-bdee-f28ff2bcb49c   10Gi       RWO            Delete           Bound     ftweedal-operator/pvc-test                        standard                 4m53s
pvc-d3bc7c81-8a24-4318-a914-296dbdc5ec3f   100Gi      RWO            Delete           Bound     openshift-image-registry/image-registry-storage   standard                 7d23h</code></pre>
<p>Before creating the pod <code>pvc-test</code> had status <code>Pending</code>. Now it is <code>Bound</code> to the volume <code>pvc-26d82d50-8e66-4938-bdee-f28ff2bcb49c</code> which was dynamically provisioned with capacity 10Gi as required by <code>pvc-test</code>.</p>
<p>Finally as we delete <code>pvc-test</code>, observe the automatic deletion of the dynamically provisioned volume:</p>
<pre><code>ftweedal% oc delete pvc pvc-test
persistentvolumeclaim &quot;pvc-test&quot; deleted

ftweedal% oc get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                                             STORAGECLASS   REASON    AGE
pvc-d3bc7c81-8a24-4318-a914-296dbdc5ec3f   100Gi      RWO            Delete           Bound     openshift-image-registry/image-registry-storage   standard                 7d23h</code></pre>
<p><code>pvc-26d82d50-8e66-4938-bdee-f28ff2bcb49c</code> went away, as expected.</p>
<h2 id="conclusion">Conclusion</h2>
<p>As we work toward operationalising FreeIPA in OpenShift, I am interested in how we can use storage classes to make for a smooth deployment across different environments and especially those for which OpenShift Dedicated is available.</p>
<p>I also need to learn more about the best practices or common idioms for representing in storage classes the application suitability (e.g. file versus block storage) or performance characteristics of supported volume types in a cluster. To make it a bit more concrete, consider that for performance reasons we might require low-latency/high-throughput block storage for the 389 DS LDAP database storage. How can we express this abstract requirement such that we get a satisfactory result across a variety of “clouds” with no administrator effort? Hopefully storage classes are the answer. But if they are not the whole solution, from what I have learned so far I have a strong feeling that they will be a bit part of the solution.</p>]]></summary>
</entry>
<entry>
    <title>CRLs for Dogtag Lightweight CAs</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2020-06-19-dogtag-lightweight-ca-crl.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2020-06-19-dogtag-lightweight-ca-crl.html</id>
    <published>2020-06-19T00:00:00Z</published>
    <updated>2020-06-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="crls-for-dogtag-lightweight-cas">CRLs for Dogtag Lightweight CAs</h1>
<p>A few years ago I implemented <em>lightweight CAs</em> in Dogtag. This feature allows multiple CAs to be hosted in a single Dogtag server instance. For now these are restricted to sub-CAs of the <em>main CA</em> but this is not a fundamental restriction.</p>
<p>An important aspect of CA operation is <em>revocation</em>: the ability to revoke a certificate because of (suspected) key compromise, cessation of operation, it was superseded, etc. There are currently two main ways of conveying revocation status to clients: <em>Certificate Revocation Lists (CRLs)</em> and <em>Online Certificate Status Protocol (OCSP)</em>. CRLs and OCSP have their respective advantages and drawbacks. Suffice to say, for many security-conscious organisations CRLs are important (as is OCSP).</p>
<p>There is currently no support for lightweight CA certificates in CRLs produced by Dogtag. The purpose of this post is to discuss the challenges and possible approaches to closing this gap.</p>
<h2 id="overview-of-ocsp-and-crls">Overview of OCSP and CRLs</h2>
<p>OCSP (defined in <a href="https://tools.ietf.org/html/rfc6960">RFC 6960</a>) is a network protocol for determining certificate revocation status. Any relying party (e.g. a web browser validating a server certificate) can ask the CA’s <em>OCSP responder</em> for a signed assertion of whether or not the certificate is revoked. For scalability and performance reasons, TLS servers can periodically obtain OCSP responses for their certificate and convey them to clients in the TLS handshake; this feature is called <a href="https://en.wikipedia.org/wiki/OCSP_stapling">OCSP stapling</a>.</p>
<p>On the other hand, CRLs are a more <em>passive</em> technology. X.509 CRLs are defined alongside X.509 certificates in <a href="https://tools.ietf.org/html/rfc5280">RFC 5280</a>. In the simple case a CRL is a signed, timestamped list of all revoked, non-exired certificates issued by a CA. The CA produces new CRLs on a fixed schedule (e.g. every 4 hours) and publishes them (e.g. on HTTP, in an LDAP directory, etc). Clients <em>somehow</em> obtain and refresh their CRL cache, and consult it when validating certificates. The CRL grows linearly in the number of revoked certificates so on a busy CA the CRL can become <em>huge</em>. Retrieving a large CRL takes time and bandwidth, storing it takes space, and consulting it takes time. The advantage is that validation requires no (additional) network traffic. The assumption is that the clients CRL cache is up to date.</p>
<p>One further downside of CRLs is that they are only as good as their most recent update. What if your CRL is 3 hours old, the certificate of interest was revoked 1 hour ago, and it is still 1 hour until the next CRL gets published? In practice, every approach to revocation suffers from such a delay. Also in practice, the delay duration is often much greater for CRLs than for OCSP.</p>
<h2 id="ocsp-support-for-lightweight-cas">OCSP support for Lightweight CAs</h2>
<p>The initial release of the Dogtag lightweight CAs feature had OCSP support for certificates issued by lightweight CAs. It works properly and there is nothing more to be said about it.</p>
<h2 id="crl-support-for-lightweight-cas">CRL support for lightweight CAs</h2>
<p>As mentioned in the introduction, certificates issued by lightweight CAs are not included in the CRLs produced by Dogtag. <a href="https://pagure.io/dogtagpki/issue/1627">Ticket #1627</a> in the upstream Pagure tracks this issue.</p>
<p>The reason this was not implemented in the initial release (or since) is that in the baseline case, a CRL can only include certificates from a single CA. Say we have the main CA <code>CN=MainCA</code> and lightweight sub-CA <code>CN=SubCA</code>. The CRL cannot include certificates from both CAs, because a CRL is just a list of serial numbers.</p>
<h3 id="indirect-crls">Indirect CRLs</h3>
<p>There is a way around this limitation. The <a href="https://tools.ietf.org/html/rfc5280#section-5.3.3">Certificate Issuer</a> CRL entry extension, if some other extensions on both the certificate and CRL are set up <em>just right</em>, allows a CRL to include certificates from multiple issuers. Such CRLs are called <em>indirect CRLs</em>. Conforming applications are not required to support indirect CRLs, and the extension is <em>critical</em> so there is a risk of compatibility issues if we were to use indirect CRLs for conveying revocation status of certificates issued by lightweight CAs.</p>
<p>Apart from client support for the Certificate Issuer extension the other requirements for indirect CRLs to work are:</p>
<ul>
<li>The certificate’s <em>CRL Distribution Points (CRLDP)</em> extension must include the <code>cRLIssuer</code> field and its value must match the issuer of the CRL.</li>
<li>The CRL must include the <em>Issuing Distribution Point</em> CRL extension that asserts the <code>indirectCRL</code> boolean. This is a critical extension.</li>
<li>The trust anchor for the CRL must be the same as the trust anchor for the certificate. This means that indirect CRLs cannot work for lightweight CAs that do not chain to the same CA. This is only a potential problem if the lightweight CAs feature is enhanced to support hosting unrelated CAs (rather than sub-CAs).</li>
</ul>
<p>So to use indirect CRLs some minor changes to certificate profiles would be required. But the changes would be the same for all profiles and the content of the CRL Distribution Point extension would be the same regardless of which lightweight CA issues the certificate.</p>
<h3 id="separate-crls">Separate CRLs</h3>
<p>An alternative approach is to create a separate CRL for each lightweight CA. This would avoid compatibility issues caused by the use of critical extensions that clients are not required to support. It also avoids the trust anchor limitations that would arise when hosting a lightweight CA that does not share a common trust root with the CRL issuer.</p>
<p>From an implementation point of view there are two major challenges with this approach.</p>
<ol type="1">
<li>Dogtag does not generate CRLs implicitly but currently requires explicit configuration for each CRL. The configuration is not stored in LDAP but in the <code>CS.cfg</code> configuration file, so there is no way to dynamically configure new CRLs as new lightweight CAs are created.</li>
<li>The content of the CRL Distribution Point extension will differ according to the CA that is issuing the certificate. The CRLDP content is currently configured per-profile. New profile components or enhancements to the existing CRLDP profile component will be required.</li>
</ol>
<p>In my view it is not acceptable to have to define multiple profiles differing only the CRL Distribution Point extension. The CA issuing the certificate should, by default, set any extensions that relate specifically to itself, including the CRLDP (also <em>Authority Key Identifier</em> and <em>Authority Information Access</em>). For more specialised use cases, the CRLDP content could be <em>overridden</em> or <em>suppressed</em> on a per-profile basis.</p>
<h3 id="deciding-the-approach">Deciding the approach</h3>
<p>Indirect CRLs is the lower-effort approach. But before choosing it, we ought to audit certificate verification libraries (especially OpenSSL, NSS and other libraries used in Fedora, RHEL and other Red Hat products) to see if they support indirect CRLs. If support is widespread, the approach is viable. If support is not widespread, it is not a good idea.</p>
<p>Thinking longer-term, this is a good opportunity to improve the administrator experience. Maybe now is a good time to implement useful features like automatic CRL generation for each CA in a Dogtag instance, and profile components that create a CRL Distribution Point extension that points to the CRL for the CA that is issuing the certificate. The current configuration approach is versatile and can handle all kinds of wild CRL scenarios. But it is <em>hostile</em> to getting things right for the common case.</p>
<p>This decision will probably not be mine to make because I will soon be leaving the Dogtag team. But I hope this post is useful to whoever is involved in the eventual decision.</p>
<h3 id="profile-changes">Profile changes</h3>
<p>Both of the discussed approaches require some changes to profile configuration. Required profile changes means upgrade steps to update them. This can be tricky especially in mixed-version topologies when new profile components (if any) are present on some servers but not others.</p>
<h3 id="the-do-nothing-option">The “do nothing” option</h3>
<p>Lightweight CAs have been available for nearly 4 years. I can only recall one or two queries about lightweight CA CRL support. To be clear, it is a fair ask. But it seems that OCSP is sufficient for most customers. Or perhaps there is a lack of awareness that CRLs do not include certificates issued by lightweight CAs. Whatever the case, the low demand aligns with my own opinion that although CRL support for lightweight CAs is a nice-to-have, it is not of critical importance to many users or customers.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this post I identified two possible approaches to CRL support for lightweight CAs. Each approach has advantages, drawbacks and unique challenges. Never implementing it is also an option to be considered because demand, though it does exist, seems low.</p>
<p>I haven’t often discussed revocation in detail, so it is probably worth mentioning other approaches besides CRLs and OCSP.</p>
<p><em>Ephemeral PKI</em> avoids the problem by only issuing very short lived certificates, e.g. one week, one day or even less! Assuming keys are rotated just as frequently, when certificate lifetimes approach the “lag” time revocation solutions, the revocation solution is not needed.</p>
<p><em>CRLite</em> is an experimental revocation solution currently in development. It achieves fast and scalable revocation checking through cascading Bloom filters produced by an <em>aggregator</em> that records certificate revocations from one or more CAs. The target use case is in fact <em>all publicly trusted CAs</em> and Firefox Nightly already uses the system (non-enforcing, telemetry-only by default). Scott Helme wrote an <a href="https://scotthelme.co.uk/crlite-finally-a-fix-for-broken-revocation/">excellent blog post</a> about it and you can read the <a href="https://obj.umiacs.umd.edu/papers_for_stories/crlite_oakland17.pdf">original paper</a> for the gory details.</p>
<p>One final note. I found some compliance issues with how the CRL Distribution Point extension is configured in the default FreeIPA certificate profiles. A strict reading of <a href="https://tools.ietf.org/html/rfc5280">RFC 5280</a> suggests that the CRL Distribution Point extension data produced by the default FreeIPA profiles would lead to the certificate not being considered in scope of the CRLs produced by Dogtag. This issue is particular to FreeIPA configuration, not a general problem with FreeIPA. More investiation is required and I will probably write a separate post about this in the future.</p>]]></summary>
</entry>
<entry>
    <title>ACME DNS challenges and FreeIPA</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2020-05-13-ipa-acme-dns.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2020-05-13-ipa-acme-dns.html</id>
    <published>2020-05-13T00:00:00Z</published>
    <updated>2020-05-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="acme-dns-challenges-and-freeipa">ACME DNS challenges and FreeIPA</h1>
<p><em>This post is part of a series of ACME client demonstrations. See also the posts about</em> <a href="2020-05-06-ipa-acme-intro.html">Certbot standalone HTTP</a> <em>and</em> <a href="2020-05-07-ipa-acme-mod_md.html">mod_md for Apache</a></p>
<p>The ACME protocol defined in <a href="https://tools.ietf.org/html/rfc8555">RFC 8555</a> defines a <a href="https://tools.ietf.org/html/rfc8555#section-8.4">DNS challenge</a> for proving control of a domain name. In this post I’ll explain how the DNS challenge works and demonstrate how to use the <a href="https://certbot.eff.org/">Certbot</a> ACME client with the FreeIPA integrated DNS service.</p>
<h2 id="the-dns-challenge">The DNS challenge</h2>
<p>To prove control of a domain name (the <code>dns</code> identifier type) ACME defines the <code>dns-01</code> challenge type. It is up to ACME servers which challenges to create for a given identifier. If a server offers multiple challenges (e.g. <code>http-01</code> and <code>dns-01</code>) the client can choose which one to attempt.</p>
<p>A DNS challenge object looks like:</p>
<pre><code>{
  &quot;type&quot;: &quot;dns-01&quot;,
  &quot;url&quot;: &quot;https://example.com/acme/chall/Rg5dV14Gh1Q&quot;,
  &quot;status&quot;: &quot;pending&quot;,
  &quot;token&quot;: &quot;evaGxfADs6pSRb2LAv9IZf17Dt3juxGJ-PCt92wr-oA&quot;
}</code></pre>
<p>The <code>token</code> field is a base64url-encoded high-entropy random value. Due to the use of TLS this value should be known only to the server and client.</p>
<p>The client responds to a <code>dns-01</code> challenge by provisioning a DNS <strong>TXT</strong> record containing the SHA-256 digest of the <em>key authorisation</em> value, which is the concatenation of the <code>token</code> value from the challenge object and the JWK Thumbprint of the account key. For example:</p>
<pre><code>_acme-challenge.www.example.org. 300 IN TXT &quot;gfj9Xq...Rg85nM&quot;</code></pre>
<p>The client then informs the ACME server that it can validate the challenge:</p>
<pre><code>POST /acme/chall/Rg5dV14Gh1Q
Host: example.com
Content-Type: application/jose+json

{
  &quot;protected&quot;: base64url({
    &quot;alg&quot;: &quot;ES256&quot;,
    &quot;kid&quot;: &quot;https://example.com/acme/acct/evOfKhNU60wg&quot;,
    &quot;nonce&quot;: &quot;SS2sSl1PtspvFZ08kNtzKd&quot;,
    &quot;url&quot;: &quot;https://example.com/acme/chall/Rg5dV14Gh1Q&quot;
  }),
  &quot;payload&quot;: base64url({}),
  &quot;signature&quot;: &quot;Q1bURgJoEslbD1c5...3pYdSMLio57mQNN4&quot;
}</code></pre>
<p>The ACME server will query the DNS. When it sees that the expected TXT record, the challenge (and corresponding identifier authorisation) are completed.</p>
<p>Because DNSSEC is not widely deployed, ACME servers can mitigate against DNS-based attacks by querying DNS from mutiple vantage points. This increases attack cost and complexity.</p>
<h2 id="dns-and-certbot">DNS and Certbot</h2>
<p>Certbot provides the <code>--preferred-challenges={dns,http}</code> CLI option to specify which challenge type to prefer if the server offers multiple challenges.</p>
<p>There are several <a href="https://certbot.eff.org/docs/using.html#dns-plugins">DNS plugins</a> available for using Certbot with particular DNS services. For example there are plugins for Cloudflare, Route53 and many other services. At a glance, many of them are packaged for Fedora. Each DNS plugin has different options to activate and configure it. Because we are not using any of these services I won’t go into further details here.</p>
<p>Certbot also provides <a href="https://certbot.eff.org/docs/using.html#pre-and-post-validation-hooks">pre and post validation hooks</a> for the <code>--manual</code> strategy. These let the user specify scripts to carry out challenge provisioning and cleanup steps. The command line options are <code>--manual-auth-hook</code> and <code>--manual-cleanup-hook</code>.</p>
<h2 id="certbot-and-freeipa-dns">Certbot and FreeIPA DNS</h2>
<p>You can use the CLI options described above to implement arbitrary means of responding to ACME challenges. And I have done just that for responding to the <code>dns-01</code> challenge using the FreeIPA integrated DNS service.</p>
<p>The FreeIPA integrated DNS is an optional component of FreeIPA. It is implmented using the BIND DNS server and a database plugin causing BIND to read from the FreeIPA replicated LDAP database. The DNS service can be installed at server install time, or afterwards via the <code>ipa-dns-install</code> command. The <code>freeipa-server-dns</code> (Fedora) or <code>ipa-server-dns</code> (RHEL) package provides this feature. The rest of this section assumes that the FreeIPA integrated DNS server is installed and FreeIPA-enrolled client machines are configured to use it.</p>
<p>The <code>ipa dnsrecord-add &lt;zone&gt; &lt;name&gt; ...</code> command adds record(s) to the zone. The resource types and values are given in options like <code>--aaaa-rec=&lt;ip6addr&gt;</code> or <code>--txt-rec=&lt;string&gt;</code>. The corresponding command <code>dnsrecord-del</code> command has the same format. Knowing that we can also interact with the FreeIPA server via the <code>ipalib</code> Python library, we have everything we need to implement the Certbot hook script(s) that will use FreeIPA’s DNS to satisfy the ACME <code>dns-01</code> challenge.</p>
<h3 id="hook-script">Hook script</h3>
<p>The script is so short I will just include the whole thing here. I have broken it into chunks with commentary.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="co">#!/usr/bin/python3</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="im">import</span> os</span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="im">from</span> dns <span class="im">import</span> resolver</span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="im">from</span> ipalib <span class="im">import</span> api </span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="im">from</span> ipapython <span class="im">import</span> dnsutil</span></code></pre></div>
<p>Shebang, imports. Trivial.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>certbot_domain <span class="op">=</span> os.environ[<span class="st">&#39;CERTBOT_DOMAIN&#39;</span>]</span>
<span id="cb5-2"><a href="#cb5-2"></a>certbot_validation <span class="op">=</span> os.environ[<span class="st">&#39;CERTBOT_VALIDATION&#39;</span>]</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="cf">if</span> <span class="st">&#39;CERTBOT_AUTH_OUTPUT&#39;</span> <span class="kw">in</span> os.environ:</span>
<span id="cb5-4"><a href="#cb5-4"></a>    command <span class="op">=</span> <span class="st">&#39;dnsrecord_del&#39;</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="cf">else</span>:</span>
<span id="cb5-6"><a href="#cb5-6"></a>    command <span class="op">=</span> <span class="st">&#39;dnsrecord_add&#39;</span></span></code></pre></div>
<p>Certbot provides the domain name and the <em>authorisation string</em> via environment variables. In the cleanup phase it also sets the <code>CERTBOT_AUTH_OUTPUT</code> environment variable. Therefore I use this same script for both the authorisation and cleanup phases. Because the commands are so similar, the only thing that changes during cleanup is the command name.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>validation_domain <span class="op">=</span> <span class="ss">f&#39;_acme-challenge.</span><span class="sc">{</span>certbot_domain<span class="sc">}</span><span class="ss">&#39;</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>fqdn <span class="op">=</span> dnsutil.DNSName(validation_domain).make_absolute()</span>
<span id="cb6-3"><a href="#cb6-3"></a>zone <span class="op">=</span> dnsutil.DNSName(resolver.zone_for_name(fqdn))</span>
<span id="cb6-4"><a href="#cb6-4"></a>name <span class="op">=</span> fqdn.relativize(zone)</span></code></pre></div>
<p>Construct the validation domain name and find the corresponding DNS zone, i.e. the zone in which we must create the TXT record. Then we relativise the validation domain name against the zone.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>api.bootstrap(context<span class="op">=</span><span class="st">&#39;cli&#39;</span>)</span>
<span id="cb7-2"><a href="#cb7-2"></a>api.finalize()</span>
<span id="cb7-3"><a href="#cb7-3"></a>api.Backend.rpcclient.<span class="ex">connect</span>()</span>
<span id="cb7-4"><a href="#cb7-4"></a></span>
<span id="cb7-5"><a href="#cb7-5"></a>api.Command[command](</span>
<span id="cb7-6"><a href="#cb7-6"></a>  zone,</span>
<span id="cb7-7"><a href="#cb7-7"></a>  name,</span>
<span id="cb7-8"><a href="#cb7-8"></a>  txtrecord<span class="op">=</span>[certbot_validation],</span>
<span id="cb7-9"><a href="#cb7-9"></a>  dnsttl<span class="op">=</span><span class="dv">60</span>)</span></code></pre></div>
<p>Initialise the API and execute the command. Note that names of the keyword arguments are different from the corresponding CLI options.</p>
<p>There are some important <strong>caveats</strong>. There must be latent, non-expired Kerberos credentials in the execution environment. These can be in the default credential cache or specified via the <code>KRB5CCNAME</code> environment variable (e.g. to point to a keytab file). The principal must also have permissions to add and remove DNS records.</p>
<h2 id="demo">Demo</h2>
<p>As in previous ACME demos the client machine is enrolled as a FreeIPA client and trusts the FreeIPA CA. For this demo Certbot does not need to run as <code>root</code>. But by default Certbot tries to read and write files under <code>/etc/letsencrypt</code>. I had to override this behaviour with the following command line options:</p>
<dl>
<dt><code>--config-dir DIR</code></dt>
<dd><p>Configuration directory. (default: <code>/etc/letsencrypt</code>)</p>
</dd>
<dt><code>--work-dir DIR</code></dt>
<dd><p>Working directory. (default: <code>/var/lib/letsencrypt</code>)</p>
</dd>
<dt><code>--logs-dir LOGS_DIR</code></dt>
<dd><p>Logs directory. (default: <code>/var/log/letsencrypt</code>)</p>
</dd>
</dl>
<p>I defined these options in a shell array variable for use in subsequent commands. I included the ACME server configuration too:</p>
<pre><code>[f31-0:~] ftweedal% CERTBOT_ARGS=( 
array&gt; --logs-dir ~/certbot/log
array&gt; --work-dir ~/certbot/work
array&gt; --config-dir ~/certbot/config
array&gt; --server https://ipa-ca.ipa.local/acme/directory
array&gt; )</code></pre>
<p>Next I registered an account:</p>
<pre><code>[f31-0:~] ftweedal% certbot $CERTBOT_ARGS \
    register --email ftweedal@redhat.com \
    --agree-tos --no-eff-email --quiet
Saving debug log to /home/ftweedal/certbot/log/letsencrypt.log

IMPORTANT NOTES:
 - Your account credentials have been saved in your Certbot
   configuration directory at /home/ftweedal/certbot/config. You
   should make a secure backup of this folder now. This configuration
   directory will also contain certificates and private keys obtained
   by Certbot so making regular backups of this folder is ideal.</code></pre>
<p>The <code>--no-eff-email</code> option suppressed the <em>“Would you be willing to share your email address with the Electronic Frontier Foundation?”</em> prompt.</p>
<p>The FreeIPA hook script requires Kerberos credentials so I executed <code>kinit admin</code>. <strong>In production use a less privileged account</strong> with permissions to add and delete DNS records.</p>
<pre><code>[f31-0:~] ftweedal% kinit admin
Password for admin@IPA.LOCAL: XXXXXXXX</code></pre>
<p>Now I was ready to request the certificate. Alongside executing <code>certbot</code>, in another terminal I executed DNS queries to observe the creation and deletion of the TXT record.</p>
<pre><code>[root@f31-0 ~]# certbot $CERTBOT_ARGS \
    certonly --domain $(hostname) \
    --preferred-challenges dns \
    --manual --manual-public-ip-logging-ok \
    --manual-auth-hook /home/ftweedal/certbot-dns-ipa.py \
    --manual-cleanup-hook /home/ftweedal/certbot-dns-ipa.py
Saving debug log to /home/ftweedal/certbot/log/letsencrypt.log 
Plugins selected: Authenticator manual, Installer None                                                            
Obtaining a new certificate                                                                                       
Performing the following challenges:
dns-01 challenge for f31-0.ipa.local
Running manual-auth-hook command: /home/ftweedal/certbot-dns-ipa.py
Waiting for verification...
Cleaning up challenges
Running manual-cleanup-hook command: /home/ftweedal/certbot-dns-ipa.py

IMPORTANT NOTES:
 - Congratulations! Your certificate and chain have been saved at:
   /home/ftweedal/certbot/config/live/f31-0.ipa.local/fullchain.pem
   Your key file has been saved at:
   /home/ftweedal/certbot/config/live/f31-0.ipa.local/privkey.pem
   Your cert will expire on 2020-08-11. To obtain a new or tweaked
   version of this certificate in the future, simply run certbot
   again. To non-interactively renew *all* of your certificates, run
   &quot;certbot renew&quot;
 - If you like Certbot, please consider supporting our work by:

   Donating to ISRG / Let&#39;s Encrypt:   https://letsencrypt.org/donate
   Donating to EFF:                    https://eff.org/donate-le</code></pre>
<p>The certificate was issued and the process took about 10 seconds. In the other terminal, running <code>dig</code> every couple of seconds let me observe the TXT record that was created and then deleted:</p>
<pre><code>[f31-0:~] ftweedal% dig +short TXT _acme-challenge.f31-0.ipa.local

[f31-0:~] ftweedal% dig +short TXT _acme-challenge.f31-0.ipa.local
&quot;5qkVb3ykx8nRdJOKbKf-xDtoySFl-B2W37bBBOHGoyc&quot;

[f31-0:~] ftweedal% dig +short TXT _acme-challenge.f31-0.ipa.local
&lt;&lt; no output; record is gone &gt;&gt;</code></pre>
<h2 id="error-handling">Error handling</h2>
<p>To my surprise, a failure (non-zero exit status) of the authorisation hook script <em>does not</em> cause Certbot to halt. For example, after deleting my credential cache with <code>kdestroy</code> and running <code>certbot</code> with the same options as above, Certbot output an error message and the standard error output from the hook script:</p>
<pre><code>...
Running manual-auth-hook command: /home/ftweedal/certbot-dns-ipa.py                                               
manual-auth-hook command &quot;/home/ftweedal/certbot-dns-ipa.py&quot;
returned error code 1                                
Error output from manual-auth-hook command certbot-dns-ipa.py:                                                    
Traceback (most recent call last):                                                                                
  File &quot;/usr/lib/python3.7/site-packages/ipalib/rpc.py&quot;, line 647,
  in get_auth_info                               
      response = self._sec_context.step()                                          
  ...</code></pre>
<p>Nevertheless Certbot proceeded to indicating to the server that the challenge is ready for verification:</p>
<pre><code>Waiting for verification...                                                                                       
&lt; 20 seconds elapse &gt;</code></pre>
<p>It then cleaned up the challenges and ran the cleanup hook (which also failed, as expected, due to no Kerberos credentials):</p>
<pre><code>Cleaning up challenges   
Cleaning up challenges                                                                                            
Running manual-cleanup-hook command: /home/ftweedal/certbot-dns-ipa.py
manual-cleanup-hook command &quot;/home/ftweedal/certbot-dns-ipa.py&quot; returned error code 1                             
Error output from manual-cleanup-hook command certbot-dns-ipa.py:                                                 
Traceback (most recent call last):   
  ...</code></pre>
<p>Finally it output the error from the ACME service:</p>
<pre><code>An unexpected error occurred:                                                                                     
There was a problem with a DNS query during identifier validation ::
  Unable to validate DNS-01 challenge at _acme-challenge.f31-0.ipa.local                                                                                         
Error: DNS name not found [response code 3]                                                                       
Please see the logfiles in /home/ftweedal/certbot/log for more details. </code></pre>
<p>Responding to a challenge after an abnormal exit of the authorisation hook seems to infringe RFC 8555 §8.2 which states:</p>
<blockquote>
<p>Clients SHOULD NOT respond to challenges until they believe that the server’s queries will succeed.</p>
</blockquote>
<p>I <a href="https://github.com/certbot/certbot/issues/7990">reported this issue</a> against the Certbot GitHub repository.</p>
<h2 id="discussion">Discussion</h2>
<p>The <code>certbot-dns-ipa.py</code> script is <a href="https://gist.github.com/frasertweedale/ca42ff31d5f5b8d3c6d4d3a94f9fbd0e">available in a Gist</a>. It is trivial so consider it public domain.</p>
<p>The script is an artifact of work that is partly an exploration of ACME use cases, and partly for verifying the PKI and FreeIPA ACME services. I encountered no issues on the ACME server side which was pleasing.</p>
<p>From the client point of view it was good to confirm that what <em>sounded</em> like a valid use case was indeed valid. Not only that, it was straightforward thanks to the FreeIPA Python API and the design of the DNS plugin. The success of this use case exploration leads to to a couple of related questions:</p>
<ul>
<li>Should we build a “proper” Certbot plugin for FreeIPA DNS?</li>
<li>Should we distribute and support the manual hook script?</li>
</ul>
<p>These questions don’t need answers today. But it is good to outline and compare the options.</p>
<p>From a technical standpoint these are not mutually exclusive; you could do both. But from a usage standpoint you only really need one or the other. A proper plugin might have better UX and discoverability but it would be additional work (how much more I’m not sure yet). On the other hand the hook script is pretty much already “done”. We would just need to distribute it, e.g. install it under <code>/usr/libexec/ipa/</code>.</p>
<p>This post concludes my “trilogy” of ACME client use case demos. In the future I will probably explore the intersection of ACME, OpenShift and FreeIPA. If so, expect the “sequel trilogy”. But my immediate focus must be to finish the FreeIPA ACME service and get it merged upstream.</p>]]></summary>
</entry>
<entry>
    <title>ACME for Apache httpd with mod_md</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2020-05-07-ipa-acme-mod_md.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2020-05-07-ipa-acme-mod_md.html</id>
    <published>2020-05-07T00:00:00Z</published>
    <updated>2020-05-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="acme-for-apache-httpd-with-mod_md">ACME for Apache httpd with mod_md</h1>
<p><em>This post is part of a series of ACME client demonstrations. See also the posts about</em> <a href="2020-05-06-ipa-acme-intro.html">Certbot standalone HTTP</a> <em>and</em> <a href="2020-05-13-ipa-acme-dns.html">Certbot with FreeIPA DNS</a>.</p>
<p><a href="">mod_md</a> is an ACME client module for Apache httpd. In this post I demonstrate the use mod_md with the FreeIPA ACME service to automatically acquire certificates for <strong>m</strong>anaged <strong>d</strong>omains from the FreeIPA CA.</p>
<p>mod_md supports the <code>http-01</code> and <code>tls-alpn-01</code> challenges (also <code>dns-01</code> via external programs). The FreeIPA ACME service does not implement <code>tls-alpn-01</code> so we will use the HTTP-based challenge. For this httpd needs to be listening on port 80, which is the case in the default Fedora configuration:</p>
<pre><code>[root@f31-0 ~]# grep ^Listen /etc/httpd/conf/httpd.conf
Listen 80</code></pre>
<p>First step was to install the module:</p>
<pre><code>[root@f31-0 ~]# dnf install -y mod_md
  &lt;stuff happens&gt;
Complete!</code></pre>
<p>Looking at the installed configuration files and their contents, I see the relevant load directives already in place:</p>
<pre><code>[root@f31-0 ~]# rpm -qc mod_md
/etc/httpd/conf.modules.d/01-md.conf

[root@f31-0 ~]# cat /etc/httpd/conf.modules.d/01-md.conf
LoadModule md_module modules/mod_md.so</code></pre>
<p>I created a minimal <code>VirtualHost</code> configuration:</p>
<pre><code>[root@f31-0 ~]# cat &gt;/etc/httpd/conf.d/acme.conf &lt;&lt;EOF
LogLevel warn md:notice

MDCertificateAuthority https://ipa-ca.ipa.local/acme/directory
MDCertificateAgreement accepted

MDomain f31-0.ipa.local

&lt;VirtualHost *:443&gt;
    ServerName f31-0.ipa.local

    SSLEngine on
    # no certificates specification
&lt;/VirtualHost&gt;
EOF</code></pre>
<p>Starting httpd and watching the error log, I observed that shortly after startup it only took mod_md about 5 seconds to create an account, submit an order, prove control of the <code>f31-0.ipa.local</code> DNS name and retrieve the issued certificate:</p>
<pre><code>[Wed May 06 15:51:37.371414 2020] [core:notice] [pid 82766:tid
  140661368246592] AH00094: Command line: &#39;/usr/sbin/httpd -D
  FOREGROUND&#39;
[Wed May 06 15:51:43.086719 2020] [md:notice] [pid 82778:tid
  140661321930496] AH10059: The Managed Domain f31-0.ipa.local has
  been setup and changes will be activated on next (graceful) server
  restart.</code></pre>
<p>The notice that we still need to perform a (graceful) restart is important. Indeed a requests from another host still fails with a self-signed certificate warning:</p>
<pre><code>[f31-1:~] ftweedal% curl https://f31-0.ipa.local/
curl: (60) SSL certificate problem: self signed certificate
More details here: https://curl.haxx.se/docs/sslcerts.html

curl failed to verify the legitimacy of the server and therefore
could not establish a secure connection to it. To learn more about
this situation and how to fix it, please visit the web page
mentioned above.</code></pre>
<p>After preforming a (graceful) restart of httpd:</p>
<pre><code>[f31-0:~] ftweedal% sudo systemctl reload httpd</code></pre>
<p>Requests now work (never mind the 403 response status):</p>
<pre><code>[f31-1:~] ftweedal% curl --head https://f31-0.ipa.local/
HTTP/1.1 403 Forbidden
Date: Wed, 06 May 2020 06:11:43 GMT
Server: Apache/2.4.43 (Fedora) OpenSSL/1.1.1d mod_auth_gssapi/1.6.1 mod_wsgi/4.6.6 Python/3.7
Last-Modified: Thu, 25 Jul 2019 05:18:03 GMT
ETag: &quot;15bc-58e7a8ccdb8c0&quot;
Accept-Ranges: bytes
Content-Length: 5564
Content-Type: text/html; charset=UTF-8</code></pre>
<p><code>curl -v</code> output included the following certificate detail:</p>
<pre><code>* Server certificate:
*  subject: CN=f31-0.ipa.local
*  start date: May  6 05:51:41 2020 GMT
*  expire date: Aug  4 05:51:41 2020 GMT
*  subjectAltName: host &quot;f31-0.ipa.local&quot; matched cert&#39;s &quot;f31-0.ipa.local&quot;
*  issuer: O=IPA.LOCAL 202004011654; CN=Certificate Authority
*  SSL certificate verify ok.</code></pre>
<p>Observe that it is a short-lived certificate issued by the FreeIPA CA.</p>
<p>The fact that a graceful restart was required suggests that if you are using mod_md in production, you should configure a cron job (or equivalent) to execute that on a regular schedule. The <code>MDRenewWindow</code> directive defines the remaining certificate lifetime at which mod_md will first attempt to renew the certificate. The default value is <code>33%</code> which for 90 day certificates is 30 days. Therefore with 90 days certificates and the default <code>MDRenewWindow 33%</code>, restarting weekly seems reasonable.</p>
<p>One last curiousity: by default mod_md publishes a “certificate status” resource at <code>.httpd/certificate-status</code> for each managed domain:</p>
<pre><code>[f31-1:~] ftweedal% curl \
    https://f31-0.ipa.local/.httpd/certificate-status
{
  &quot;valid&quot;: {
    &quot;until&quot;: &quot;Tue, 04 Aug 2020 05:51:41 GMT&quot;,
    &quot;from&quot;: &quot;Wed, 06 May 2020 05:51:41 GMT&quot;
  },
  &quot;serial&quot;: &quot;1E&quot;,
  &quot;sha256-fingerprint&quot;: &quot;a70d2182f347cf9dddfbd19a14243c5efe24df55fa5728297c667494a28e7d2e&quot;
}</code></pre>
<p>This can be suppressed by <code>MDCertificateStatus off</code> which is a server-wide setting.</p>
<h2 id="discussion">Discussion</h2>
<p>Confession time. The above scenario did not go anywhere near as smoothly as portrayed above. In fact, mod_md was failing immediately after retrieving the directory resource:</p>
<pre><code>[Tue May 05 22:28:32.462108 2020] [md:warn] [pid 68047:tid
140418815502080] (22)Invalid argument: md[f31-0.ipa.local]
while[Contacting ACME server for f31-0.ipa.local at
https://ipa-ca.ipa.local/acme/directory] detail[Unable to understand
ACME server response from &lt;https://ipa-ca.ipa.local/acme/directory&gt;.
Wrong ACME protocol version or link?]</code></pre>
<p>I went to the mod_md source code to investigate. The problem was that mod_md required the ACME <code>revokeCert</code> and <code>keyChange</code> (account key rollover) resources to be defined in the resource document, even though mod_md does not use those capabilities (at this time). The Dogtag ACME responder has not yet implemented key rollover. As a consequence, mod_md refused to interact with it.</p>
<p>What does RFC 8555 have to say about this? §7.1 states:</p>
<blockquote>
<p>The server MUST provide “directory” and “newNonce” resources.</p>
</blockquote>
<p>But there is no explicit statement about whether other resources are, or are not, required (with the exception of the <code>newAuthz</code> resource other resource which is optional). My conclusion is that mod_md, in checking for resources it doesn’t even use, is too strict. I submitted <a href="https://github.com/icing/mod_md/pull/214">a pull request</a> to <a href="https://github.com/icing/mod_md">https://github.com/icing/mod_md</a> to relax the check. It was accepted and merged the next day.</p>
<p>Note that mod_md has also been pulled into the httpd codebase, although it does not seem to be as actively maintained there at this point in time. I suppose that the httpd code is periodically updated with the code from the <em>icing</em> respository. Nevertheless I also submitted a <a href="https://github.com/apache/httpd/pull/122">pull request to httpd</a>. At time of publication of this post there has been no activity. I have also submitted bugs against the Fedora and RHEL mod_md packages.</p>
<p>In the meantime I built a version of the Fedora package containing my patch. This time mod_md was able to successfully validate the identifier and finalise the order, causing the certificate to be issued. But it was not able to retrieve the certificate; mod_md does not handle the absense of the <code>Location</code> header in the response to the finalise request. This header was required in an earlier (pre-RFC) draft of the ACME protocol, but it is not required any more. <em>Boulder</em> (the ACME server implementation used by Let’s Encrypt) does set it so mod_md works fine with Boulder. But the Dogtag ACME service did not set it and mod_md fails at this point, putting the client-side order data into an unrecoverable state.</p>
<p>The quick fix was to update the Dogtag ACME service to include the Location header. I also <a href="https://github.com/icing/mod_md/issues/216">reported the issue</a> in the upstream repository.</p>
<p>That’s it for this demo. For my next FreeIPA ACME demo I’m going to attempt DNS-based identifier validation challenges with Certbot and FreeIPA’s integrated DNS.</p>]]></summary>
</entry>
<entry>
    <title>Introducing the FreeIPA ACME service</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2020-05-06-ipa-acme-intro.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2020-05-06-ipa-acme-intro.html</id>
    <published>2020-05-06T00:00:00Z</published>
    <updated>2020-05-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="introducing-the-freeipa-acme-service">Introducing the FreeIPA ACME service</h1>
<p><em>This post is part of a series of ACME client demonstrations. See also the posts about</em> <a href="2020-05-07-ipa-acme-mod_md.html">mod_md for Apache</a> <em>and</em> <a href="2020-05-13-ipa-acme-dns.html">Certbot with FreeIPA DNS</a>.</p>
<p><em>Automated Certificate Management Environment (ACME)</em> is a protocol for automated identifier validation and certificate issuance. Its goal is to improve security on the Internet by reducing certificate lifetimes and avoiding manual processes from certificate lifecycle management.</p>
<p>ACME’s original use case is HTTPS on the public Internet. The public CA <a href="https://letsencrypt.org/">*Let's Encrypt*</a> is already one of the biggest CAs. Clients use ACME to talk to <em>Let’s Encrypt</em>, automating DNS name validation, certificate issuance and in most cases, certificate installation and renewal.</p>
<p>But ACME is not limited to Let’s Encrypt. Other CAs implement it and enterprise (private) CAs can implement it too. And after a few years of talking about it, we are finally implementing an ACME service in FreeIPA.</p>
<p>In this post I will give a high-level overview of the ACME protocol, and the ACME service architecture in FreeIPA. If that doesn’t interest you, scroll down to the demo where I show the Certbot ACME client acquiring a certificate from the FreeIPA CA.</p>
<h2 id="acme-protocol-in-brief">ACME protocol, in brief</h2>
<ol type="1">
<li><p>ACME client registers with ACME server. ACME accounts <em>may</em> be bound to some external accounts but more commonly clients register <em>ad hoc</em> with no binding to any other service. This is the case for the FreeIPA ACME service.</p></li>
<li><p>ACME client creates an <em>order</em> for a certificate with one or more <em>identifiers</em> (e.g. DNS names). The FreeIPA ACME service initially supports only DNS identifiers, but the IETF ACME working has defined challenges for other identifier types including IP addresses and email addresses.</p></li>
<li><p>ACME service offers <em>challenges</em> that the client can use to prove <em>control</em> of the identifier. For DNS names there are three challenge types:</p>
<dl>
<dt><code>dns-01</code></dt>
<dd><p>Client creates DNS records to prove control of the identifier.</p>
</dd>
<dt><code>http-01</code></dt>
<dd><p>Client provisions HTTP resource to prove control of the identifier.</p>
</dd>
<dt><code>tls-alpn-01</code></dt>
<dd><p>Client configures TLS server use <em>Application Layer Protocol Negotiation (ALPN)</em> and a special X.509 certificate to prove control of the identifier.</p>
</dd>
</dl>
<p>The FreeIPA ACME service currently implements the <code>dns-01</code> and <code>http-01</code> challenges.</p></li>
<li><p>Client responds to the challenge and advises ACME server to proceed with validation.</p></li>
<li><p>Server attempts to validate the clients response to the challenge. The identifier is <em>authorised</em> when sufficient challenges (usually one per identifier) have been validated.</p></li>
<li><p>After all identifiers in the order have been authorised, the client <em>finalises</em> the order causing the CA to issue the certificate.</p></li>
<li><p>The client retrieves the issued certificate and (commonly) configures an application to use it.</p></li>
</ol>
<p>There are many ACME client implementations. Some, such as <a href="https://certbot.eff.org/">Certbot</a>, are general purpose and can be used standalone or integrated with many kinds of applications. Others are application specific, like <a href="https://httpd.apache.org/docs/current/mod/mod_md.html">mod_md</a> for Apache httpd.</p>
<h2 id="freeipa-acme-service-architecture">FreeIPA ACME service architecture</h2>
<p>The FreeIPA ACME service uses <a href="https://www.dogtagpki.org/wiki/PKI_ACME_Responder">Dogtag PKI ACME responder</a>. This is an optional component of Dogtag, separate from the CA or other subsystems. Like other Dogtag subsystems it run in the same process and is accessed via Tomcat.</p>
<p>The Dogtag ACME subsystem will automatically be deployed on every CA server in a FreeIPA deployment. But <strong>it will not service requests</strong> until the administrator enables it. There are two reasons for this approach.</p>
<p>For ease of client configuration it is desired to have a single, permanent name for the ACME service across the whole topology. The topology should be able to evolve without having the reconfigure ACME clients. There is already a candidate DNS name that is either managed by FreeIPA (when using internal DNS) or required to managed by administrators (when not using internal DNS). That is <code>ipa-ca.$DOMAIN</code>. This points to all CA replicas in the topology. If we let administrators choose the FreeIPA servers upon which to configure the ACME service, we would have to introduce a new DNS name to manage. It will complicate code, and impose a new burden on administrators if the internal DNS is not used. By automatically deploying the ACME service on all CA replicas, the <code>ipa-ca.$DOMAIN</code> name is always a valid name for ACME clients to use.</p>
<p>The second reason is that there is just less for adminstrators to worry about. How do I install the ACME service? Don’t worry about it, it’s already there, just turn it on.</p>
<p>Turning the ACME service on or off, or other configuration changes, will be effected deployment-wide. At least, that is the goal. Early releases <em>might</em> require per-server configuration steps. But eventually configuration will be contained in the replicated LDAP database and administrators will just use regular <code>ipa</code> subcommands to control the ACME service deployment-wide.</p>
<p>The ACME database, too, will be replicated deployment wide. It is possible that some data, such as <em>nonces</em>, might have to be kept server-local for performance reasons (this is not the case now, but load testing is coming).</p>
<h2 id="demo-certbot-client-running-standalone-http-server">Demo: Certbot client running standalone HTTP server</h2>
<p>The following demo scenario was carried out on a FreeIPA-enrolled host. The ACME protocol requires the use of TLS between client and server. The FreeIPA ACME service certificate is (usually) signed by the FreeIPA CA, so the client needs to trust it. On machines that are not FreeIPA clients CA trust would have to be established by other means so that the ACME client will trust the ACME server.</p>
<p>The general purpose ACME client <a href="https://certbot.eff.org/">Certbot</a> integrates with many different server program and can also be used “standalone”. That is what I will do in this demo. It is not representative of real-world use but is a straightforward way to demonstrate that an ACME server is operating correctly.</p>
<p>The two steps, registration and issuance, can be rolled into a single command. For clarity I will keep these as two separate steps.</p>
<h3 id="registration">Registration</h3>
<p>First, the registration step creates an account with the ACME service:</p>
<pre><code>[root@f31-0 ~]# certbot \
    --server https://ipa-ca.ipa.local/acme/directory \
    register -m ftweedal@redhat.com --agree-tos \
Saving debug log to /var/log/letsencrypt/letsencrypt.log

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Would you be willing to share your email address with the Electronic Frontier
Foundation, a founding partner of the Let&#39;s Encrypt project and the non-profit
organization that develops Certbot? We&#39;d like to send you email about our work
encrypting the web, EFF news, campaigns, and ways to support digital freedom.
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
(Y)es/(N)o: n

IMPORTANT NOTES:
 - Your account credentials have been saved in your Certbot
   configuration directory at /etc/letsencrypt. You should make a
   secure backup of this folder now. This configuration directory will
   also contain certificates and private keys obtained by Certbot so
   making regular backups of this folder is ideal.</code></pre>
<p>By default Certbot will contact <em>Let’s Encrypt</em>, the public CA. The <code>--server</code> option is given to point Certbot to the FreeIPA ACME service instead.</p>
<p><code>-m</code> gives a contact email address (this is optional). <code>--agree-tos</code> agrees to the terms of service of the ACME server. The “share email with EFF” prompt is only relevant when using Let’s Encrypt and can be ignored.</p>
<h3 id="identifier-validation-and-certificate-issuance">Identifier validation and certificate issuance</h3>
<p>and ACME account then request a certificate for the machine’s hostname from the FreeIPA CA.</p>
<p>The next step is to issue the certificate. The <code>certonly</code> command means: just write the issued certificate to disk; don’t configure any programs to use it. The <code>--domain</code> option can be given multiple times to request a certificate with multiple subject alternative names.</p>
<p>The <code>--standalone</code> option tells Certbot to start its own HTTP server to fulfil the <code>http-01</code> challenge. This server will listen on <code>tcp/80</code> therefore it must run as <code>root</code>. In typical production scenarios Certbot will instead integrate with existing HTTP servers and avoid running it with <code>root</code> privileges. Or you would use an alternative client implementation suited to your use case.</p>
<pre><code>[root@f31-0 ~]# certbot \
    --server https://ipa-ca.ipa.local/acme/directory \
    certonly \
    --domain $(hostname) \
    --standalone
Saving debug log to /var/log/letsencrypt/letsencrypt.log
Plugins selected: Authenticator standalone, Installer None
Obtaining a new certificate
Performing the following challenges:
http-01 challenge for f31-0.ipa.local
Waiting for verification...
Cleaning up challenges

IMPORTANT NOTES:
 - Congratulations! Your certificate and chain have been saved at:
   /etc/letsencrypt/live/f31-0.ipa.local/fullchain.pem
   Your key file has been saved at:
   /etc/letsencrypt/live/f31-0.ipa.local/privkey.pem
   Your cert will expire on 2020-08-03. To obtain a new or tweaked
   version of this certificate in the future, simply run certbot
   again. To non-interactively renew *all* of your certificates, run
   &quot;certbot renew&quot;
 - If you like Certbot, please consider supporting our work by:

   Donating to ISRG / Let&#39;s Encrypt:   https://letsencrypt.org/donate
   Donating to EFF:                    https://eff.org/donate-le</code></pre>
<p>The whole command completed in a few seconds. Below is the pretty print of the certificate. Observe the ~3 month validity and that the issuer is the FreeIPA CA, not Let’s Encrypt.</p>
<pre><code>[root@f31-0 ~]# openssl x509 -text -noout -in /etc/letsencrypt/live/f31-0.ipa.local/cert.pem
Certificate:
  Data:
  Version: 3 (0x2)
  Serial Number: 25 (0x19)
  Signature Algorithm: sha256WithRSAEncryption
  Issuer: O = IPA.LOCAL 202004011654, CN = Certificate Authority
  Validity
      Not Before: May  5 11:30:33 2020 GMT
      Not After : Aug  3 11:30:33 2020 GMT
  Subject: CN = f31-0.ipa.local
  Subject Public Key Info:
      Public Key Algorithm: rsaEncryption
          RSA Public-Key: (2048 bit)
          Modulus:
              &lt;snip&gt;
          Exponent: 65537 (0x10001)
  X509v3 extensions:
      X509v3 Subject Key Identifier: 
          2D:75:79:C2:A0:8C:EF:44:D2:6B:E4:19:E6:BC:42:23:BA:66:1E:D9
      X509v3 Authority Key Identifier: 
          keyid:5E:55:7C:10:82:C1:19:09:E2:42:EC:65:96:89:08:50:35:62:FE:8F

      X509v3 Subject Alternative Name: 
          DNS:f31-0.ipa.local
      X509v3 Key Usage: critical
          Digital Signature, Key Encipherment
      X509v3 Extended Key Usage: 
          TLS Web Server Authentication, TLS Web Client Authentication
      Authority Information Access: 
          OCSP - URI:http://ipa-ca.ipa.local/ca/ocsp

      X509v3 CRL Distribution Points: 

          Full Name:
            URI:http://ipa-ca.ipa.local/ipa/crl/MasterCRL.bin
          CRL Issuer:
            DirName:O = ipaca, CN = Certificate Authority

  Signature Algorithm: sha256WithRSAEncryption
       &lt;snip&gt;</code></pre>
<h2 id="discussion">Discussion</h2>
<p>In this post I demonstrated just one basic client scenario. In upcoming posts I will explore some more advanced and more realistic client scenarios including use of the DNS-based challenges and the <a href="https://httpd.apache.org/docs/current/mod/mod_md.html">mod_md</a> client module for Apache httpd.</p>
<p>The Dogtag ACME responder and FreeIPA ACME service are still undergoing rapid development and are <strong>not production ready</strong>. Some parts of the Dogtag implementation have made their way into releases, but should be considered a “preview”. That said, if you would like to play with the ACME service or perform integration testing, we are happy to collaborate and you should reach out on <code>pki-devel@redhat.com</code>.</p>
<p>The fact that ACME accounts have no “binding” to any existing FreeIPA may surprise some people. In the initial release we want to implement the “baseline” use case also addressed by the public ACME CAs (Let’s Encrypt). That is: <em>an essentially anonymous client proves control of an identifier and gets a certificate.</em> We recognise that organisiations <em>may</em> want ACME accounts to be associated with (or views of) existing identities, and implement authorisation policies based on those accounts and their groups. But we don’t <em>know</em> whether this is required, or exactly what it would look like. So we are going to “wait and see” if customers tell us what “enterprise ACME” should be. In the mean time we are focused on the core use case.</p>
<p>Other considerations for the FreeIPA ACME service include:</p>
<ul>
<li>customising the ACME certificate profile (e.g. altering the validity period, Certificate Policies extension, etc)</li>
<li>issuing ACME certificates from a sub-CA of the FreeIPA CA</li>
<li>controlling which validation challenges are enabled</li>
<li>block/allow lists or other mechanisms to decide whether a particular identifier (DNS name) can be issued via ACME</li>
</ul>
<p>All of these are on the roadmap, but they are likely to be deferred beyond the initial release.</p>
<h2 id="conclusion">Conclusion</h2>
<p>That’s all for this post. I’ll be following up soon with a post about using Apache <a href="https://httpd.apache.org/docs/current/mod/mod_md.html">mod_md</a> with the FreeIPA ACME service.</p>]]></summary>
</entry>
<entry>
    <title>Deploying FreeIPA with a 4096-bit CA signing key</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2020-01-28-freeipa-override-ca-key-size.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2020-01-28-freeipa-override-ca-key-size.html</id>
    <published>2020-01-28T00:00:00Z</published>
    <updated>2020-01-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="deploying-freeipa-with-a-4096-bit-ca-signing-key">Deploying FreeIPA with a 4096-bit CA signing key</h1>
<p>Recent versions of FreeIPA create a 3072-bit CA signing key by default. Older versions used 2048-bit signing keys. Until recently, there was no supported way to deploy FreeIPA with a larger signing key. It was an open secret that you could hack a single file to change the key size when deploying, and everything would work just fine. But still, it was not supported or recommended to do this.</p>
<p>As of FreeIPA 4.8 (RHEL 8.1; Fedora 30) there is an officially supported way to choose a different key size when installing FreeIPA. In this short post I will demonstrate how to do it.</p>
<p>First, an admonition. Choosing a larger key size can negatively affect performance, for both signing and verification (i.e. <em>all clients are affected</em>). 4096-bit RSA operations are twice as slow as 3072-bit RSA, but the bits of security grows at a smaller rate. 3072-bit RSA has 128 bits of security, but 4096-bit RSA only increases your security to 140 bits. For 256 bits of security you need a 15360-bit key. In practice 3072-bit RSA is expected to be secure for at least another decade.</p>
<p>With that out of the way, let’s look at how to do it. The procedure works for both self-signed and externally-signed CAs. It is done via the <code>--pki-config-override</code> option, which allows the server administrator to specify a file that sets or overrides Dogtag <code>pkispawn(8)</code> configuration directives. <code>pki_default.cfg(5)</code> gives a comprehensive overview of the directives available, although not all of these are allowed to be overriden in a FreeIPA installation (<code>ipa-server-install</code> itself checks the file for directives that are not allowed to be overridden).</p>
<p>Fortunately, override is allowed for the <code>pki_ca_signing_key_size</code> directive. Setting this to 4096 (or some other sensible value) will have the desired effect, as the following transcript demonstrates:</p>
<pre><code>[root@rhel82-0 ~]# cat &gt; pki_override.cfg &lt;&lt;EOF
[CA]
pki_ca_signing_key_size=4096
EOF

[root@rhel82-0 ~]# ipa-server-install \
    --unattended \
    --realm IPA.LOCAL \
    --ds-password &quot;$DM_PASS&quot; --admin-password &quot;$ADMIN_PASS&quot; \
    --external-ca \
    --pki-config-override $PWD/pki_override.cfg

... stuff happens ...

  [1/10]: configuring certificate server instance
The next step is to get /root/ipa.csr signed by your
CA and re-run /usr/sbin/ipa-server-install as:
/usr/sbin/ipa-server-install \
  --external-cert-file=/path/to/signed_certificate \
  --external-cert-file=/path/to/external_ca_certificate
The ipa-server-install command was successful

[root@rhel82-0 ~]# openssl req -text &lt; /root/ipa.csr | head
Certificate Request:
    Data:
        Version: 1 (0x0)
        Subject: O = IPA.LOCAL, CN = Certificate Authority
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                RSA Public-Key: (4096 bit)
                Modulus:
                    00:c6:05:36:7b:28:c6:03:19:19:91:d3:e9:31:28:
                    5f:50:ab:60:a4:e8:fa:09:ba:5d:a1:25:53:cf:74:</code></pre>
<p>The key size is 4096-bit, as expected. Had the <code>--external-ca</code> option <em>not</em> been provided a 4096-bit self-signed CA would have been created and the installation would have run to completion.</p>]]></summary>
</entry>
<entry>
    <title>Disabling Certmonger auto-renewal</title>
    <link href="https://frasertweedale.github.io/blog-redhat/posts/2019-12-12-certmonger-disable-auto-renew.html" />
    <id>https://frasertweedale.github.io/blog-redhat/posts/2019-12-12-certmonger-disable-auto-renew.html</id>
    <published>2019-12-12T00:00:00Z</published>
    <updated>2019-12-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 id="disabling-certmonger-auto-renewal">Disabling Certmonger auto-renewal</h1>
<p>A customer recently asked how to disable Certmonger auto-renewal of some FreeIPA system certificates. Their organisation’s security policy prohibited auto-renewal. (This is not a good idea in general, but this was a very security-conscious organisation so I’ll assume they have good reasons).</p>
<p>One way to achieve this is to remove the Certmonger tracking requests via <code>getcert stop-tracking</code>. But when it comes time to renew the certificate, this makes life hard. The Certmonger tracking requests are set up to:</p>
<ul>
<li>Use the correct renewal helpers to issue the certificate properly</li>
<li>Store the certificate in the correct place</li>
<li>Copy the certificate to particular LDAP entries to ensure the FreeIPA system continues to function</li>
</ul>
<p>Removing the tracking request means that you have to do all the above tasks yourself. And the steps differ depending on the certificate being renewed. There are many ways to mess up.</p>
<p>A better approach is to keep the Certmonger tracking requests defined, but disable auto-renewal. It is not obvious that you can even do this, let alone <em>how</em> to do it. And that is why I wrote this post. The command is:</p>
<pre><code># getcert start-tracking -i $REQUEST_ID --no-renew</code></pre>
<p>Don’t let the name <code>start-tracking</code> trick you. If you supply <code>-i $REQUEST_ID</code> this command will modify the existing request. With auto-renewal disabled, to renew the certificate you must manually trigger it via:</p>
<pre><code># getcert resubmit -i $REQUEST_ID</code></pre>
<p>If you want to reenable auto-renewal, use the <code>--renew</code> flag:</p>
<pre><code># getcert start-tracking -i $REQUEST_ID --renew</code></pre>
<p>The following transcript deals with the IPA RA agent certificate tracking request. We first disable auto-renewal, then manually renew the certificate, and finally reenable auto-renewal.</p>
<pre><code># getcert list -i 20191206060652                                                                                                                        [6/38]
Number of certificates and requests being tracked: 9.           
Request ID &#39;20191206060652&#39;:                                                          
        status: MONITORING                                                            
        stuck: no                                                                     
        key pair storage: type=FILE,location=&#39;/var/lib/ipa/ra-agent.key&#39;
        certificate: type=FILE,location=&#39;/var/lib/ipa/ra-agent.pem&#39;
        CA: dogtag-ipa-ca-renew-agent
        issuer: CN=Certificate Authority,O=IPA ACME 201912061604
        subject: CN=IPA RA,O=IPA ACME 201912061604                                                                                                                           
        expires: 2021-11-25 17:06:54 AEDT
        key usage: digitalSignature,keyEncipherment,dataEncipherment
        eku: id-kp-clientAuth
        pre-save command: /usr/libexec/ipa/certmonger/renew_ra_cert_pre
        post-save command: /usr/libexec/ipa/certmonger/renew_ra_cert
        track: yes
        auto-renew: yes

# getcert start-tracking -i 20191206060652 --no-renew
Request &quot;20191206060652&quot; modified.

# getcert list -i 20191206060652 |grep auto-renew                       
        auto-renew: no

# openssl x509 -serial &lt; /var/lib/ipa/ra-agent.pem
serial=07

# getcert resubmit -i 20191206060652
Resubmitting &quot;20191206060652&quot; to &quot;dogtag-ipa-ca-renew-agent&quot;.

# getcert list -i 20191206060652 |grep status
        status: MONITORING

# openssl x509 -serial -noout &lt; /var/lib/ipa/ra-agent.pem
serial=0B

# getcert start-tracking -i 20191206060652 --renew
Request &quot;20191206060652&quot; modified.

# getcert list -i 20191206060652 |grep auto-renew
        auto-renew: yes</code></pre>
<p>A final note. I used the long form <code>--[no-]renew</code> options. I prefer long options because they are usually easier for readers (including <em>future me</em>) to understand. But <code>getcert-start-tracking(1)</code> and other Certmonger man pages don’t even mention the long options. The corresponding short options are <code>-r</code> (enable auto-renew) and <code>-R</code> (disable auto-renew).</p>]]></summary>
</entry>

</feed>
